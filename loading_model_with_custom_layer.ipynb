{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7245ea27",
   "metadata": {},
   "source": [
    "***\n",
    "### Tutorial to load a keras model with custom layer(s):\n",
    "\n",
    "This notebook can be used to load the model with custom layer using the function `loading_pruned_model` available in the package. The necessary imports can be installed using the cell below. For all the classes that are not buint-in to the tensorflow/keras library, you have to use the `custom_objects` parameter to specify them so that when reading the .json file to ascertain the model architecture, the function `load_model_from_json` can identify any customized layers/operations. \n",
    "\n",
    "The format to declare the custom class object in the function call is `\"Class/Function Name String\": Class/ Function`. Example: for our custom layer the declaration is as follow: `\"MaskedDense\": MaskedDense`.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7410229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "1.3.4\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "from nn_globals import *\n",
    "from nn_evaluate import get_sparsity,k_fold_validation\n",
    "from nn_pruning_module_support import __generate_delta_plots__\n",
    "from dataset import muon_data_split\n",
    "from nn_pruning_module_support import loading_trained_model\n",
    "\n",
    "from custom_dense_layer import MaskedDense\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416363a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model.json\n",
      "./models/model_weights.h5\n",
      "Loaded model from disk\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 23)                92        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                460       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                300       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 1,204\n",
      "Trainable params: 1,068\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# pruned_model = loading_trained_model(filepath = \"./models\",\n",
    "#                                  model_filename = \"custom_model_50\",\n",
    "#                                  custom_objects ={'GlorotUniform': glorot_uniform(), \n",
    "#                                                   \"MaskedDense\": MaskedDense, \n",
    "#                                                   \"L1L2\": l1_l2()})\n",
    "# pruned_model.summary()\n",
    "baseline = loading_trained_model(filepath = \"./models\",\n",
    "                                 model_filename = \"model\")\n",
    "baseline.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a2e7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of the dense layer is = 0.0\n",
      "Sparsity of the dense_1 layer is = 0.0\n",
      "Sparsity of the dense_2 layer is = 0.0\n",
      "Sparsity of the dense_3 layer is = 0.0\n"
     ]
    }
   ],
   "source": [
    "# verify the sparsity of loaded pruned model\n",
    "for layer in pruned_model.layers:\n",
    "    if \"dense\" in layer.name:\n",
    "        print(\"Sparsity of the {} layer is = {}\".format(layer.name, get_sparsity(layer.get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c221b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(array):\n",
    "    n = len(array)\n",
    "    prb = 1 / n\n",
    "    # calculating expectation overall\n",
    "    exp = 0\n",
    "    for i in range(0, n):\n",
    "        exp += (array[i] * prb)         \n",
    "    # returning expectation as sum\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7dbc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_adjusted(W_sparse, W_dense):\n",
    "    eps = 10e-9\n",
    "    const = np.std(W_sparse)/(np.std(W_dense)+eps)\n",
    "    W_sparse_corr = const*W_sparse + expectation(W_dense) - expectation(const*W_sparse)\n",
    "    \n",
    "    return W_sparse_corr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pruned_model.layers:\n",
    "    if \"dense\" in layer.name:\n",
    "        print(\"Sparsity of the {} layer is = {}\".format(layer.name, get_sparsity(layer.get_weights()[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aae7ca",
   "metadata": {},
   "source": [
    "***\n",
    "### Evaluating the model:\n",
    "To use the model for prediction, suggestion is to use the functions available in `nn_evaluate` file. The code to preprocess the data can be used to load and extract relevant features from the raw file. **NOTE:** file path to the data needs to be edited in the `nn_globals.py`\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514eea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,dxy =  muon_data_split(infile_muon_displ, \n",
    "                            reg_pt_scale=reg_pt_scale, \n",
    "                            reg_dxy_scale=reg_dxy_scale, \n",
    "                            test_size=0.0)\n",
    "y = np.abs(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cd4b9",
   "metadata": {},
   "source": [
    "***\n",
    "With `k_fold_validation`, using `metric_type` argument, we can change the type of evaluation metric. It can be `[\"RMSE\", \"MAE\", \"MAPE\"]`\n",
    "\n",
    "Using `__generate_delta_plots__` we can get a gaussian approximation for the errors for momentum and angular displacement.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(model = pruned_model,\n",
    "                    x = x,\n",
    "                    y = y,\n",
    "                    dxy = dxy,\n",
    "                    folds=1,\n",
    "                    eval_batch_size=2000,\n",
    "                    metric_type='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d24368",
   "metadata": {},
   "outputs": [],
   "source": [
    "__generate_delta_plots__(model = pruned_model,\n",
    "                        x = x,\n",
    "                        y = y,\n",
    "                        dxy = dxy,\n",
    "                        color='plum',\n",
    "                        bins_y = [-20.,20.],\n",
    "                        bins_dxy = [-20.,20.],\n",
    "                        batch_size = 4096,\n",
    "                        min_y_val= 20.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
