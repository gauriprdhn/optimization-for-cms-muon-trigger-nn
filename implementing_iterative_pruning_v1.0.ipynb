{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2875097b",
   "metadata": {},
   "source": [
    "### Part - I: Importing Required Modules/ Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4751381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "1.3.4\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c610e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports \n",
    "from nn_globals import *\n",
    "from dataset import muon_data_split\n",
    "from nn_plotting import gaus, fit_gaus, corr_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8b6c7",
   "metadata": {},
   "source": [
    "### Part- II: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import muon data\n",
    "# 'x' is the array of input variables, 'y' is the q/pT\n",
    "x_train_displ, x_test_displ, y_train_displ, y_test_displ, dxy_train_displ, dxy_test_displ= muon_data_split(filename=DATAFILEPATH, \n",
    "                                                                                                           reg_pt_scale=REG_PT_SCALE, \n",
    "                                                                                                           reg_dxy_scale=REG_DXY_SCALE, \n",
    "                                                                                                           test_size=TEST_SIZE,\n",
    "                                                                                                           nvariables = NVARIABLES,\n",
    "                                                                                                           nentries= NENTRIES,\n",
    "                                                                                                           batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc7c79",
   "metadata": {},
   "source": [
    "### Part-III: Use the cells in this section for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754959ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\"dphi_1\",\"dphi_2\",\"dphi_3\",\"dphi_4\",\"dphi_5\",\"dphi_6\",\n",
    "#        \"dtheta_1\",\"dtheta_2\",\"dtheta_3\",\"dtheta_4\",\"dtheta_5\", \"dtheta_6\",\n",
    "#        \"bend_1\",\"bend_2\",\"bend_3\",\"bend_4\",\n",
    "#        \"track theta\"]\n",
    "\n",
    "# x = np.concatenate((x_train_displ,x_test_displ),axis=0)\n",
    "# y = np.concatenate((y_train_displ,y_test_displ),axis=0)\n",
    "# dxy = np.concatenate((dxy_train_displ,dxy_test_displ),axis=0)\n",
    "\n",
    "# corr_plot(x,y,dxy,columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e64cc0",
   "metadata": {},
   "source": [
    "### Part-IV: Build the custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, TerminateOnNaN, EarlyStopping\n",
    "\n",
    "# project-specific imports\n",
    "from nn_evaluate import huber_loss, k_fold_validation\n",
    "from nn_training import lr_schedule\n",
    "from nn_pruning_module_support import loading_trained_model\n",
    "from nn_training_pruned_model import (generate_layer_masks, \n",
    "                                      create_sparse_model)\n",
    "from nn_training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b1ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = loading_trained_model(filepath = \"models/\",\n",
    "                                 model_filename = \"model\")\n",
    "baseline.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cb284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PRUNING CYCLE - I\n",
    "\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "eps = 1e-4\n",
    "momentum = 0.9\n",
    "lr = 1e-4\n",
    "retrain_batch_size = 1000\n",
    "sparsity = 0.10\n",
    "retrain_epochs = 50\n",
    "clipnorm = 10.0\n",
    "\n",
    "adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0,\n",
    "                               mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "pruned_model_10 = create_sparse_model(model = baseline,\n",
    "                                       input_dim = NVARIABLES,\n",
    "                                       output_dim = 2,\n",
    "                                       k_sparsity = sparsity,\n",
    "                                       bn_epsilon = eps,\n",
    "                                       bn_momentum = momentum,\n",
    "                                       l1_reg = l1_reg,\n",
    "                                       l2_reg = l1_reg,\n",
    "                                       kernel_initializer=\"glorot_uniform\",\n",
    "                                       optimizer = adam)\n",
    "pruned_model_10, history_10 = train_model(model = pruned_model_10,\n",
    "                                            x = x_train_displ,\n",
    "                                            y = np.column_stack((y_train_displ,dxy_train_displ)),\n",
    "                                            epochs = retrain_epochs,\n",
    "                                            batch_size = retrain_batch_size,\n",
    "                                            callbacks=[lr_decay, \n",
    "                                                      early_stopping, \n",
    "                                                      terminate_on_nan],\n",
    "                                            verbose = True,\n",
    "                                            validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf813e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(model = pruned_model_10, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds =1,\n",
    "                  metric_type = \"RMSE\")\n",
    "k_fold_validation(model = pruned_model_10, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ, \n",
    "                  folds =1,\n",
    "                  metric_type = \"MAE\")\n",
    "__generate_delta_plots__(pruned_model_10,\n",
    "                         x = x_test_displ,\n",
    "                         y = y_test_displ,\n",
    "                         dxy = dxy_test_displ,\n",
    "                         plot_colors = \"seagreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f44ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUNING CYCLE - II\n",
    "\n",
    "lr = 2.5e-4\n",
    "clipnorm = 10.\n",
    "eps = 1e-4\n",
    "momentum = 0.9\n",
    "retrain_epochs = 75\n",
    "retrain_batch_size = 1000\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "sparsity = 0.20\n",
    "adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0,\n",
    "                               mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "pruned_model_20 = create_sparse_model(model = pruned_model_10,\n",
    "                                       input_dim = NVARIABLES,\n",
    "                                       output_dim = 2,\n",
    "                                       k_sparsity = sparsity,\n",
    "                                       bn_epsilon = eps,\n",
    "                                       bn_momentum = momentum,\n",
    "                                       l1_reg = l1_reg,\n",
    "                                       l2_reg = l1_reg,\n",
    "                                       kernel_initializer=\"glorot_uniform\",\n",
    "                                       optimizer = adam)\n",
    "\n",
    "pruned_model_20, history_20 = train_model(model = pruned_model_20,\n",
    "                                           x = x_train_displ,\n",
    "                                           y = np.column_stack((y_train_displ,dxy_train_displ)),\n",
    "                                           epochs = retrain_epochs,\n",
    "                                           batch_size = retrain_batch_size,\n",
    "                                           callbacks=[lr_decay, \n",
    "                                                      early_stopping, \n",
    "                                                      terminate_on_nan],\n",
    "                                           verbose = True,\n",
    "                                           validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14658ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(model = pruned_model_20, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds =1,\n",
    "                  metric_type = \"RMSE\")\n",
    "k_fold_validation(model = pruned_model_20, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ, \n",
    "                  folds =1,\n",
    "                  metric_type = \"MAE\")\n",
    "__generate_delta_plots__(pruned_model_20,\n",
    "                         x = x_test_displ,\n",
    "                         y = y_test_displ,\n",
    "                         dxy = dxy_test_displ,\n",
    "                         plot_colors = \"seagreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUNING CYCLE - III\n",
    "\n",
    "lr = 3e-4\n",
    "clipnorm = 10.\n",
    "eps = 1e-4\n",
    "momentum = 0.9\n",
    "retrain_epochs = 75\n",
    "retrain_batch_size = 800\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "\n",
    "adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0,\n",
    "                               mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "pruned_model_30 = create_sparse_model(model = pruned_model_20,\n",
    "                                       input_dim = NVARIABLES,\n",
    "                                       output_dim = 2,\n",
    "                                       k_sparsity = sparsity,\n",
    "                                       bn_epsilon = eps,\n",
    "                                       bn_momentum = momentum,\n",
    "                                       l1_reg = l1_reg,\n",
    "                                       l2_reg = l1_reg,\n",
    "                                       kernel_initializer=\"glorot_uniform\",\n",
    "                                       optimizer = adam)\n",
    "\n",
    "pruned_model_30, history_30 = train_model(model = pruned_model_30,\n",
    "                                           x = x_train_displ,\n",
    "                                           y = np.column_stack((y_train_displ,dxy_train_displ)),\n",
    "                                           epochs = retrain_epochs,\n",
    "                                           batch_size = retrain_batch_size,\n",
    "                                           callbacks=[lr_decay, \n",
    "                                                      early_stopping, \n",
    "                                                      terminate_on_nan],\n",
    "                                           verbose = True,\n",
    "                                           validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(model = pruned_model_30, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds =1,\n",
    "                  metric_type = \"RMSE\")\n",
    "k_fold_validation(model = pruned_model_30, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ, \n",
    "                  folds =1,\n",
    "                  metric_type = \"MAE\")\n",
    "__generate_delta_plots__(pruned_model_30,\n",
    "                         x = x_test_displ,\n",
    "                         y = y_test_displ,\n",
    "                         dxy = dxy_test_displ,\n",
    "                         plot_colors = \"seagreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4bdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUNING CYCLE - IV\n",
    "\n",
    "lr = 5e-4\n",
    "clipnorm = 10.\n",
    "eps = 1e-4\n",
    "momentum = 0.8\n",
    "retrain_epochs = 100\n",
    "retrain_batch_size = 800\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "\n",
    "adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0,\n",
    "                               mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "pruned_model_40 = create_sparse_model(model = pruned_model_30,\n",
    "                                       input_dim = NVARIABLES,\n",
    "                                       output_dim = 2,\n",
    "                                       k_sparsity = sparsity,\n",
    "                                       bn_epsilon = eps,\n",
    "                                       bn_momentum = momentum,\n",
    "                                       l1_reg = l1_reg,\n",
    "                                       l2_reg = l1_reg,\n",
    "                                       kernel_initializer=\"glorot_uniform\",\n",
    "                                       optimizer = adam)\n",
    "\n",
    "pruned_model_40, history_40 = train_model(model = pruned_model_40,\n",
    "                                           x = x_train_displ,\n",
    "                                           y = np.column_stack((y_train_displ,dxy_train_displ)),\n",
    "                                           epochs = retrain_epochs,\n",
    "                                           batch_size = retrain_batch_size,\n",
    "                                           callbacks=[lr_decay, \n",
    "                                                      early_stopping, \n",
    "                                                      terminate_on_nan],\n",
    "                                           verbose = True,\n",
    "                                           validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(model = pruned_model_40, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds =1,\n",
    "                  metric_type = \"RMSE\")\n",
    "k_fold_validation(model = pruned_model_40, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ, \n",
    "                  folds =1,\n",
    "                  metric_type = \"MAE\")\n",
    "__generate_delta_plots__(pruned_model_40,\n",
    "                         x = x_test_displ,\n",
    "                         y = y_test_displ,\n",
    "                         dxy = dxy_test_displ,\n",
    "                         plot_colors = \"seagreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287399f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUNING CYCLE - V\n",
    "\n",
    "lr = 7.5e-4\n",
    "clipnorm = 10.\n",
    "eps = 1e-4\n",
    "momentum = 0.9\n",
    "retrain_epochs = 125\n",
    "retrain_batch_size = 500\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "sparsity = 0.50\n",
    "\n",
    "adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0,\n",
    "                               mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "pruned_model_50 = create_sparse_model(model = pruned_model_40,\n",
    "                                       input_dim = NVARIABLES,\n",
    "                                       output_dim = 2,\n",
    "                                       k_sparsity = sparsity,\n",
    "                                       bn_epsilon = eps,\n",
    "                                       bn_momentum = momentum,\n",
    "                                       l1_reg = l1_reg,\n",
    "                                       l2_reg = l1_reg,\n",
    "                                       kernel_initializer=\"glorot_uniform\",\n",
    "                                       optimizer = adam)\n",
    "\n",
    "pruned_model_50, history_50 = train_model(model = pruned_model_50,\n",
    "                                           x = x_train_displ,\n",
    "                                           y = np.column_stack((y_train_displ,dxy_train_displ)),\n",
    "                                           epochs = retrain_epochs,\n",
    "                                           batch_size = retrain_batch_size,\n",
    "                                           callbacks=[lr_decay, \n",
    "                                                      early_stopping, \n",
    "                                                      terminate_on_nan],\n",
    "                                           verbose = True,\n",
    "                                           validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f654c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(model = pruned_model_50, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds =1,\n",
    "                  metric_type = \"RMSE\")\n",
    "k_fold_validation(model = pruned_model_50, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ, \n",
    "                  folds =1,\n",
    "                  metric_type = \"MAE\")\n",
    "__generate_delta_plots__(pruned_model_50,\n",
    "                         x = x_test_displ,\n",
    "                         y = y_test_displ,\n",
    "                         dxy = dxy_test_displ,\n",
    "                         plot_colors = \"seagreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUNING CYCLE - VI\n",
    "\n",
    "lr = 3.5e-3\n",
    "clipnorm = 10.\n",
    "eps = 1e-4\n",
    "momentum = 0.9\n",
    "retrain_epochs = 200\n",
    "retrain_batch_size = 1000\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "sparsity = 0.60\n",
    "\n",
    "adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0,\n",
    "                               mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "pruned_model_60 = create_sparse_model(model = pruned_model_50,\n",
    "                                       input_dim = NVARIABLES,\n",
    "                                       output_dim = 2,\n",
    "                                       k_sparsity = sparsity,\n",
    "                                       bn_epsilon = eps,\n",
    "                                       bn_momentum = momentum,\n",
    "                                       l1_reg = l1_reg,\n",
    "                                       l2_reg = l1_reg,\n",
    "                                       kernel_initializer=\"glorot_uniform\",\n",
    "                                       optimizer = adam)\n",
    "\n",
    "pruned_model_60, history_60 = train_model(model = pruned_model_60,\n",
    "                                           x = x_train_displ,\n",
    "                                           y = np.column_stack((y_train_displ,dxy_train_displ)),\n",
    "                                           epochs = retrain_epochs,\n",
    "                                           batch_size = retrain_batch_size,\n",
    "                                           callbacks=[lr_decay, \n",
    "                                                      early_stopping, \n",
    "                                                      terminate_on_nan],\n",
    "                                           verbose = True,\n",
    "                                           validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(model = pruned_model_60, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds =1,\n",
    "                  metric_type = \"RMSE\")\n",
    "k_fold_validation(model = pruned_model_60, \n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ, \n",
    "                  folds =1,\n",
    "                  metric_type = \"MAE\")\n",
    "__generate_delta_plots__(pruned_model_60,\n",
    "                         x = x_test_displ,\n",
    "                         y = y_test_displ,\n",
    "                         dxy = dxy_test_displ,\n",
    "                         plot_colors = \"seagreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83027a",
   "metadata": {},
   "source": [
    "### Part- V: Saving the trained pruned model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_pruning_module_support import saving_model\n",
    "\n",
    "pruned_models = [pruned_model_10,pruned_model_20, pruned_model_30, pruned_model_40, pruned_model_50, pruned_model_60]\n",
    "\n",
    "for i in range(len(pruned_models)):\n",
    "    j = (i+1)*10\n",
    "    saving_model(model = pruned_models[i],\n",
    "                filepath = \"./models\",\n",
    "                model_filename = \"pruned_model_{}\".format(j) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
