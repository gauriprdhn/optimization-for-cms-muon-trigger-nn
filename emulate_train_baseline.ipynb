{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76497b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "1.3.4\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b742b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports \n",
    "import glob\n",
    "from nn_globals import *\n",
    "from nn_plotting import gaus, fit_gaus, corr_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e455ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_nan_in_x(x):\n",
    "    x[np.isnan(x)] = 0.0\n",
    "    x[x==-999.0] = 0.0\n",
    "    return x\n",
    "\n",
    "def _zero_out_x(x):\n",
    "    x = 0.0\n",
    "    return x\n",
    "    \n",
    "def _fixME1Ring(x):\n",
    "    for i in range(len(x)):\n",
    "        if (x[i,0] != 0.0): x[i,18] = x[i,18] + 1\n",
    "    return x   \n",
    "\n",
    "def muon_data(filename, reg_pt_scale=1.0, reg_dxy_scale=1.0, correct_for_eta=False):\n",
    "    try:\n",
    "        logger.info('Loading muon data from {0} ...'.format(filename))\n",
    "        loaded = np.load(filename)\n",
    "        the_variables = loaded['variables']\n",
    "        the_parameters = loaded['parameters']\n",
    "        # print(the_variables.shape)\n",
    "        the_variables = the_variables[:nentries]\n",
    "        the_parameters = the_parameters[:nentries]\n",
    "        logger.info('Loaded the variables with shape {0}'.format(the_variables.shape))\n",
    "        logger.info('Loaded the parameters with shape {0}'.format(the_parameters.shape))\n",
    "    except:\n",
    "        logger.error('Failed to load data from file: {0}'.format(filename))\n",
    "\n",
    "    assert(the_variables.shape[0] == the_parameters.shape[0])\n",
    "    _handle_nan_in_x(the_variables)\n",
    "      #_fixME1Ring(the_variables)\n",
    "    _handle_nan_in_x(the_parameters)\n",
    "    mask = np.logical_or(np.logical_or( np.logical_or((the_variables[:,23] == 11), (the_variables[:,23] == 13)), (the_variables[:,23] == 14)),(the_variables[:,23] == 15)) \n",
    "\n",
    "    the_variables = the_variables[mask]  \n",
    "    the_parameters = the_parameters[mask]  \n",
    "    assert(the_variables.shape[0] == the_parameters.shape[0])\n",
    "\n",
    "    x = the_variables[:,0:23]\n",
    "    y = reg_pt_scale*the_parameters[:,0]\n",
    "#    print (x[0:30,:], the_variables[0:30,23])\n",
    "#    print (y[0:30])\n",
    "    phi = the_parameters[:,1] \n",
    "    eta = the_parameters[:,2] \n",
    "    vx = the_parameters[:,3] \n",
    "    vy = the_parameters[:,4] \n",
    "    vz = the_parameters[:,5]      \n",
    "    dxy = vy * np.cos(phi) - vx * np.sin(phi) \n",
    "    logger.info('Loaded the encoded variables with shape {0}'.format(x.shape))\n",
    "    logger.info('Loaded the encoded parameters with shape {0}'.format(y.shape))\n",
    "\n",
    "    return x, y, dxy\n",
    "\n",
    "def muon_data_split(filename, reg_pt_scale=1.0, reg_dxy_scale=1.0, test_size=0.5, correct_for_eta=False):\n",
    "    x, y, dxy = muon_data(filename, reg_pt_scale=reg_pt_scale, reg_dxy_scale=reg_dxy_scale, correct_for_eta=correct_for_eta)\n",
    "\n",
    "    # Split dataset in training and testing\n",
    "    x_train, x_test, y_train, y_test, dxy_train, dxy_test = train_test_split(x, y, dxy, test_size=test_size)\n",
    "    logger.info('Loaded # of training and testing events: {0}'.format((x_train.shape[0], x_test.shape[0])))\n",
    "\n",
    "    # Check for cases where the number of events in the last batch could be too few\n",
    "    validation_split = 0.1\n",
    "    train_num_samples = int(x_train.shape[0] * (1.0-validation_split))\n",
    "    val_num_samples = x_train.shape[0] - train_num_samples\n",
    "    batch_size = 128\n",
    "    if (train_num_samples%batch_size) < 100:\n",
    "        logger.warning('The last batch for training could be too few! ({0}%{1})={2}. Please change test_size.'.format(train_num_samples, batch_size, train_num_samples%batch_size))\n",
    "        logger.warning('Try this formula: int(int({0}*{1})*{2}) % 128'.format(x.shape[0], 1.0-test_size, 1.0-validation_split))\n",
    "    train_num_samples = int(x_train.shape[0] * 2 * (1.0-validation_split))\n",
    "    val_num_samples = x_train.shape[0] - train_num_samples\n",
    "    batch_size = 128\n",
    "    if (train_num_samples%batch_size) < 100:\n",
    "        logger.warning('The last batch for training after mixing could be too few! ({0}%{1})={2}. Please change test_size.'.format(train_num_samples, batch_size, train_num_samples%batch_size))\n",
    "        logger.warning('Try this formula: int(int({0}*{1})*2*{2}) % 128'.format(x.shape[0], 1.0-test_size, 1.0-validation_split))\n",
    "    return x_train, x_test, y_train, y_test, dxy_train, dxy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be3d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading muon data from ./data/NN_input_params_FlatXYZ.npz ...\n",
      "[INFO    ] Loaded the variables with shape (19300000, 25)\n",
      "[INFO    ] Loaded the parameters with shape (19300000, 6)\n",
      "[INFO    ] Loaded the encoded variables with shape (3284620, 23)\n",
      "[INFO    ] Loaded the encoded parameters with shape (3284620,)\n",
      "[INFO    ] Loaded # of training and testing events: (2249964, 1034656)\n",
      "[WARNING ] The last batch for training could be too few! (2024967%128)=7. Please change test_size.\n",
      "[WARNING ] Try this formula: int(int(3284620*0.685)*0.9) % 128\n",
      "[WARNING ] The last batch for training after mixing could be too few! (4049935%128)=15. Please change test_size.\n",
      "[WARNING ] Try this formula: int(int(3284620*0.685)*2*0.9) % 128\n"
     ]
    }
   ],
   "source": [
    "# Import muon data\n",
    "# 'x' is the array of input variables, 'y' is the q/pT\n",
    "x_train_displ, x_test_displ, y_train_displ, y_test_displ, dxy_train_displ, dxy_test_displ= muon_data_split(infile_muon_displ, \n",
    "                                                                                                           reg_pt_scale=reg_pt_scale, \n",
    "                                                                                                           reg_dxy_scale=reg_dxy_scale, \n",
    "                                                                                                           test_size=0.315)\n",
    "\n",
    "y_train_displ = np.abs(y_train_displ)\n",
    "y_test_displ = np.abs(y_test_displ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14f3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, BatchNormalization, Dense, Activation\n",
    "from nn_evaluate import huber_loss\n",
    "from nn_training import train_model, lr_schedule\n",
    "from keras.callbacks import LearningRateScheduler, TerminateOnNaN, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69e3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nvariables, lr=0.001, clipnorm=10., initializer = \"glorot_uniform\",\n",
    "                nodes1=64, nodes2=32, nodes3=16, outnodes=2,\n",
    "                l1_reg = 0.0, l2_reg = 0.0):\n",
    "  \n",
    "    regularizer = L1L2(l1=l1_reg, l2=l2_reg)\n",
    "    bn_momentum = 0.9\n",
    "    eps = 1e-4\n",
    "\n",
    "    x = x_in = Input((nvariables,))\n",
    "    x = BatchNormalization(epsilon=eps, momentum=bn_momentum,name=\"bn-input\")(x)\n",
    "    \n",
    "    x = Dense(nodes1, \n",
    "               kernel_initializer=initializer,\n",
    "               use_bias = False,\n",
    "               kernel_regularizer = regularizer,\n",
    "               name=\"hidden-dense-1\")(x)\n",
    "    x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-1\")(x)\n",
    "    x = Activation(activation = \"tanh\",name=\"act_1\")(x)\n",
    "    \n",
    "    if nodes2:\n",
    "    \n",
    "        x = Dense(nodes2, \n",
    "                   kernel_initializer=initializer,\n",
    "                   use_bias = False,\n",
    "                   kernel_regularizer = regularizer,\n",
    "                   name=\"hidden-dense-2\")(x)\n",
    "        x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-2\")(x)\n",
    "        x = Activation(activation = \"tanh\",name=\"act_2\")(x)\n",
    "        if nodes3:\n",
    "\n",
    "            x = Dense(nodes3, \n",
    "                       kernel_initializer=initializer,\n",
    "                       kernel_regularizer = regularizer,\n",
    "                       use_bias = False,\n",
    "                       name=\"hidden-dense-3\")(x)\n",
    "            x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-3\")(x)\n",
    "            x = Activation(activation = \"tanh\", name=\"act_3\")(x)\n",
    "\n",
    "    x = Dense(outnodes,kernel_initializer = initializer,name=\"dense-output\")(x)\n",
    "    x = Activation(\"linear\")(x)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=x,name=\"baseline-model\")\n",
    "    \n",
    "    adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "    model.compile(optimizer=adam, \n",
    "                  loss=huber_loss, \n",
    "                  metrics=['acc','mse','mae'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c420cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 11:04:01.419570: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-14 11:04:01.420367: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/gpradhan/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "[INFO    ] Training model with l1_reg: 0.0 l2_reg: 0.0\n",
      "[INFO    ] Begin training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"baseline-model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "bn-input (BatchNormalization (None, 23)                92        \n",
      "_________________________________________________________________\n",
      "hidden-dense-1 (Dense)       (None, 20)                460       \n",
      "_________________________________________________________________\n",
      "bn-1 (BatchNormalization)    (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "act_1 (Activation)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "hidden-dense-2 (Dense)       (None, 15)                300       \n",
      "_________________________________________________________________\n",
      "bn-2 (BatchNormalization)    (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "act_2 (Activation)           (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "hidden-dense-3 (Dense)       (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "bn-3 (BatchNormalization)    (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "act_3 (Activation)           (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense-output (Dense)         (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,204\n",
      "Trainable params: 1,068\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 11:04:01.640755: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-14 11:04:01.643887: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.006300000008195639.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 11:04:01.994338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - ETA: 0s - loss: 28.5617 - acc: 0.8953 - mse: 1122.1554 - mae: 21.8892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 11:04:16.645959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 28.5617 - acc: 0.8953 - mse: 1122.1554 - mae: 21.8892 - val_loss: 17.9991 - val_acc: 0.9267 - val_mse: 478.2961 - val_mae: 14.0294\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 14.1489 - acc: 0.9360 - mse: 301.9149 - mae: 11.1632 - val_loss: 11.9997 - val_acc: 0.9348 - val_mse: 211.9298 - val_mae: 9.5627\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 11.2887 - acc: 0.9371 - mse: 189.6111 - mae: 9.0332 - val_loss: 10.8681 - val_acc: 0.9337 - val_mse: 174.2014 - val_mae: 8.7202\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.6227 - acc: 0.9379 - mse: 169.7215 - mae: 8.5365 - val_loss: 10.4941 - val_acc: 0.9385 - val_mse: 165.6372 - val_mae: 8.4403\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.3803 - acc: 0.9386 - mse: 163.8687 - mae: 8.3553 - val_loss: 10.2958 - val_acc: 0.9389 - val_mse: 162.1230 - val_mae: 8.2923\n",
      "\n",
      "Epoch 00005: saving model to checkpoints/model_ckpt_epoch_05.hdf5\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.2758 - acc: 0.9390 - mse: 161.6376 - mae: 8.2773 - val_loss: 10.1015 - val_acc: 0.9402 - val_mse: 157.7691 - val_mae: 8.1464\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.1869 - acc: 0.9392 - mse: 159.7421 - mae: 8.2107 - val_loss: 10.2808 - val_acc: 0.9382 - val_mse: 161.6332 - val_mae: 8.2805\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 10.1267 - acc: 0.9392 - mse: 158.6647 - mae: 8.1654 - val_loss: 10.0709 - val_acc: 0.9382 - val_mse: 156.7662 - val_mae: 8.1239\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.0793 - acc: 0.9392 - mse: 157.8756 - mae: 8.1298 - val_loss: 9.9743 - val_acc: 0.9396 - val_mse: 155.0921 - val_mae: 8.0508\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.0376 - acc: 0.9394 - mse: 157.0403 - mae: 8.0985 - val_loss: 10.0934 - val_acc: 0.9359 - val_mse: 156.3967 - val_mae: 8.1410\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/model_ckpt_epoch_10.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.005670000007376075.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.0057 - acc: 0.9395 - mse: 156.4166 - mae: 8.0746 - val_loss: 9.9882 - val_acc: 0.9374 - val_mse: 155.9521 - val_mae: 8.0624\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.9917 - acc: 0.9395 - mse: 156.0851 - mae: 8.0642 - val_loss: 9.9169 - val_acc: 0.9399 - val_mse: 153.2799 - val_mae: 8.0089\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 9.9692 - acc: 0.9396 - mse: 155.4931 - mae: 8.0473 - val_loss: 9.9240 - val_acc: 0.9398 - val_mse: 153.8891 - val_mae: 8.0129\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.9445 - acc: 0.9397 - mse: 154.9317 - mae: 8.0289 - val_loss: 9.8538 - val_acc: 0.9398 - val_mse: 152.8760 - val_mae: 7.9613\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.9391 - acc: 0.9397 - mse: 154.6739 - mae: 8.0248 - val_loss: 9.8093 - val_acc: 0.9399 - val_mse: 152.4763 - val_mae: 7.9275\n",
      "\n",
      "Epoch 00015: saving model to checkpoints/model_ckpt_epoch_15.hdf5\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.9171 - acc: 0.9398 - mse: 154.1092 - mae: 8.0083 - val_loss: 9.7736 - val_acc: 0.9412 - val_mse: 151.3063 - val_mae: 7.9002\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.9036 - acc: 0.9399 - mse: 153.8237 - mae: 7.9983 - val_loss: 9.8705 - val_acc: 0.9387 - val_mse: 152.4987 - val_mae: 7.9729\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8795 - acc: 0.9400 - mse: 153.2081 - mae: 7.9804 - val_loss: 9.7316 - val_acc: 0.9407 - val_mse: 149.8653 - val_mae: 7.8696\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.8747 - acc: 0.9401 - mse: 153.1464 - mae: 7.9767 - val_loss: 9.7758 - val_acc: 0.9400 - val_mse: 150.7096 - val_mae: 7.9025\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8668 - acc: 0.9399 - mse: 152.9936 - mae: 7.9707 - val_loss: 9.8415 - val_acc: 0.9411 - val_mse: 151.9136 - val_mae: 7.9519\n",
      "\n",
      "Epoch 00020: saving model to checkpoints/model_ckpt_epoch_20.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.00510299988090992.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8424 - acc: 0.9402 - mse: 152.4298 - mae: 7.9524 - val_loss: 9.7478 - val_acc: 0.9409 - val_mse: 150.2121 - val_mae: 7.8819\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8327 - acc: 0.9403 - mse: 152.2177 - mae: 7.9452 - val_loss: 9.7562 - val_acc: 0.9403 - val_mse: 150.1144 - val_mae: 7.8872\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8320 - acc: 0.9402 - mse: 152.2472 - mae: 7.9446 - val_loss: 9.6729 - val_acc: 0.9412 - val_mse: 148.6345 - val_mae: 7.8256\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8253 - acc: 0.9403 - mse: 152.2230 - mae: 7.9395 - val_loss: 9.7517 - val_acc: 0.9408 - val_mse: 150.1593 - val_mae: 7.8844\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8127 - acc: 0.9405 - mse: 151.8430 - mae: 7.9301 - val_loss: 9.7385 - val_acc: 0.9397 - val_mse: 149.5386 - val_mae: 7.8742\n",
      "\n",
      "Epoch 00025: saving model to checkpoints/model_ckpt_epoch_25.hdf5\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8177 - acc: 0.9404 - mse: 151.9721 - mae: 7.9339 - val_loss: 9.6925 - val_acc: 0.9413 - val_mse: 148.4207 - val_mae: 7.8396\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8158 - acc: 0.9404 - mse: 151.9176 - mae: 7.9323 - val_loss: 9.8305 - val_acc: 0.9372 - val_mse: 150.5382 - val_mae: 7.9441\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8045 - acc: 0.9403 - mse: 151.6717 - mae: 7.9239 - val_loss: 9.7384 - val_acc: 0.9407 - val_mse: 149.4507 - val_mae: 7.8748\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8048 - acc: 0.9403 - mse: 151.7467 - mae: 7.9243 - val_loss: 9.6621 - val_acc: 0.9403 - val_mse: 148.1670 - val_mae: 7.8171\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.8059 - acc: 0.9403 - mse: 151.6903 - mae: 7.9250 - val_loss: 9.7017 - val_acc: 0.9414 - val_mse: 149.7773 - val_mae: 7.8465\n",
      "\n",
      "Epoch 00030: saving model to checkpoints/model_ckpt_epoch_30.hdf5\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.004592699976637959.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7814 - acc: 0.9405 - mse: 151.1978 - mae: 7.9067 - val_loss: 9.6740 - val_acc: 0.9412 - val_mse: 149.2065 - val_mae: 7.8262\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7894 - acc: 0.9404 - mse: 151.3992 - mae: 7.9126 - val_loss: 9.6730 - val_acc: 0.9408 - val_mse: 148.4598 - val_mae: 7.8250\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7861 - acc: 0.9405 - mse: 151.3307 - mae: 7.9102 - val_loss: 9.6397 - val_acc: 0.9412 - val_mse: 148.5138 - val_mae: 7.8001\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7809 - acc: 0.9405 - mse: 151.2128 - mae: 7.9064 - val_loss: 9.6865 - val_acc: 0.9409 - val_mse: 148.8338 - val_mae: 7.8356\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7792 - acc: 0.9405 - mse: 151.1011 - mae: 7.9051 - val_loss: 9.7557 - val_acc: 0.9400 - val_mse: 149.1187 - val_mae: 7.8871\n",
      "\n",
      "Epoch 00035: saving model to checkpoints/model_ckpt_epoch_35.hdf5\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7845 - acc: 0.9405 - mse: 151.3101 - mae: 7.9090 - val_loss: 9.6583 - val_acc: 0.9411 - val_mse: 148.8978 - val_mae: 7.8140\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7772 - acc: 0.9405 - mse: 151.1384 - mae: 7.9036 - val_loss: 9.6418 - val_acc: 0.9414 - val_mse: 148.4836 - val_mae: 7.8015\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.7677 - acc: 0.9405 - mse: 150.9412 - mae: 7.8964 - val_loss: 9.7293 - val_acc: 0.9403 - val_mse: 150.3274 - val_mae: 7.8671\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7684 - acc: 0.9405 - mse: 150.9468 - mae: 7.8969 - val_loss: 9.6600 - val_acc: 0.9414 - val_mse: 148.5672 - val_mae: 7.8150\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.7678 - acc: 0.9406 - mse: 150.9462 - mae: 7.8965 - val_loss: 9.7345 - val_acc: 0.9411 - val_mse: 151.7770 - val_mae: 7.8706\n",
      "\n",
      "Epoch 00040: saving model to checkpoints/model_ckpt_epoch_40.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.004133429937064648.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 9.7621 - acc: 0.9405 - mse: 150.8457 - mae: 7.8922 - val_loss: 9.6456 - val_acc: 0.9412 - val_mse: 147.6765 - val_mae: 7.8048\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 9.7560 - acc: 0.9407 - mse: 150.7156 - mae: 7.8876 - val_loss: 9.6086 - val_acc: 0.9414 - val_mse: 147.3261 - val_mae: 7.7770\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.7607 - acc: 0.9407 - mse: 150.7006 - mae: 7.8912 - val_loss: 9.7139 - val_acc: 0.9408 - val_mse: 148.9496 - val_mae: 7.8556\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.7572 - acc: 0.9407 - mse: 150.6805 - mae: 7.8886 - val_loss: 9.6092 - val_acc: 0.9407 - val_mse: 146.9988 - val_mae: 7.7778\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.7584 - acc: 0.9407 - mse: 150.7478 - mae: 7.8893 - val_loss: 9.6566 - val_acc: 0.9408 - val_mse: 147.6470 - val_mae: 7.8122\n",
      "\n",
      "Epoch 00045: saving model to checkpoints/model_ckpt_epoch_45.hdf5\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7511 - acc: 0.9407 - mse: 150.5685 - mae: 7.8838 - val_loss: 9.6197 - val_acc: 0.9412 - val_mse: 147.7793 - val_mae: 7.7851\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7569 - acc: 0.9405 - mse: 150.7049 - mae: 7.8882 - val_loss: 9.6695 - val_acc: 0.9408 - val_mse: 147.6633 - val_mae: 7.8224\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7562 - acc: 0.9405 - mse: 150.5971 - mae: 7.8878 - val_loss: 9.6989 - val_acc: 0.9410 - val_mse: 149.2599 - val_mae: 7.8445\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7513 - acc: 0.9405 - mse: 150.5694 - mae: 7.8842 - val_loss: 9.5945 - val_acc: 0.9413 - val_mse: 146.6831 - val_mae: 7.7667\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7481 - acc: 0.9407 - mse: 150.4887 - mae: 7.8816 - val_loss: 9.6708 - val_acc: 0.9405 - val_mse: 148.3586 - val_mae: 7.8235\n",
      "\n",
      "Epoch 00050: saving model to checkpoints/model_ckpt_epoch_50.hdf5\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0037200868595391513.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7334 - acc: 0.9408 - mse: 150.2367 - mae: 7.8706 - val_loss: 9.6051 - val_acc: 0.9414 - val_mse: 147.7135 - val_mae: 7.7743\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7392 - acc: 0.9407 - mse: 150.3162 - mae: 7.8750 - val_loss: 9.6104 - val_acc: 0.9409 - val_mse: 147.3030 - val_mae: 7.7786\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7375 - acc: 0.9407 - mse: 150.3039 - mae: 7.8737 - val_loss: 9.6208 - val_acc: 0.9409 - val_mse: 148.3858 - val_mae: 7.7857\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.7381 - acc: 0.9408 - mse: 150.3158 - mae: 7.8741 - val_loss: 9.6231 - val_acc: 0.9410 - val_mse: 148.5537 - val_mae: 7.7874\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7273 - acc: 0.9408 - mse: 150.1045 - mae: 7.8661 - val_loss: 9.5900 - val_acc: 0.9417 - val_mse: 146.9989 - val_mae: 7.7630\n",
      "\n",
      "Epoch 00055: saving model to checkpoints/model_ckpt_epoch_55.hdf5\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.7385 - acc: 0.9408 - mse: 150.2822 - mae: 7.8745 - val_loss: 9.5884 - val_acc: 0.9413 - val_mse: 146.8776 - val_mae: 7.7616\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7390 - acc: 0.9407 - mse: 150.3123 - mae: 7.8749 - val_loss: 9.6192 - val_acc: 0.9407 - val_mse: 147.2691 - val_mae: 7.7846\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.7244 - acc: 0.9408 - mse: 150.0271 - mae: 7.8639 - val_loss: 9.6330 - val_acc: 0.9402 - val_mse: 147.4021 - val_mae: 7.7950\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7310 - acc: 0.9408 - mse: 150.1151 - mae: 7.8688 - val_loss: 9.5962 - val_acc: 0.9408 - val_mse: 147.2738 - val_mae: 7.7678\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7269 - acc: 0.9408 - mse: 150.1040 - mae: 7.8657 - val_loss: 9.5874 - val_acc: 0.9416 - val_mse: 147.1038 - val_mae: 7.7609\n",
      "\n",
      "Epoch 00060: saving model to checkpoints/model_ckpt_epoch_60.hdf5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0033480780897662044.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7271 - acc: 0.9408 - mse: 150.0563 - mae: 7.8660 - val_loss: 9.6209 - val_acc: 0.9405 - val_mse: 146.6589 - val_mae: 7.7866\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.7248 - acc: 0.9408 - mse: 150.0373 - mae: 7.8643 - val_loss: 9.5947 - val_acc: 0.9404 - val_mse: 147.2496 - val_mae: 7.7664\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7215 - acc: 0.9409 - mse: 149.9408 - mae: 7.8617 - val_loss: 9.6582 - val_acc: 0.9408 - val_mse: 148.4793 - val_mae: 7.8137\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7282 - acc: 0.9407 - mse: 150.1324 - mae: 7.8667 - val_loss: 9.5614 - val_acc: 0.9413 - val_mse: 146.3882 - val_mae: 7.7417\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7206 - acc: 0.9408 - mse: 149.8919 - mae: 7.8610 - val_loss: 9.6002 - val_acc: 0.9409 - val_mse: 147.1426 - val_mae: 7.7701\n",
      "\n",
      "Epoch 00065: saving model to checkpoints/model_ckpt_epoch_65.hdf5\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7152 - acc: 0.9409 - mse: 149.7868 - mae: 7.8569 - val_loss: 9.5889 - val_acc: 0.9413 - val_mse: 146.7995 - val_mae: 7.7618\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7160 - acc: 0.9408 - mse: 149.8620 - mae: 7.8576 - val_loss: 9.6569 - val_acc: 0.9402 - val_mse: 147.5353 - val_mae: 7.8129\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7165 - acc: 0.9408 - mse: 149.8374 - mae: 7.8579 - val_loss: 9.5947 - val_acc: 0.9408 - val_mse: 146.8055 - val_mae: 7.7664\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7193 - acc: 0.9408 - mse: 149.8849 - mae: 7.8600 - val_loss: 9.6321 - val_acc: 0.9415 - val_mse: 148.0786 - val_mae: 7.7947\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7206 - acc: 0.9407 - mse: 149.8932 - mae: 7.8610 - val_loss: 9.6518 - val_acc: 0.9418 - val_mse: 149.2420 - val_mae: 7.8094\n",
      "\n",
      "Epoch 00070: saving model to checkpoints/model_ckpt_epoch_70.hdf5\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.003013270301744342.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7075 - acc: 0.9409 - mse: 149.6234 - mae: 7.8513 - val_loss: 9.5973 - val_acc: 0.9410 - val_mse: 147.2478 - val_mae: 7.7682\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7145 - acc: 0.9408 - mse: 149.7803 - mae: 7.8564 - val_loss: 9.5587 - val_acc: 0.9410 - val_mse: 146.4395 - val_mae: 7.7399\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7067 - acc: 0.9409 - mse: 149.6478 - mae: 7.8507 - val_loss: 9.6872 - val_acc: 0.9392 - val_mse: 148.0346 - val_mae: 7.8358\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7028 - acc: 0.9409 - mse: 149.5418 - mae: 7.8476 - val_loss: 9.5662 - val_acc: 0.9417 - val_mse: 146.5666 - val_mae: 7.7448\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7086 - acc: 0.9408 - mse: 149.7106 - mae: 7.8519 - val_loss: 9.5923 - val_acc: 0.9409 - val_mse: 146.9763 - val_mae: 7.7646\n",
      "\n",
      "Epoch 00075: saving model to checkpoints/model_ckpt_epoch_75.hdf5\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7052 - acc: 0.9409 - mse: 149.5583 - mae: 7.8495 - val_loss: 9.5744 - val_acc: 0.9412 - val_mse: 146.8189 - val_mae: 7.7510\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7075 - acc: 0.9409 - mse: 149.6427 - mae: 7.8512 - val_loss: 9.5761 - val_acc: 0.9415 - val_mse: 146.5116 - val_mae: 7.7522\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7060 - acc: 0.9409 - mse: 149.6158 - mae: 7.8500 - val_loss: 9.5845 - val_acc: 0.9419 - val_mse: 147.5877 - val_mae: 7.7583\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7093 - acc: 0.9409 - mse: 149.7371 - mae: 7.8525 - val_loss: 9.5650 - val_acc: 0.9414 - val_mse: 146.9231 - val_mae: 7.7438\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6971 - acc: 0.9409 - mse: 149.4927 - mae: 7.8434 - val_loss: 9.5798 - val_acc: 0.9411 - val_mse: 146.6771 - val_mae: 7.7552\n",
      "\n",
      "Epoch 00080: saving model to checkpoints/model_ckpt_epoch_80.hdf5\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.002711943187750876.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7055 - acc: 0.9409 - mse: 149.5847 - mae: 7.8497 - val_loss: 9.5939 - val_acc: 0.9410 - val_mse: 147.3500 - val_mae: 7.7658\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.002711943117901683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7014 - acc: 0.9409 - mse: 149.5466 - mae: 7.8466 - val_loss: 9.5633 - val_acc: 0.9414 - val_mse: 146.6685 - val_mae: 7.7432\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6947 - acc: 0.9410 - mse: 149.3762 - mae: 7.8416 - val_loss: 9.5684 - val_acc: 0.9415 - val_mse: 146.9379 - val_mae: 7.7464\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6968 - acc: 0.9409 - mse: 149.4258 - mae: 7.8431 - val_loss: 9.5665 - val_acc: 0.9412 - val_mse: 146.1598 - val_mae: 7.7454\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.7013 - acc: 0.9408 - mse: 149.4656 - mae: 7.8466 - val_loss: 9.6084 - val_acc: 0.9411 - val_mse: 147.7284 - val_mae: 7.7765\n",
      "\n",
      "Epoch 00085: saving model to checkpoints/model_ckpt_epoch_85.hdf5\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6990 - acc: 0.9409 - mse: 149.4038 - mae: 7.8448 - val_loss: 9.5521 - val_acc: 0.9413 - val_mse: 146.7270 - val_mae: 7.7345\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6950 - acc: 0.9409 - mse: 149.3247 - mae: 7.8419 - val_loss: 9.5654 - val_acc: 0.9415 - val_mse: 146.2192 - val_mae: 7.7449\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6948 - acc: 0.9409 - mse: 149.3696 - mae: 7.8417 - val_loss: 9.5550 - val_acc: 0.9414 - val_mse: 146.3493 - val_mae: 7.7366\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6917 - acc: 0.9411 - mse: 149.2931 - mae: 7.8393 - val_loss: 9.5533 - val_acc: 0.9415 - val_mse: 146.2245 - val_mae: 7.7357\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6982 - acc: 0.9409 - mse: 149.4296 - mae: 7.8443 - val_loss: 9.5804 - val_acc: 0.9409 - val_mse: 147.3603 - val_mae: 7.7553\n",
      "\n",
      "Epoch 00090: saving model to checkpoints/model_ckpt_epoch_90.hdf5\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0024407488061115147.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6936 - acc: 0.9409 - mse: 149.3314 - mae: 7.8407 - val_loss: 9.5816 - val_acc: 0.9410 - val_mse: 146.4862 - val_mae: 7.7566\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6832 - acc: 0.9410 - mse: 149.1769 - mae: 7.8330 - val_loss: 9.5435 - val_acc: 0.9414 - val_mse: 146.4147 - val_mae: 7.7279\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6907 - acc: 0.9410 - mse: 149.2800 - mae: 7.8386 - val_loss: 9.5616 - val_acc: 0.9412 - val_mse: 146.1079 - val_mae: 7.7417\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6953 - acc: 0.9409 - mse: 149.3946 - mae: 7.8421 - val_loss: 9.5782 - val_acc: 0.9417 - val_mse: 146.1159 - val_mae: 7.7537\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6867 - acc: 0.9410 - mse: 149.2062 - mae: 7.8357 - val_loss: 9.5673 - val_acc: 0.9409 - val_mse: 146.1793 - val_mae: 7.7458\n",
      "\n",
      "Epoch 00095: saving model to checkpoints/model_ckpt_epoch_95.hdf5\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6867 - acc: 0.9409 - mse: 149.1789 - mae: 7.8355 - val_loss: 9.6450 - val_acc: 0.9396 - val_mse: 147.0477 - val_mae: 7.8045\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6941 - acc: 0.9409 - mse: 149.3044 - mae: 7.8411 - val_loss: 9.5374 - val_acc: 0.9414 - val_mse: 145.9500 - val_mae: 7.7234\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6830 - acc: 0.9409 - mse: 149.1089 - mae: 7.8328 - val_loss: 9.5408 - val_acc: 0.9417 - val_mse: 146.2063 - val_mae: 7.7260\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6878 - acc: 0.9409 - mse: 149.1962 - mae: 7.8363 - val_loss: 9.5604 - val_acc: 0.9416 - val_mse: 146.8457 - val_mae: 7.7406\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6844 - acc: 0.9410 - mse: 149.0882 - mae: 7.8339 - val_loss: 9.5751 - val_acc: 0.9416 - val_mse: 146.9607 - val_mae: 7.7516\n",
      "\n",
      "Epoch 00100: saving model to checkpoints/model_ckpt_epoch_100.hdf5\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0021966738626360894.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6911 - acc: 0.9409 - mse: 149.2124 - mae: 7.8388 - val_loss: 9.5844 - val_acc: 0.9415 - val_mse: 146.5647 - val_mae: 7.7584\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6850 - acc: 0.9409 - mse: 149.1557 - mae: 7.8343 - val_loss: 9.5523 - val_acc: 0.9416 - val_mse: 147.3451 - val_mae: 7.7343\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6815 - acc: 0.9410 - mse: 149.0598 - mae: 7.8317 - val_loss: 9.6034 - val_acc: 0.9406 - val_mse: 146.5975 - val_mae: 7.7727\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6831 - acc: 0.9410 - mse: 149.1075 - mae: 7.8328 - val_loss: 9.5332 - val_acc: 0.9418 - val_mse: 146.1781 - val_mae: 7.7202\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6830 - acc: 0.9411 - mse: 149.0679 - mae: 7.8328 - val_loss: 9.5509 - val_acc: 0.9412 - val_mse: 145.8781 - val_mae: 7.7340\n",
      "\n",
      "Epoch 00105: saving model to checkpoints/model_ckpt_epoch_105.hdf5\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6783 - acc: 0.9411 - mse: 148.9982 - mae: 7.8292 - val_loss: 9.5913 - val_acc: 0.9417 - val_mse: 147.3960 - val_mae: 7.7640\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6756 - acc: 0.9410 - mse: 148.9643 - mae: 7.8273 - val_loss: 9.5522 - val_acc: 0.9415 - val_mse: 145.8754 - val_mae: 7.7344\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6768 - acc: 0.9410 - mse: 148.9678 - mae: 7.8282 - val_loss: 9.5543 - val_acc: 0.9417 - val_mse: 146.0939 - val_mae: 7.7359\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6833 - acc: 0.9411 - mse: 149.1032 - mae: 7.8331 - val_loss: 9.5294 - val_acc: 0.9416 - val_mse: 145.9834 - val_mae: 7.7173\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6843 - acc: 0.9410 - mse: 149.0656 - mae: 7.8339 - val_loss: 9.5566 - val_acc: 0.9414 - val_mse: 146.4494 - val_mae: 7.7376\n",
      "\n",
      "Epoch 00110: saving model to checkpoints/model_ckpt_epoch_110.hdf5\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.001977006392553449.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6782 - acc: 0.9410 - mse: 148.9617 - mae: 7.8293 - val_loss: 9.5342 - val_acc: 0.9414 - val_mse: 145.6819 - val_mae: 7.7208\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6791 - acc: 0.9410 - mse: 149.0148 - mae: 7.8299 - val_loss: 9.5728 - val_acc: 0.9404 - val_mse: 146.4770 - val_mae: 7.7499\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6739 - acc: 0.9411 - mse: 148.8799 - mae: 7.8259 - val_loss: 9.5946 - val_acc: 0.9403 - val_mse: 146.3708 - val_mae: 7.7666\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6794 - acc: 0.9410 - mse: 148.9725 - mae: 7.8302 - val_loss: 9.5498 - val_acc: 0.9418 - val_mse: 146.2629 - val_mae: 7.7325\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6754 - acc: 0.9410 - mse: 148.9035 - mae: 7.8272 - val_loss: 9.5679 - val_acc: 0.9414 - val_mse: 146.0771 - val_mae: 7.7462\n",
      "\n",
      "Epoch 00115: saving model to checkpoints/model_ckpt_epoch_115.hdf5\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6753 - acc: 0.9410 - mse: 148.8124 - mae: 7.8271 - val_loss: 9.5338 - val_acc: 0.9416 - val_mse: 146.1106 - val_mae: 7.7209\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6701 - acc: 0.9411 - mse: 148.7660 - mae: 7.8232 - val_loss: 9.5252 - val_acc: 0.9414 - val_mse: 145.4888 - val_mae: 7.7145\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6781 - acc: 0.9411 - mse: 148.9288 - mae: 7.8292 - val_loss: 9.5428 - val_acc: 0.9417 - val_mse: 146.3311 - val_mae: 7.7276\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6675 - acc: 0.9410 - mse: 148.7419 - mae: 7.8212 - val_loss: 9.5767 - val_acc: 0.9404 - val_mse: 146.2870 - val_mae: 7.7526\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6675 - acc: 0.9412 - mse: 148.7763 - mae: 7.8212 - val_loss: 9.5272 - val_acc: 0.9416 - val_mse: 145.6852 - val_mae: 7.7157\n",
      "\n",
      "Epoch 00120: saving model to checkpoints/model_ckpt_epoch_120.hdf5\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0017793057952076197.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6657 - acc: 0.9410 - mse: 148.6678 - mae: 7.8200 - val_loss: 9.5263 - val_acc: 0.9414 - val_mse: 145.7949 - val_mae: 7.7151\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6645 - acc: 0.9411 - mse: 148.6730 - mae: 7.8190 - val_loss: 9.5538 - val_acc: 0.9419 - val_mse: 146.7020 - val_mae: 7.7357\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6708 - acc: 0.9410 - mse: 148.8043 - mae: 7.8236 - val_loss: 9.5347 - val_acc: 0.9412 - val_mse: 145.8317 - val_mae: 7.7216\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6687 - acc: 0.9410 - mse: 148.7172 - mae: 7.8221 - val_loss: 9.5371 - val_acc: 0.9415 - val_mse: 145.6522 - val_mae: 7.7234\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6619 - acc: 0.9411 - mse: 148.6545 - mae: 7.8170 - val_loss: 9.5478 - val_acc: 0.9411 - val_mse: 146.6800 - val_mae: 7.7309\n",
      "\n",
      "Epoch 00125: saving model to checkpoints/model_ckpt_epoch_125.hdf5\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6708 - acc: 0.9411 - mse: 148.8201 - mae: 7.8237 - val_loss: 9.5670 - val_acc: 0.9408 - val_mse: 145.8918 - val_mae: 7.7462\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6720 - acc: 0.9410 - mse: 148.8115 - mae: 7.8246 - val_loss: 9.5341 - val_acc: 0.9419 - val_mse: 146.2035 - val_mae: 7.7207\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6640 - acc: 0.9411 - mse: 148.6498 - mae: 7.8185 - val_loss: 9.5368 - val_acc: 0.9413 - val_mse: 146.6544 - val_mae: 7.7225\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6735 - acc: 0.9411 - mse: 148.8394 - mae: 7.8258 - val_loss: 9.5318 - val_acc: 0.9414 - val_mse: 145.8625 - val_mae: 7.7191\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6550 - acc: 0.9412 - mse: 148.4674 - mae: 7.8118 - val_loss: 9.5285 - val_acc: 0.9414 - val_mse: 145.7662 - val_mae: 7.7166\n",
      "\n",
      "Epoch 00130: saving model to checkpoints/model_ckpt_epoch_130.hdf5\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6601 - acc: 0.9412 - mse: 148.5239 - mae: 7.8155 - val_loss: 9.5366 - val_acc: 0.9416 - val_mse: 145.7813 - val_mae: 7.7228\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6586 - acc: 0.9412 - mse: 148.5438 - mae: 7.8144 - val_loss: 9.5445 - val_acc: 0.9412 - val_mse: 146.2408 - val_mae: 7.7284\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6682 - acc: 0.9409 - mse: 148.6955 - mae: 7.8217 - val_loss: 9.5345 - val_acc: 0.9418 - val_mse: 146.0337 - val_mae: 7.7211\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6642 - acc: 0.9411 - mse: 148.6415 - mae: 7.8188 - val_loss: 9.5335 - val_acc: 0.9416 - val_mse: 145.7616 - val_mae: 7.7206\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6558 - acc: 0.9412 - mse: 148.5166 - mae: 7.8124 - val_loss: 9.5261 - val_acc: 0.9416 - val_mse: 145.3150 - val_mae: 7.7152\n",
      "\n",
      "Epoch 00135: saving model to checkpoints/model_ckpt_epoch_135.hdf5\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6659 - acc: 0.9410 - mse: 148.7106 - mae: 7.8200 - val_loss: 9.5505 - val_acc: 0.9406 - val_mse: 146.0802 - val_mae: 7.7336\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6550 - acc: 0.9412 - mse: 148.5093 - mae: 7.8118 - val_loss: 9.5257 - val_acc: 0.9416 - val_mse: 145.5788 - val_mae: 7.7145\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6586 - acc: 0.9413 - mse: 148.5374 - mae: 7.8145 - val_loss: 9.5240 - val_acc: 0.9414 - val_mse: 145.7069 - val_mae: 7.7132\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6585 - acc: 0.9412 - mse: 148.5202 - mae: 7.8144 - val_loss: 9.5436 - val_acc: 0.9410 - val_mse: 145.8990 - val_mae: 7.7279\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0016013751737773418.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6597 - acc: 0.9411 - mse: 148.5370 - mae: 7.8154 - val_loss: 9.5496 - val_acc: 0.9414 - val_mse: 145.9278 - val_mae: 7.7329\n",
      "\n",
      "Epoch 00140: saving model to checkpoints/model_ckpt_epoch_140.hdf5\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.0014412376563996078.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6583 - acc: 0.9410 - mse: 148.5115 - mae: 7.8143 - val_loss: 9.5245 - val_acc: 0.9412 - val_mse: 145.6113 - val_mae: 7.7137\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6581 - acc: 0.9412 - mse: 148.5132 - mae: 7.8141 - val_loss: 9.5414 - val_acc: 0.9410 - val_mse: 145.8191 - val_mae: 7.7264\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6553 - acc: 0.9411 - mse: 148.4640 - mae: 7.8120 - val_loss: 9.5221 - val_acc: 0.9415 - val_mse: 145.2472 - val_mae: 7.7117\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6561 - acc: 0.9412 - mse: 148.4524 - mae: 7.8126 - val_loss: 9.5159 - val_acc: 0.9414 - val_mse: 145.9129 - val_mae: 7.7071\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6590 - acc: 0.9411 - mse: 148.5400 - mae: 7.8149 - val_loss: 9.5287 - val_acc: 0.9416 - val_mse: 145.7154 - val_mae: 7.7167\n",
      "\n",
      "Epoch 00145: saving model to checkpoints/model_ckpt_epoch_145.hdf5\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6615 - acc: 0.9412 - mse: 148.5757 - mae: 7.8167 - val_loss: 9.5360 - val_acc: 0.9414 - val_mse: 146.2455 - val_mae: 7.7225\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6550 - acc: 0.9411 - mse: 148.3741 - mae: 7.8119 - val_loss: 9.5258 - val_acc: 0.9416 - val_mse: 145.7673 - val_mae: 7.7147\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6558 - acc: 0.9411 - mse: 148.5159 - mae: 7.8124 - val_loss: 9.5272 - val_acc: 0.9415 - val_mse: 145.9450 - val_mae: 7.7155\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6579 - acc: 0.9412 - mse: 148.5297 - mae: 7.8140 - val_loss: 9.5307 - val_acc: 0.9419 - val_mse: 145.6177 - val_mae: 7.7182\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0014412376331165433.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6549 - acc: 0.9411 - mse: 148.4904 - mae: 7.8117 - val_loss: 9.5276 - val_acc: 0.9415 - val_mse: 145.9446 - val_mae: 7.7160\n",
      "\n",
      "Epoch 00150: saving model to checkpoints/model_ckpt_epoch_150.hdf5\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.001297113869804889.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6553 - acc: 0.9411 - mse: 148.4724 - mae: 7.8121 - val_loss: 9.5170 - val_acc: 0.9414 - val_mse: 145.5738 - val_mae: 7.7082\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6543 - acc: 0.9412 - mse: 148.4357 - mae: 7.8113 - val_loss: 9.5404 - val_acc: 0.9415 - val_mse: 145.9373 - val_mae: 7.7253\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6506 - acc: 0.9412 - mse: 148.3688 - mae: 7.8085 - val_loss: 9.5276 - val_acc: 0.9417 - val_mse: 146.4787 - val_mae: 7.7159\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6548 - acc: 0.9411 - mse: 148.4342 - mae: 7.8117 - val_loss: 9.5150 - val_acc: 0.9416 - val_mse: 145.8348 - val_mae: 7.7065\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6489 - acc: 0.9412 - mse: 148.2950 - mae: 7.8073 - val_loss: 9.5232 - val_acc: 0.9416 - val_mse: 145.6915 - val_mae: 7.7126\n",
      "\n",
      "Epoch 00155: saving model to checkpoints/model_ckpt_epoch_155.hdf5\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6518 - acc: 0.9411 - mse: 148.3887 - mae: 7.8094 - val_loss: 9.5170 - val_acc: 0.9418 - val_mse: 145.8921 - val_mae: 7.7081\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6493 - acc: 0.9411 - mse: 148.3563 - mae: 7.8075 - val_loss: 9.5180 - val_acc: 0.9414 - val_mse: 145.8059 - val_mae: 7.7088\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6564 - acc: 0.9412 - mse: 148.4712 - mae: 7.8129 - val_loss: 9.5295 - val_acc: 0.9417 - val_mse: 146.2310 - val_mae: 7.7173\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6543 - acc: 0.9412 - mse: 148.4164 - mae: 7.8113 - val_loss: 9.5132 - val_acc: 0.9414 - val_mse: 145.4623 - val_mae: 7.7051\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.0012971138348802924.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6469 - acc: 0.9412 - mse: 148.2977 - mae: 7.8058 - val_loss: 9.5104 - val_acc: 0.9419 - val_mse: 145.7284 - val_mae: 7.7032\n",
      "\n",
      "Epoch 00160: saving model to checkpoints/model_ckpt_epoch_160.hdf5\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0011674024513922633.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6468 - acc: 0.9413 - mse: 148.2630 - mae: 7.8058 - val_loss: 9.5230 - val_acc: 0.9418 - val_mse: 145.3873 - val_mae: 7.7131\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6528 - acc: 0.9413 - mse: 148.3690 - mae: 7.8101 - val_loss: 9.5444 - val_acc: 0.9416 - val_mse: 145.8444 - val_mae: 7.7286\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6486 - acc: 0.9413 - mse: 148.2919 - mae: 7.8070 - val_loss: 9.5109 - val_acc: 0.9418 - val_mse: 145.5785 - val_mae: 7.7035\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6496 - acc: 0.9412 - mse: 148.3055 - mae: 7.8079 - val_loss: 9.5122 - val_acc: 0.9416 - val_mse: 145.6221 - val_mae: 7.7043\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6492 - acc: 0.9412 - mse: 148.3309 - mae: 7.8074 - val_loss: 9.5220 - val_acc: 0.9418 - val_mse: 145.4059 - val_mae: 7.7117\n",
      "\n",
      "Epoch 00165: saving model to checkpoints/model_ckpt_epoch_165.hdf5\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6487 - acc: 0.9411 - mse: 148.3255 - mae: 7.8071 - val_loss: 9.5070 - val_acc: 0.9416 - val_mse: 145.3405 - val_mae: 7.7005\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6523 - acc: 0.9411 - mse: 148.3172 - mae: 7.8098 - val_loss: 9.5203 - val_acc: 0.9416 - val_mse: 146.0029 - val_mae: 7.7103\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6444 - acc: 0.9412 - mse: 148.2336 - mae: 7.8039 - val_loss: 9.5111 - val_acc: 0.9418 - val_mse: 145.4660 - val_mae: 7.7036\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6540 - acc: 0.9411 - mse: 148.3581 - mae: 7.8111 - val_loss: 9.5165 - val_acc: 0.9415 - val_mse: 145.6538 - val_mae: 7.7076\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.0011674024863168597.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6491 - acc: 0.9411 - mse: 148.2807 - mae: 7.8074 - val_loss: 9.5522 - val_acc: 0.9417 - val_mse: 146.3847 - val_mae: 7.7347\n",
      "\n",
      "Epoch 00170: saving model to checkpoints/model_ckpt_epoch_170.hdf5\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.0010506622376851738.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6450 - acc: 0.9412 - mse: 148.2850 - mae: 7.8042 - val_loss: 9.5151 - val_acc: 0.9415 - val_mse: 145.7170 - val_mae: 7.7066\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6437 - acc: 0.9413 - mse: 148.2076 - mae: 7.8034 - val_loss: 9.5162 - val_acc: 0.9416 - val_mse: 145.4543 - val_mae: 7.7075\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6493 - acc: 0.9412 - mse: 148.2491 - mae: 7.8076 - val_loss: 9.5147 - val_acc: 0.9415 - val_mse: 145.4232 - val_mae: 7.7063\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6433 - acc: 0.9412 - mse: 148.2274 - mae: 7.8031 - val_loss: 9.5142 - val_acc: 0.9416 - val_mse: 145.0847 - val_mae: 7.7062\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6466 - acc: 0.9412 - mse: 148.2533 - mae: 7.8055 - val_loss: 9.5263 - val_acc: 0.9417 - val_mse: 146.0496 - val_mae: 7.7150\n",
      "\n",
      "Epoch 00175: saving model to checkpoints/model_ckpt_epoch_175.hdf5\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6487 - acc: 0.9412 - mse: 148.2736 - mae: 7.8071 - val_loss: 9.5242 - val_acc: 0.9419 - val_mse: 145.8091 - val_mae: 7.7135\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6469 - acc: 0.9412 - mse: 148.2589 - mae: 7.8057 - val_loss: 9.5197 - val_acc: 0.9417 - val_mse: 145.6635 - val_mae: 7.7102\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6448 - acc: 0.9412 - mse: 148.1803 - mae: 7.8042 - val_loss: 9.5172 - val_acc: 0.9414 - val_mse: 145.2576 - val_mae: 7.7082\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6393 - acc: 0.9412 - mse: 148.0639 - mae: 7.8000 - val_loss: 9.5215 - val_acc: 0.9416 - val_mse: 146.2158 - val_mae: 7.7112\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.001050662249326706.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6429 - acc: 0.9412 - mse: 148.2574 - mae: 7.8027 - val_loss: 9.5121 - val_acc: 0.9413 - val_mse: 145.6975 - val_mae: 7.7042\n",
      "\n",
      "Epoch 00180: saving model to checkpoints/model_ckpt_epoch_180.hdf5\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6420 - acc: 0.9413 - mse: 148.1397 - mae: 7.8020 - val_loss: 9.5090 - val_acc: 0.9417 - val_mse: 145.6008 - val_mae: 7.7020\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6534 - acc: 0.9412 - mse: 148.3372 - mae: 7.8107 - val_loss: 9.5272 - val_acc: 0.9419 - val_mse: 145.4834 - val_mae: 7.7157\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6432 - acc: 0.9412 - mse: 148.1553 - mae: 7.8030 - val_loss: 9.5227 - val_acc: 0.9419 - val_mse: 146.0139 - val_mae: 7.7123\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6416 - acc: 0.9413 - mse: 148.1709 - mae: 7.8018 - val_loss: 9.5208 - val_acc: 0.9419 - val_mse: 145.9968 - val_mae: 7.7108\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6420 - acc: 0.9411 - mse: 148.1551 - mae: 7.8021 - val_loss: 9.5051 - val_acc: 0.9418 - val_mse: 145.2402 - val_mae: 7.6989\n",
      "\n",
      "Epoch 00185: saving model to checkpoints/model_ckpt_epoch_185.hdf5\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6398 - acc: 0.9412 - mse: 148.1316 - mae: 7.8004 - val_loss: 9.5051 - val_acc: 0.9420 - val_mse: 145.3148 - val_mae: 7.6993\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6429 - acc: 0.9412 - mse: 148.1440 - mae: 7.8028 - val_loss: 9.5105 - val_acc: 0.9417 - val_mse: 145.2523 - val_mae: 7.7033\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6378 - acc: 0.9412 - mse: 148.0215 - mae: 7.7989 - val_loss: 9.5199 - val_acc: 0.9419 - val_mse: 145.5730 - val_mae: 7.7106\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6424 - acc: 0.9412 - mse: 148.1365 - mae: 7.8024 - val_loss: 9.5160 - val_acc: 0.9416 - val_mse: 146.0715 - val_mae: 7.7071\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.0009455960243940353.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6372 - acc: 0.9412 - mse: 147.9930 - mae: 7.7985 - val_loss: 9.5079 - val_acc: 0.9416 - val_mse: 145.2394 - val_mae: 7.7012\n",
      "\n",
      "Epoch 00190: saving model to checkpoints/model_ckpt_epoch_190.hdf5\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0008510364219546318.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6396 - acc: 0.9413 - mse: 148.1044 - mae: 7.8003 - val_loss: 9.5037 - val_acc: 0.9417 - val_mse: 145.5216 - val_mae: 7.6981\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6464 - acc: 0.9412 - mse: 148.1945 - mae: 7.8054 - val_loss: 9.5120 - val_acc: 0.9416 - val_mse: 145.6616 - val_mae: 7.7044\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6384 - acc: 0.9413 - mse: 148.0288 - mae: 7.7994 - val_loss: 9.5046 - val_acc: 0.9416 - val_mse: 145.4124 - val_mae: 7.6986\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6414 - acc: 0.9412 - mse: 148.1016 - mae: 7.8017 - val_loss: 9.5058 - val_acc: 0.9418 - val_mse: 145.4363 - val_mae: 7.6996\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 18s 17ms/step - loss: 9.6423 - acc: 0.9413 - mse: 148.1455 - mae: 7.8022 - val_loss: 9.5095 - val_acc: 0.9418 - val_mse: 145.5454 - val_mae: 7.7026\n",
      "\n",
      "Epoch 00195: saving model to checkpoints/model_ckpt_epoch_195.hdf5\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6354 - acc: 0.9413 - mse: 147.9846 - mae: 7.7971 - val_loss: 9.5047 - val_acc: 0.9417 - val_mse: 145.4875 - val_mae: 7.6987\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 9.6376 - acc: 0.9412 - mse: 148.0601 - mae: 7.7988 - val_loss: 9.5009 - val_acc: 0.9417 - val_mse: 145.2765 - val_mae: 7.6960\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6380 - acc: 0.9413 - mse: 148.0655 - mae: 7.7990 - val_loss: 9.5089 - val_acc: 0.9417 - val_mse: 145.3997 - val_mae: 7.7020\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6365 - acc: 0.9412 - mse: 148.0153 - mae: 7.7980 - val_loss: 9.5105 - val_acc: 0.9418 - val_mse: 145.6736 - val_mae: 7.7029\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.0008510363986715674.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6384 - acc: 0.9413 - mse: 148.1188 - mae: 7.7994 - val_loss: 9.5177 - val_acc: 0.9414 - val_mse: 145.3555 - val_mae: 7.7086\n",
      "\n",
      "Epoch 00200: saving model to checkpoints/model_ckpt_epoch_200.hdf5\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.0007659327588044107.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6394 - acc: 0.9413 - mse: 148.0018 - mae: 7.8000 - val_loss: 9.5157 - val_acc: 0.9419 - val_mse: 145.2371 - val_mae: 7.7073\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 18s 18ms/step - loss: 9.6435 - acc: 0.9412 - mse: 148.1798 - mae: 7.8033 - val_loss: 9.5092 - val_acc: 0.9415 - val_mse: 145.0903 - val_mae: 7.7023\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 18s 17ms/step - loss: 9.6334 - acc: 0.9412 - mse: 147.9589 - mae: 7.7957 - val_loss: 9.5033 - val_acc: 0.9416 - val_mse: 145.3111 - val_mae: 7.6976\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6360 - acc: 0.9412 - mse: 147.9736 - mae: 7.7976 - val_loss: 9.5086 - val_acc: 0.9418 - val_mse: 145.7437 - val_mae: 7.7018\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6330 - acc: 0.9413 - mse: 148.0111 - mae: 7.7953 - val_loss: 9.5005 - val_acc: 0.9418 - val_mse: 145.3494 - val_mae: 7.6958\n",
      "\n",
      "Epoch 00205: saving model to checkpoints/model_ckpt_epoch_205.hdf5\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6416 - acc: 0.9411 - mse: 148.1040 - mae: 7.8017 - val_loss: 9.5045 - val_acc: 0.9415 - val_mse: 145.3795 - val_mae: 7.6986\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 9.6360 - acc: 0.9413 - mse: 147.9911 - mae: 7.7976 - val_loss: 9.5046 - val_acc: 0.9416 - val_mse: 145.3501 - val_mae: 7.6986\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6356 - acc: 0.9413 - mse: 148.0228 - mae: 7.7973 - val_loss: 9.5117 - val_acc: 0.9413 - val_mse: 145.4356 - val_mae: 7.7038\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6356 - acc: 0.9413 - mse: 148.0103 - mae: 7.7973 - val_loss: 9.5096 - val_acc: 0.9416 - val_mse: 145.4012 - val_mae: 7.7023\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.0007659327820874751.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 9.6304 - acc: 0.9413 - mse: 147.9042 - mae: 7.7933 - val_loss: 9.4999 - val_acc: 0.9419 - val_mse: 145.3390 - val_mae: 7.6951\n",
      "\n",
      "Epoch 00210: saving model to checkpoints/model_ckpt_epoch_210.hdf5\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.0006893395038787276.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6357 - acc: 0.9412 - mse: 147.9920 - mae: 7.7974 - val_loss: 9.5040 - val_acc: 0.9416 - val_mse: 145.5233 - val_mae: 7.6982\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6334 - acc: 0.9413 - mse: 147.9798 - mae: 7.7957 - val_loss: 9.4986 - val_acc: 0.9419 - val_mse: 145.2081 - val_mae: 7.6943\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6334 - acc: 0.9413 - mse: 147.9898 - mae: 7.7956 - val_loss: 9.5099 - val_acc: 0.9419 - val_mse: 145.8798 - val_mae: 7.7026\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 9.6345 - acc: 0.9413 - mse: 147.9752 - mae: 7.7964 - val_loss: 9.5040 - val_acc: 0.9417 - val_mse: 145.3168 - val_mae: 7.6983\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6395 - acc: 0.9412 - mse: 148.1220 - mae: 7.8001 - val_loss: 9.5027 - val_acc: 0.9416 - val_mse: 145.3859 - val_mae: 7.6974\n",
      "\n",
      "Epoch 00215: saving model to checkpoints/model_ckpt_epoch_215.hdf5\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6363 - acc: 0.9414 - mse: 148.0266 - mae: 7.7978 - val_loss: 9.4995 - val_acc: 0.9417 - val_mse: 145.3048 - val_mae: 7.6950\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6314 - acc: 0.9413 - mse: 147.8996 - mae: 7.7941 - val_loss: 9.5021 - val_acc: 0.9417 - val_mse: 145.2330 - val_mae: 7.6968\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6325 - acc: 0.9413 - mse: 147.9567 - mae: 7.7950 - val_loss: 9.5036 - val_acc: 0.9417 - val_mse: 145.3361 - val_mae: 7.6980\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6325 - acc: 0.9413 - mse: 147.9649 - mae: 7.7949 - val_loss: 9.5014 - val_acc: 0.9418 - val_mse: 145.1622 - val_mae: 7.6960\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.0006893394747748971.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6342 - acc: 0.9413 - mse: 148.0131 - mae: 7.7961 - val_loss: 9.5042 - val_acc: 0.9417 - val_mse: 145.4645 - val_mae: 7.6983\n",
      "\n",
      "Epoch 00220: saving model to checkpoints/model_ckpt_epoch_220.hdf5\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.0006204055272974074.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6327 - acc: 0.9412 - mse: 147.9172 - mae: 7.7952 - val_loss: 9.5113 - val_acc: 0.9416 - val_mse: 145.1689 - val_mae: 7.7037\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6334 - acc: 0.9412 - mse: 147.9393 - mae: 7.7956 - val_loss: 9.5064 - val_acc: 0.9415 - val_mse: 145.1689 - val_mae: 7.7002\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6345 - acc: 0.9412 - mse: 147.9412 - mae: 7.7965 - val_loss: 9.4968 - val_acc: 0.9419 - val_mse: 145.2904 - val_mae: 7.6930\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6365 - acc: 0.9413 - mse: 148.0318 - mae: 7.7980 - val_loss: 9.4988 - val_acc: 0.9418 - val_mse: 145.2070 - val_mae: 7.6943\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6318 - acc: 0.9412 - mse: 147.9013 - mae: 7.7943 - val_loss: 9.5016 - val_acc: 0.9418 - val_mse: 145.6535 - val_mae: 7.6963\n",
      "\n",
      "Epoch 00225: saving model to checkpoints/model_ckpt_epoch_225.hdf5\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 9.6351 - acc: 0.9412 - mse: 147.9516 - mae: 7.7969 - val_loss: 9.5090 - val_acc: 0.9418 - val_mse: 145.7820 - val_mae: 7.7020\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6362 - acc: 0.9412 - mse: 148.0171 - mae: 7.7978 - val_loss: 9.5033 - val_acc: 0.9416 - val_mse: 145.5693 - val_mae: 7.6977\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6287 - acc: 0.9413 - mse: 147.9079 - mae: 7.7920 - val_loss: 9.5021 - val_acc: 0.9421 - val_mse: 145.4163 - val_mae: 7.6969\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6343 - acc: 0.9412 - mse: 147.9544 - mae: 7.7963 - val_loss: 9.5007 - val_acc: 0.9416 - val_mse: 145.3115 - val_mae: 7.6957\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.0006204055389389396.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6334 - acc: 0.9412 - mse: 148.0092 - mae: 7.7956 - val_loss: 9.5145 - val_acc: 0.9418 - val_mse: 145.3885 - val_mae: 7.7061\n",
      "\n",
      "Epoch 00230: saving model to checkpoints/model_ckpt_epoch_230.hdf5\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.0005583649850450456.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6343 - acc: 0.9413 - mse: 147.9290 - mae: 7.7963 - val_loss: 9.5046 - val_acc: 0.9416 - val_mse: 145.4719 - val_mae: 7.6986\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6305 - acc: 0.9412 - mse: 147.9462 - mae: 7.7934 - val_loss: 9.5046 - val_acc: 0.9416 - val_mse: 145.3371 - val_mae: 7.6989\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 9.6367 - acc: 0.9412 - mse: 148.0351 - mae: 7.7979 - val_loss: 9.5024 - val_acc: 0.9418 - val_mse: 145.5032 - val_mae: 7.6971\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6253 - acc: 0.9413 - mse: 147.8001 - mae: 7.7895 - val_loss: 9.5101 - val_acc: 0.9412 - val_mse: 145.3564 - val_mae: 7.7029\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6342 - acc: 0.9413 - mse: 148.0050 - mae: 7.7962 - val_loss: 9.4989 - val_acc: 0.9419 - val_mse: 145.4267 - val_mae: 7.6943\n",
      "\n",
      "Epoch 00235: saving model to checkpoints/model_ckpt_epoch_235.hdf5\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6365 - acc: 0.9413 - mse: 147.9699 - mae: 7.7980 - val_loss: 9.5024 - val_acc: 0.9413 - val_mse: 145.1270 - val_mae: 7.6970\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6375 - acc: 0.9413 - mse: 148.0388 - mae: 7.7986 - val_loss: 9.5059 - val_acc: 0.9420 - val_mse: 145.3087 - val_mae: 7.6997\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6294 - acc: 0.9414 - mse: 147.8668 - mae: 7.7926 - val_loss: 9.5002 - val_acc: 0.9415 - val_mse: 145.1885 - val_mae: 7.6954\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6319 - acc: 0.9412 - mse: 147.9092 - mae: 7.7945 - val_loss: 9.4961 - val_acc: 0.9419 - val_mse: 145.4109 - val_mae: 7.6922\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.0005583649617619812.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6308 - acc: 0.9413 - mse: 147.8374 - mae: 7.7936 - val_loss: 9.4995 - val_acc: 0.9418 - val_mse: 145.2281 - val_mae: 7.6948\n",
      "\n",
      "Epoch 00240: saving model to checkpoints/model_ckpt_epoch_240.hdf5\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.0005025284655857832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6328 - acc: 0.9413 - mse: 147.9243 - mae: 7.7952 - val_loss: 9.5182 - val_acc: 0.9419 - val_mse: 146.0038 - val_mae: 7.7089\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6262 - acc: 0.9413 - mse: 147.7965 - mae: 7.7903 - val_loss: 9.4964 - val_acc: 0.9420 - val_mse: 145.5180 - val_mae: 7.6925\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6275 - acc: 0.9413 - mse: 147.8139 - mae: 7.7911 - val_loss: 9.4959 - val_acc: 0.9415 - val_mse: 145.3020 - val_mae: 7.6921\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6231 - acc: 0.9414 - mse: 147.7374 - mae: 7.7878 - val_loss: 9.4975 - val_acc: 0.9419 - val_mse: 145.4284 - val_mae: 7.6934\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6245 - acc: 0.9412 - mse: 147.7811 - mae: 7.7889 - val_loss: 9.4967 - val_acc: 0.9418 - val_mse: 145.0746 - val_mae: 7.6928\n",
      "\n",
      "Epoch 00245: saving model to checkpoints/model_ckpt_epoch_245.hdf5\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6291 - acc: 0.9413 - mse: 147.8552 - mae: 7.7924 - val_loss: 9.5019 - val_acc: 0.9418 - val_mse: 145.7794 - val_mae: 7.6964\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6272 - acc: 0.9413 - mse: 147.8554 - mae: 7.7910 - val_loss: 9.5018 - val_acc: 0.9420 - val_mse: 145.2964 - val_mae: 7.6964\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6331 - acc: 0.9413 - mse: 147.9038 - mae: 7.7954 - val_loss: 9.5021 - val_acc: 0.9420 - val_mse: 145.4910 - val_mae: 7.6969\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6275 - acc: 0.9413 - mse: 147.8458 - mae: 7.7912 - val_loss: 9.5005 - val_acc: 0.9416 - val_mse: 145.3376 - val_mae: 7.6954\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.0005025284481234848.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6284 - acc: 0.9414 - mse: 147.8442 - mae: 7.7919 - val_loss: 9.4975 - val_acc: 0.9420 - val_mse: 145.5396 - val_mae: 7.6934\n",
      "\n",
      "Epoch 00250: saving model to checkpoints/model_ckpt_epoch_250.hdf5\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.0004522756033111364.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6275 - acc: 0.9413 - mse: 147.8418 - mae: 7.7911 - val_loss: 9.5034 - val_acc: 0.9420 - val_mse: 145.3214 - val_mae: 7.6978\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6307 - acc: 0.9413 - mse: 147.8674 - mae: 7.7937 - val_loss: 9.4953 - val_acc: 0.9417 - val_mse: 145.1535 - val_mae: 7.6917\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6217 - acc: 0.9415 - mse: 147.7304 - mae: 7.7869 - val_loss: 9.4928 - val_acc: 0.9420 - val_mse: 145.3421 - val_mae: 7.6898\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6280 - acc: 0.9414 - mse: 147.8512 - mae: 7.7915 - val_loss: 9.4983 - val_acc: 0.9419 - val_mse: 145.1944 - val_mae: 7.6941\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6229 - acc: 0.9413 - mse: 147.7553 - mae: 7.7878 - val_loss: 9.4971 - val_acc: 0.9417 - val_mse: 144.9682 - val_mae: 7.6932\n",
      "\n",
      "Epoch 00255: saving model to checkpoints/model_ckpt_epoch_255.hdf5\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6241 - acc: 0.9415 - mse: 147.7685 - mae: 7.7886 - val_loss: 9.4994 - val_acc: 0.9413 - val_mse: 145.2206 - val_mae: 7.6948\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6261 - acc: 0.9413 - mse: 147.7913 - mae: 7.7902 - val_loss: 9.4981 - val_acc: 0.9419 - val_mse: 145.3217 - val_mae: 7.6938\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6285 - acc: 0.9413 - mse: 147.8612 - mae: 7.7919 - val_loss: 9.4971 - val_acc: 0.9418 - val_mse: 145.1740 - val_mae: 7.6932\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6299 - acc: 0.9414 - mse: 147.8521 - mae: 7.7930 - val_loss: 9.4990 - val_acc: 0.9419 - val_mse: 145.5399 - val_mae: 7.6944\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.0004522755916696042.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6183 - acc: 0.9414 - mse: 147.7123 - mae: 7.7843 - val_loss: 9.5000 - val_acc: 0.9419 - val_mse: 145.1510 - val_mae: 7.6954\n",
      "\n",
      "Epoch 00260: saving model to checkpoints/model_ckpt_epoch_260.hdf5\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.0004070480325026438.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6323 - acc: 0.9413 - mse: 147.8863 - mae: 7.7948 - val_loss: 9.4947 - val_acc: 0.9418 - val_mse: 145.2502 - val_mae: 7.6912\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6251 - acc: 0.9414 - mse: 147.7930 - mae: 7.7895 - val_loss: 9.4969 - val_acc: 0.9418 - val_mse: 145.2021 - val_mae: 7.6931\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6277 - acc: 0.9414 - mse: 147.8301 - mae: 7.7913 - val_loss: 9.4956 - val_acc: 0.9420 - val_mse: 145.2995 - val_mae: 7.6920\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6233 - acc: 0.9413 - mse: 147.7637 - mae: 7.7880 - val_loss: 9.5045 - val_acc: 0.9420 - val_mse: 145.2940 - val_mae: 7.6989\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6288 - acc: 0.9413 - mse: 147.8533 - mae: 7.7922 - val_loss: 9.5016 - val_acc: 0.9418 - val_mse: 145.3394 - val_mae: 7.6967\n",
      "\n",
      "Epoch 00265: saving model to checkpoints/model_ckpt_epoch_265.hdf5\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6278 - acc: 0.9413 - mse: 147.8240 - mae: 7.7914 - val_loss: 9.4959 - val_acc: 0.9420 - val_mse: 145.0424 - val_mae: 7.6922\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6180 - acc: 0.9414 - mse: 147.6478 - mae: 7.7841 - val_loss: 9.4951 - val_acc: 0.9419 - val_mse: 145.1266 - val_mae: 7.6915\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6286 - acc: 0.9413 - mse: 147.8022 - mae: 7.7920 - val_loss: 9.4936 - val_acc: 0.9417 - val_mse: 145.0559 - val_mae: 7.6905\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6259 - acc: 0.9413 - mse: 147.7985 - mae: 7.7900 - val_loss: 9.5002 - val_acc: 0.9415 - val_mse: 145.0470 - val_mae: 7.6956\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.0004070480354130268.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6278 - acc: 0.9413 - mse: 147.8287 - mae: 7.7914 - val_loss: 9.4973 - val_acc: 0.9419 - val_mse: 145.1811 - val_mae: 7.6933\n",
      "\n",
      "Epoch 00270: saving model to checkpoints/model_ckpt_epoch_270.hdf5\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.0003663432318717241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6215 - acc: 0.9414 - mse: 147.7197 - mae: 7.7867 - val_loss: 9.5003 - val_acc: 0.9415 - val_mse: 145.1059 - val_mae: 7.6956\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6265 - acc: 0.9412 - mse: 147.7925 - mae: 7.7906 - val_loss: 9.4927 - val_acc: 0.9416 - val_mse: 145.1787 - val_mae: 7.6898\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6236 - acc: 0.9414 - mse: 147.7776 - mae: 7.7883 - val_loss: 9.4993 - val_acc: 0.9414 - val_mse: 145.2207 - val_mae: 7.6947\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6276 - acc: 0.9412 - mse: 147.7890 - mae: 7.7913 - val_loss: 9.4944 - val_acc: 0.9420 - val_mse: 145.3181 - val_mae: 7.6910\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6304 - acc: 0.9413 - mse: 147.7923 - mae: 7.7934 - val_loss: 9.4928 - val_acc: 0.9418 - val_mse: 145.2749 - val_mae: 7.6899\n",
      "\n",
      "Epoch 00275: saving model to checkpoints/model_ckpt_epoch_275.hdf5\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6252 - acc: 0.9412 - mse: 147.7514 - mae: 7.7895 - val_loss: 9.4961 - val_acc: 0.9417 - val_mse: 145.4243 - val_mae: 7.6922\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6220 - acc: 0.9414 - mse: 147.7196 - mae: 7.7870 - val_loss: 9.4952 - val_acc: 0.9418 - val_mse: 145.2360 - val_mae: 7.6915\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6248 - acc: 0.9413 - mse: 147.7509 - mae: 7.7892 - val_loss: 9.4961 - val_acc: 0.9420 - val_mse: 145.2685 - val_mae: 7.6924\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6253 - acc: 0.9414 - mse: 147.7848 - mae: 7.7895 - val_loss: 9.5003 - val_acc: 0.9417 - val_mse: 145.2263 - val_mae: 7.6953\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.0003663432435132563.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6280 - acc: 0.9413 - mse: 147.8634 - mae: 7.7915 - val_loss: 9.4977 - val_acc: 0.9421 - val_mse: 145.1821 - val_mae: 7.6937\n",
      "\n",
      "Epoch 00280: saving model to checkpoints/model_ckpt_epoch_280.hdf5\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.0003297089191619307.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6310 - acc: 0.9412 - mse: 147.8602 - mae: 7.7938 - val_loss: 9.4922 - val_acc: 0.9419 - val_mse: 145.1093 - val_mae: 7.6893\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6258 - acc: 0.9414 - mse: 147.7905 - mae: 7.7900 - val_loss: 9.4926 - val_acc: 0.9418 - val_mse: 145.3747 - val_mae: 7.6896\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6326 - acc: 0.9412 - mse: 147.9234 - mae: 7.7950 - val_loss: 9.5028 - val_acc: 0.9419 - val_mse: 144.9985 - val_mae: 7.6975\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6220 - acc: 0.9414 - mse: 147.7572 - mae: 7.7871 - val_loss: 9.5008 - val_acc: 0.9418 - val_mse: 145.2881 - val_mae: 7.6960\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6255 - acc: 0.9414 - mse: 147.8213 - mae: 7.7897 - val_loss: 9.4936 - val_acc: 0.9420 - val_mse: 145.1473 - val_mae: 7.6906\n",
      "\n",
      "Epoch 00285: saving model to checkpoints/model_ckpt_epoch_285.hdf5\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6229 - acc: 0.9414 - mse: 147.7700 - mae: 7.7878 - val_loss: 9.4934 - val_acc: 0.9416 - val_mse: 145.1390 - val_mae: 7.6904\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6278 - acc: 0.9413 - mse: 147.8072 - mae: 7.7914 - val_loss: 9.4948 - val_acc: 0.9417 - val_mse: 145.2624 - val_mae: 7.6913\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6241 - acc: 0.9413 - mse: 147.7454 - mae: 7.7887 - val_loss: 9.5039 - val_acc: 0.9414 - val_mse: 145.2593 - val_mae: 7.6981\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6220 - acc: 0.9413 - mse: 147.7372 - mae: 7.7871 - val_loss: 9.4943 - val_acc: 0.9420 - val_mse: 145.2957 - val_mae: 7.6909\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.0003297089133411646.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6217 - acc: 0.9413 - mse: 147.7004 - mae: 7.7869 - val_loss: 9.4957 - val_acc: 0.9419 - val_mse: 145.3579 - val_mae: 7.6920\n",
      "\n",
      "Epoch 00290: saving model to checkpoints/model_ckpt_epoch_290.hdf5\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.00029673802200704815.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 9.6201 - acc: 0.9413 - mse: 147.6627 - mae: 7.7857 - val_loss: 9.4955 - val_acc: 0.9418 - val_mse: 145.4815 - val_mae: 7.6919\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6222 - acc: 0.9414 - mse: 147.6505 - mae: 7.7873 - val_loss: 9.4943 - val_acc: 0.9419 - val_mse: 145.0889 - val_mae: 7.6910\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6229 - acc: 0.9414 - mse: 147.7410 - mae: 7.7878 - val_loss: 9.4915 - val_acc: 0.9418 - val_mse: 145.1939 - val_mae: 7.6889\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 9.6215 - acc: 0.9414 - mse: 147.6783 - mae: 7.7867 - val_loss: 9.4977 - val_acc: 0.9418 - val_mse: 145.0635 - val_mae: 7.6934\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6273 - acc: 0.9412 - mse: 147.7986 - mae: 7.7911 - val_loss: 9.5021 - val_acc: 0.9414 - val_mse: 145.2915 - val_mae: 7.6967\n",
      "\n",
      "Epoch 00295: saving model to checkpoints/model_ckpt_epoch_295.hdf5\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6241 - acc: 0.9413 - mse: 147.7717 - mae: 7.7887 - val_loss: 9.5046 - val_acc: 0.9416 - val_mse: 145.2620 - val_mae: 7.6987\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6189 - acc: 0.9414 - mse: 147.6535 - mae: 7.7848 - val_loss: 9.4994 - val_acc: 0.9414 - val_mse: 145.0880 - val_mae: 7.6948\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6239 - acc: 0.9414 - mse: 147.7996 - mae: 7.7884 - val_loss: 9.4916 - val_acc: 0.9416 - val_mse: 145.0948 - val_mae: 7.6891\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6244 - acc: 0.9413 - mse: 147.7585 - mae: 7.7888 - val_loss: 9.5010 - val_acc: 0.9419 - val_mse: 145.1543 - val_mae: 7.6962\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.0002967380278278142.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 9.6166 - acc: 0.9414 - mse: 147.5428 - mae: 7.7831 - val_loss: 9.4917 - val_acc: 0.9418 - val_mse: 145.3066 - val_mae: 7.6889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Done training. Time elapsed: 1:16:55.644935 sec\n",
      "[INFO    ] Epoch 300/300 - loss: 9.616619110107422 - val_loss: 9.491670608520508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00300: saving model to checkpoints/model_ckpt_epoch_300.hdf5\n"
     ]
    }
   ],
   "source": [
    "assert(keras.backend.backend() == 'tensorflow')\n",
    "\n",
    "normal_epochs = 300\n",
    "normal_batch_size = 2000\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "learning_rate = 0.0063\n",
    "gradient_clip_norm = 100.\n",
    "\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "model_training_checkpoint = ModelCheckpoint(monitor=\"val_loss\", \n",
    "                                           verbose = 1,\n",
    "                                           filepath = \"checkpoints/model_ckpt_epoch_{epoch:02d}.hdf5\",\n",
    "                                           period = 5)\n",
    "model = create_model(\n",
    "                    nvariables = nvariables, \n",
    "                    lr = learning_rate, \n",
    "                    clipnorm = gradient_clip_norm, \n",
    "                    nodes1=20, \n",
    "                    nodes2=15, \n",
    "                    nodes3=10, \n",
    "                    outnodes=2,\n",
    "                    l1_reg = l1_reg, \n",
    "                    l2_reg = l2_reg)\n",
    "\n",
    "logger.info('Training model with l1_reg: {0} l2_reg: {1}'.format(l1_reg, l2_reg))\n",
    "\n",
    "model, history = train_model(model, \n",
    "                      x_train_displ, \n",
    "                      np.column_stack((y_train_displ, dxy_train_displ)),\n",
    "                      save_model=False, \n",
    "                      epochs=normal_epochs, \n",
    "                      batch_size=normal_batch_size,\n",
    "                      callbacks=[lr_decay,terminate_on_nan, model_training_checkpoint], \n",
    "                      validation_split=0.1, \n",
    "                      verbose=True)\n",
    "\n",
    "metrics = [len(history.history['loss']), history.history['loss'][-1], history.history['val_loss'][-1]]\n",
    "logger.info('Epoch {0}/{0} - loss: {1} - val_loss: {2}'.format(*metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a833908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoints/model_ckpt_epoch_05.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_10.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_15.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_20.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_25.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_30.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_35.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_40.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_45.hdf5',\n",
       " 'checkpoints/model_ckpt_epoch_50.hdf5']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "from keras.models import load_model\n",
    "filenames = glob.glob(\"checkpoints/model_ckpt_*.hdf5\")\n",
    "files = sorted(filenames, key=lambda x:float(re.findall(\"(\\d+)\",x)[0]))\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2526fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/model_ckpt_epoch_300.hdf5\n"
     ]
    }
   ],
   "source": [
    "# import glob\n",
    "# import os\n",
    "\n",
    "# list_of_files = glob.glob('checkpoints/model_ckpt_*.hdf5') # * means all if need specific format then *.csv\n",
    "# latest_file = max(list_of_files, key=os.path.getctime)\n",
    "# print(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0273a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [i for i in range(5,305,5)]\n",
    "maxs, mins, abs_mins, negs, pos, var = [], [], [],[], [], []\n",
    "for i in range(len(files)):\n",
    "    loaded_model = load_model(filepath = files[i])   \n",
    "    for layer in loaded_model.layers:\n",
    "        if layer.name == \"dense-output\":\n",
    "            w = layer.get_weights()[0]\n",
    "            maxs.append(np.max(w))\n",
    "            mins.append(np.min(w))\n",
    "            abs_mins.append(abs(np.min(w)))\n",
    "            negs.append(np.sum(w < 0))\n",
    "            pos.append(np.sum(w >= 0))\n",
    "            var.append(np.var(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b36fbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([maxs,mins,abs_mins,var,negs,pos])\n",
    "df = df.transpose()\n",
    "df.columns=[\"max\",\"min\",\"abs_min\",\"variance\",\"negs\",\"pos\"]\n",
    "df.index = idxs\n",
    "df\n",
    "df.to_excel(\"dense-output.xlsx\",index=True, index_label = \"epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
