{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76497b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "1.3.4\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "import re\n",
    "import glob\n",
    "# Script Imports\n",
    "from nn_globals import *\n",
    "from nn_plotting import gaus, fit_gaus, corr_plot\n",
    "from dataset import muon_data_split\n",
    "from nn_evaluate import huber_loss\n",
    "from nn_training import train_model, lr_schedule\n",
    "# Keras/TF import\n",
    "from keras.models import Model, load_model\n",
    "from keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, BatchNormalization, Dense, Activation\n",
    "from keras.callbacks import LearningRateScheduler, TerminateOnNaN, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be3d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading muon data from ./data/NN_input_params_FlatXYZ.npz ...\n",
      "[INFO    ] Loaded the variables with shape (19300000, 25)\n",
      "[INFO    ] Loaded the parameters with shape (19300000, 6)\n",
      "[INFO    ] Loaded the encoded variables with shape (3284620, 23)\n",
      "[INFO    ] Loaded the encoded parameters with shape (3284620,)\n",
      "[INFO    ] Loaded # of training and testing events: (2249964, 1034656)\n",
      "[WARNING ] The last batch for training could be too few! (2024967%128)=7. Please change test_size.\n",
      "[WARNING ] Try this formula: int(int(3284620*0.685)*0.9) % 128\n",
      "[WARNING ] The last batch for training after mixing could be too few! (4049935%128)=15. Please change test_size.\n",
      "[WARNING ] Try this formula: int(int(3284620*0.685)*2*0.9) % 128\n"
     ]
    }
   ],
   "source": [
    "# Import muon data\n",
    "# 'x' is the array of input variables, 'y' is the q/pT\n",
    "x_train_displ, x_test_displ, y_train_displ, y_test_displ, dxy_train_displ, dxy_test_displ= muon_data_split(filename=DATAFILEPATH, \n",
    "                                                                                                           reg_pt_scale=REG_PT_SCALE, \n",
    "                                                                                                           reg_dxy_scale=REG_DXY_SCALE, \n",
    "                                                                                                           test_size=TEST_SIZE,\n",
    "                                                                                                           nvariables = NVARIABLES,\n",
    "                                                                                                           nentries= NENTRIES,\n",
    "                                                                                                           batch_size = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69e3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nvariables, lr=0.001, clipnorm=10., initializer = \"glorot_uniform\",\n",
    "                nodes1=64, nodes2=32, nodes3=16, outnodes=2,\n",
    "                l1_reg = 0.0, l2_reg = 0.0):\n",
    "  \n",
    "    regularizer = L1L2(l1=l1_reg, l2=l2_reg)\n",
    "    bn_momentum = 0.9\n",
    "    eps = 1e-4\n",
    "\n",
    "    x = x_in = Input((nvariables,))\n",
    "    x = BatchNormalization(epsilon=eps, momentum=bn_momentum,name=\"bn-input\")(x)\n",
    "    \n",
    "    x = Dense(nodes1, \n",
    "               kernel_initializer=initializer,\n",
    "               use_bias = False,\n",
    "               kernel_regularizer = regularizer,\n",
    "               name=\"hidden-dense-1\")(x)\n",
    "    x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-1\")(x)\n",
    "    x = Activation(activation = \"tanh\",name=\"act_1\")(x)\n",
    "    \n",
    "    if nodes2:\n",
    "    \n",
    "        x = Dense(nodes2, \n",
    "                   kernel_initializer=initializer,\n",
    "                   use_bias = False,\n",
    "                   kernel_regularizer = regularizer,\n",
    "                   name=\"hidden-dense-2\")(x)\n",
    "        x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-2\")(x)\n",
    "        x = Activation(activation = \"tanh\",name=\"act_2\")(x)\n",
    "        if nodes3:\n",
    "\n",
    "            x = Dense(nodes3, \n",
    "                       kernel_initializer=initializer,\n",
    "                       kernel_regularizer = regularizer,\n",
    "                       use_bias = False,\n",
    "                       name=\"hidden-dense-3\")(x)\n",
    "            x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-3\")(x)\n",
    "            x = Activation(activation = \"tanh\", name=\"act_3\")(x)\n",
    "\n",
    "    x = Dense(outnodes,kernel_initializer = initializer,name=\"dense-output\")(x)\n",
    "    x = Activation(\"linear\")(x)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=x,name=\"baseline-model\")\n",
    "    \n",
    "    adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "    model.compile(optimizer=adam, \n",
    "                  loss=huber_loss, \n",
    "                  metrics=['acc','mse','mae'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c420cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:52:05.498337: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-11 10:52:05.499529: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/gpradhan/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "[INFO    ] Training model with l1_reg: 0.0 l2_reg: 0.0\n",
      "[INFO    ] Begin training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"baseline-model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "bn-input (BatchNormalization (None, 23)                92        \n",
      "_________________________________________________________________\n",
      "hidden-dense-1 (Dense)       (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "bn-1 (BatchNormalization)    (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "act_1 (Activation)           (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "hidden-dense-2 (Dense)       (None, 7)                 70        \n",
      "_________________________________________________________________\n",
      "bn-2 (BatchNormalization)    (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "act_2 (Activation)           (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "hidden-dense-3 (Dense)       (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "bn-3 (BatchNormalization)    (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "act_3 (Activation)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense-output (Dense)         (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 527\n",
      "Trainable params: 437\n",
      "Non-trainable params: 90\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:52:05.769980: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-11 10:52:05.772927: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.006300000008195639.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:52:06.107368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - ETA: 0s - loss: 35.3421 - acc: 0.8949 - mse: 1534.7742 - mae: 26.9357"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:52:22.272572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 17s 15ms/step - loss: 35.3421 - acc: 0.8949 - mse: 1534.7742 - mae: 26.9357 - val_loss: 27.4625 - val_acc: 0.9151 - val_mse: 1039.4320 - val_mae: 21.0726\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 22.2225 - acc: 0.9257 - mse: 706.1531 - mae: 17.1738 - val_loss: 17.7120 - val_acc: 0.9331 - val_mse: 443.9235 - val_mae: 13.8178\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 15.4664 - acc: 0.9334 - mse: 338.0123 - mae: 12.1465 - val_loss: 13.6558 - val_acc: 0.9346 - val_mse: 261.7858 - val_mae: 10.7985\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 12.8708 - acc: 0.9342 - mse: 232.1196 - mae: 10.2140 - val_loss: 12.3754 - val_acc: 0.9311 - val_mse: 212.3261 - val_mae: 9.8451\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 11.8892 - acc: 0.9340 - mse: 200.1672 - mae: 9.4828 - val_loss: 11.5785 - val_acc: 0.9340 - val_mse: 191.0241 - val_mae: 9.2511\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 11.4862 - acc: 0.9341 - mse: 189.1691 - mae: 9.1823 - val_loss: 11.2534 - val_acc: 0.9358 - val_mse: 183.5719 - val_mae: 9.0083\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 11.2950 - acc: 0.9340 - mse: 184.7834 - mae: 9.0397 - val_loss: 11.1195 - val_acc: 0.9353 - val_mse: 181.4442 - val_mae: 8.9082\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 11.1734 - acc: 0.9342 - mse: 182.2737 - mae: 8.9487 - val_loss: 10.9645 - val_acc: 0.9361 - val_mse: 177.8151 - val_mae: 8.7920\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 11.0677 - acc: 0.9344 - mse: 180.3031 - mae: 8.8697 - val_loss: 10.9091 - val_acc: 0.9362 - val_mse: 177.0822 - val_mae: 8.7512\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.006300000008195639.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.9828 - acc: 0.9344 - mse: 178.8844 - mae: 8.8061 - val_loss: 10.9965 - val_acc: 0.9354 - val_mse: 180.1138 - val_mae: 8.8158\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/model_ckpt_epoch_10.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.005670000007376075.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.9186 - acc: 0.9348 - mse: 177.8410 - mae: 8.7580 - val_loss: 10.7670 - val_acc: 0.9363 - val_mse: 174.6518 - val_mae: 8.6441\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.8735 - acc: 0.9350 - mse: 177.1315 - mae: 8.7242 - val_loss: 10.8145 - val_acc: 0.9361 - val_mse: 175.3331 - val_mae: 8.6804\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.8464 - acc: 0.9351 - mse: 176.7536 - mae: 8.7040 - val_loss: 10.6548 - val_acc: 0.9367 - val_mse: 172.8801 - val_mae: 8.5603\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 17s 16ms/step - loss: 10.8152 - acc: 0.9352 - mse: 176.1599 - mae: 8.6805 - val_loss: 10.6683 - val_acc: 0.9366 - val_mse: 174.1050 - val_mae: 8.5704\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.8021 - acc: 0.9353 - mse: 176.0365 - mae: 8.6707 - val_loss: 10.7748 - val_acc: 0.9359 - val_mse: 175.3976 - val_mae: 8.6499\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.7696 - acc: 0.9354 - mse: 175.3263 - mae: 8.6464 - val_loss: 10.6659 - val_acc: 0.9371 - val_mse: 173.9092 - val_mae: 8.5687\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.7509 - acc: 0.9353 - mse: 175.0381 - mae: 8.6323 - val_loss: 10.6371 - val_acc: 0.9372 - val_mse: 171.5990 - val_mae: 8.5475\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.7406 - acc: 0.9353 - mse: 174.8983 - mae: 8.6246 - val_loss: 10.5621 - val_acc: 0.9356 - val_mse: 170.5958 - val_mae: 8.4911\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.7284 - acc: 0.9354 - mse: 174.6570 - mae: 8.6156 - val_loss: 10.6655 - val_acc: 0.9368 - val_mse: 173.9602 - val_mae: 8.5680\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.005669999867677689.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.7102 - acc: 0.9354 - mse: 174.3003 - mae: 8.6020 - val_loss: 10.6037 - val_acc: 0.9368 - val_mse: 172.2743 - val_mae: 8.5216\n",
      "\n",
      "Epoch 00020: saving model to checkpoints/model_ckpt_epoch_20.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.00510299988090992.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.7045 - acc: 0.9354 - mse: 174.1402 - mae: 8.5976 - val_loss: 10.5465 - val_acc: 0.9360 - val_mse: 170.0787 - val_mae: 8.4797\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6909 - acc: 0.9356 - mse: 173.8646 - mae: 8.5874 - val_loss: 10.5849 - val_acc: 0.9368 - val_mse: 171.9898 - val_mae: 8.5076\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 10.6880 - acc: 0.9356 - mse: 173.8059 - mae: 8.5854 - val_loss: 10.5550 - val_acc: 0.9376 - val_mse: 170.1358 - val_mae: 8.4854\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6870 - acc: 0.9355 - mse: 173.7805 - mae: 8.5845 - val_loss: 10.6071 - val_acc: 0.9370 - val_mse: 171.0717 - val_mae: 8.5249\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6786 - acc: 0.9356 - mse: 173.5117 - mae: 8.5783 - val_loss: 10.5363 - val_acc: 0.9367 - val_mse: 171.0914 - val_mae: 8.4712\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6683 - acc: 0.9355 - mse: 173.4001 - mae: 8.5705 - val_loss: 10.5606 - val_acc: 0.9374 - val_mse: 170.6869 - val_mae: 8.4898\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6592 - acc: 0.9356 - mse: 173.1950 - mae: 8.5638 - val_loss: 10.5097 - val_acc: 0.9369 - val_mse: 169.6315 - val_mae: 8.4517\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6623 - acc: 0.9354 - mse: 173.3149 - mae: 8.5661 - val_loss: 10.6030 - val_acc: 0.9373 - val_mse: 170.8229 - val_mae: 8.5216\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.005102999974042177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6494 - acc: 0.9356 - mse: 173.0099 - mae: 8.5564 - val_loss: 10.5553 - val_acc: 0.9374 - val_mse: 170.4642 - val_mae: 8.4861\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.005102999974042177.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6503 - acc: 0.9355 - mse: 173.0529 - mae: 8.5571 - val_loss: 10.5835 - val_acc: 0.9366 - val_mse: 170.5215 - val_mae: 8.5066\n",
      "\n",
      "Epoch 00030: saving model to checkpoints/model_ckpt_epoch_30.hdf5\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.004592699976637959.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6341 - acc: 0.9356 - mse: 172.7280 - mae: 8.5450 - val_loss: 10.6209 - val_acc: 0.9334 - val_mse: 171.0067 - val_mae: 8.5353\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6363 - acc: 0.9355 - mse: 172.7241 - mae: 8.5465 - val_loss: 10.4609 - val_acc: 0.9366 - val_mse: 169.5619 - val_mae: 8.4153\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6309 - acc: 0.9356 - mse: 172.7180 - mae: 8.5424 - val_loss: 10.4920 - val_acc: 0.9364 - val_mse: 169.9006 - val_mae: 8.4385\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6402 - acc: 0.9355 - mse: 172.7806 - mae: 8.5495 - val_loss: 10.4714 - val_acc: 0.9375 - val_mse: 170.1396 - val_mae: 8.4231\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6199 - acc: 0.9356 - mse: 172.4194 - mae: 8.5343 - val_loss: 10.4956 - val_acc: 0.9364 - val_mse: 169.1194 - val_mae: 8.4416\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6292 - acc: 0.9357 - mse: 172.7045 - mae: 8.5412 - val_loss: 10.5141 - val_acc: 0.9361 - val_mse: 170.5580 - val_mae: 8.4552\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6207 - acc: 0.9356 - mse: 172.5061 - mae: 8.5348 - val_loss: 10.5119 - val_acc: 0.9377 - val_mse: 170.5827 - val_mae: 8.4535\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.6179 - acc: 0.9357 - mse: 172.4524 - mae: 8.5327 - val_loss: 10.4409 - val_acc: 0.9366 - val_mse: 168.4998 - val_mae: 8.4002\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 18s 18ms/step - loss: 10.6270 - acc: 0.9355 - mse: 172.7338 - mae: 8.5395 - val_loss: 10.4898 - val_acc: 0.9348 - val_mse: 169.2606 - val_mae: 8.4374\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.004592699930071831.\n",
      "1013/1013 [==============================] - 19s 19ms/step - loss: 10.6187 - acc: 0.9357 - mse: 172.5272 - mae: 8.5334 - val_loss: 10.4553 - val_acc: 0.9374 - val_mse: 169.3414 - val_mae: 8.4112\n",
      "\n",
      "Epoch 00040: saving model to checkpoints/model_ckpt_epoch_40.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.004133429937064648.\n",
      "1013/1013 [==============================] - 19s 18ms/step - loss: 10.6061 - acc: 0.9357 - mse: 172.2570 - mae: 8.5240 - val_loss: 10.5204 - val_acc: 0.9364 - val_mse: 171.1121 - val_mae: 8.4594\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 18s 18ms/step - loss: 10.6088 - acc: 0.9356 - mse: 172.2828 - mae: 8.5260 - val_loss: 10.4520 - val_acc: 0.9367 - val_mse: 168.7628 - val_mae: 8.4085\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6042 - acc: 0.9356 - mse: 172.2382 - mae: 8.5226 - val_loss: 10.5375 - val_acc: 0.9373 - val_mse: 169.3678 - val_mae: 8.4729\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.6069 - acc: 0.9356 - mse: 172.2957 - mae: 8.5246 - val_loss: 10.4433 - val_acc: 0.9371 - val_mse: 169.3085 - val_mae: 8.4018\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5983 - acc: 0.9356 - mse: 172.1024 - mae: 8.5182 - val_loss: 10.4736 - val_acc: 0.9366 - val_mse: 167.9134 - val_mae: 8.4255\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5964 - acc: 0.9356 - mse: 172.0539 - mae: 8.5167 - val_loss: 10.4602 - val_acc: 0.9360 - val_mse: 168.7266 - val_mae: 8.4147\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5975 - acc: 0.9357 - mse: 172.1047 - mae: 8.5175 - val_loss: 10.5303 - val_acc: 0.9370 - val_mse: 170.3893 - val_mae: 8.4668\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5932 - acc: 0.9357 - mse: 172.0584 - mae: 8.5143 - val_loss: 10.5104 - val_acc: 0.9346 - val_mse: 169.9563 - val_mae: 8.4524\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5928 - acc: 0.9356 - mse: 171.9883 - mae: 8.5140 - val_loss: 10.5095 - val_acc: 0.9372 - val_mse: 170.3273 - val_mae: 8.4520\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00413342984393239.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5912 - acc: 0.9357 - mse: 171.9395 - mae: 8.5128 - val_loss: 10.4517 - val_acc: 0.9367 - val_mse: 169.5078 - val_mae: 8.4083\n",
      "\n",
      "Epoch 00050: saving model to checkpoints/model_ckpt_epoch_50.hdf5\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0037200868595391513.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5875 - acc: 0.9357 - mse: 171.8489 - mae: 8.5101 - val_loss: 10.5505 - val_acc: 0.9364 - val_mse: 170.9216 - val_mae: 8.4819\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5830 - acc: 0.9357 - mse: 171.8387 - mae: 8.5067 - val_loss: 10.4081 - val_acc: 0.9371 - val_mse: 167.8254 - val_mae: 8.3763\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5805 - acc: 0.9357 - mse: 171.6835 - mae: 8.5048 - val_loss: 10.4135 - val_acc: 0.9370 - val_mse: 167.9609 - val_mae: 8.3799\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5790 - acc: 0.9358 - mse: 171.6736 - mae: 8.5037 - val_loss: 10.3902 - val_acc: 0.9367 - val_mse: 167.5011 - val_mae: 8.3625\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5666 - acc: 0.9358 - mse: 171.5065 - mae: 8.4944 - val_loss: 10.4831 - val_acc: 0.9380 - val_mse: 168.7290 - val_mae: 8.4322\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5792 - acc: 0.9358 - mse: 171.6593 - mae: 8.5039 - val_loss: 10.4912 - val_acc: 0.9368 - val_mse: 170.8736 - val_mae: 8.4376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5698 - acc: 0.9359 - mse: 171.4992 - mae: 8.4967 - val_loss: 10.4237 - val_acc: 0.9372 - val_mse: 168.4699 - val_mae: 8.3869\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5646 - acc: 0.9359 - mse: 171.4987 - mae: 8.4928 - val_loss: 10.4232 - val_acc: 0.9369 - val_mse: 167.8926 - val_mae: 8.3871\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5689 - acc: 0.9358 - mse: 171.5931 - mae: 8.4961 - val_loss: 10.4127 - val_acc: 0.9374 - val_mse: 168.1478 - val_mae: 8.3790\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0037200867664068937.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5685 - acc: 0.9359 - mse: 171.4885 - mae: 8.4959 - val_loss: 10.4412 - val_acc: 0.9362 - val_mse: 169.6062 - val_mae: 8.4004\n",
      "\n",
      "Epoch 00060: saving model to checkpoints/model_ckpt_epoch_60.hdf5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0033480780897662044.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5513 - acc: 0.9359 - mse: 171.1746 - mae: 8.4829 - val_loss: 10.4146 - val_acc: 0.9376 - val_mse: 168.1983 - val_mae: 8.3814\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5570 - acc: 0.9359 - mse: 171.3380 - mae: 8.4872 - val_loss: 10.3765 - val_acc: 0.9378 - val_mse: 168.2116 - val_mae: 8.3520\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5536 - acc: 0.9361 - mse: 171.2161 - mae: 8.4848 - val_loss: 10.4110 - val_acc: 0.9381 - val_mse: 168.0771 - val_mae: 8.3777\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5494 - acc: 0.9360 - mse: 171.1647 - mae: 8.4816 - val_loss: 10.4082 - val_acc: 0.9367 - val_mse: 168.0136 - val_mae: 8.3760\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5518 - acc: 0.9359 - mse: 171.2379 - mae: 8.4834 - val_loss: 10.3975 - val_acc: 0.9375 - val_mse: 168.2387 - val_mae: 8.3674\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5491 - acc: 0.9360 - mse: 171.1197 - mae: 8.4813 - val_loss: 10.4507 - val_acc: 0.9379 - val_mse: 168.5272 - val_mae: 8.4079\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5511 - acc: 0.9360 - mse: 171.2460 - mae: 8.4828 - val_loss: 10.3983 - val_acc: 0.9366 - val_mse: 167.8681 - val_mae: 8.3687\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5478 - acc: 0.9360 - mse: 171.1305 - mae: 8.4802 - val_loss: 10.4342 - val_acc: 0.9381 - val_mse: 168.1843 - val_mae: 8.3957\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5528 - acc: 0.9361 - mse: 171.1749 - mae: 8.4841 - val_loss: 10.4280 - val_acc: 0.9382 - val_mse: 169.4730 - val_mae: 8.3900\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0033480781130492687.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.5564 - acc: 0.9361 - mse: 171.3199 - mae: 8.4866 - val_loss: 10.3954 - val_acc: 0.9375 - val_mse: 169.0533 - val_mae: 8.3662\n",
      "\n",
      "Epoch 00070: saving model to checkpoints/model_ckpt_epoch_70.hdf5\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.003013270301744342.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5390 - acc: 0.9361 - mse: 170.9025 - mae: 8.4738 - val_loss: 10.3870 - val_acc: 0.9373 - val_mse: 167.2343 - val_mae: 8.3600\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5298 - acc: 0.9362 - mse: 170.7218 - mae: 8.4668 - val_loss: 10.3882 - val_acc: 0.9374 - val_mse: 167.4029 - val_mae: 8.3609\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5391 - acc: 0.9362 - mse: 170.9429 - mae: 8.4738 - val_loss: 10.4060 - val_acc: 0.9370 - val_mse: 168.3788 - val_mae: 8.3742\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5310 - acc: 0.9362 - mse: 170.7539 - mae: 8.4676 - val_loss: 10.3876 - val_acc: 0.9374 - val_mse: 168.0914 - val_mae: 8.3599\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5365 - acc: 0.9360 - mse: 170.9113 - mae: 8.4718 - val_loss: 10.3576 - val_acc: 0.9371 - val_mse: 167.1437 - val_mae: 8.3381\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 10.5319 - acc: 0.9361 - mse: 170.7090 - mae: 8.4684 - val_loss: 10.3948 - val_acc: 0.9375 - val_mse: 167.7829 - val_mae: 8.3661\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 16s 15ms/step - loss: 10.5353 - acc: 0.9362 - mse: 170.8001 - mae: 8.4709 - val_loss: 10.3620 - val_acc: 0.9377 - val_mse: 167.1475 - val_mae: 8.3414\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5354 - acc: 0.9362 - mse: 170.8663 - mae: 8.4710 - val_loss: 10.3578 - val_acc: 0.9382 - val_mse: 167.2044 - val_mae: 8.3377\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5354 - acc: 0.9361 - mse: 170.8208 - mae: 8.4710 - val_loss: 10.3755 - val_acc: 0.9375 - val_mse: 167.2716 - val_mae: 8.3512\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0030132702086120844.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5240 - acc: 0.9363 - mse: 170.6272 - mae: 8.4624 - val_loss: 10.3815 - val_acc: 0.9380 - val_mse: 167.6214 - val_mae: 8.3559\n",
      "\n",
      "Epoch 00080: saving model to checkpoints/model_ckpt_epoch_80.hdf5\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.002711943187750876.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5266 - acc: 0.9362 - mse: 170.6055 - mae: 8.4643 - val_loss: 10.3739 - val_acc: 0.9379 - val_mse: 167.4141 - val_mae: 8.3502\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5291 - acc: 0.9362 - mse: 170.6629 - mae: 8.4663 - val_loss: 10.3608 - val_acc: 0.9376 - val_mse: 166.9324 - val_mae: 8.3405\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5163 - acc: 0.9362 - mse: 170.4616 - mae: 8.4566 - val_loss: 10.3490 - val_acc: 0.9375 - val_mse: 166.6441 - val_mae: 8.3314\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.002711943117901683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5277 - acc: 0.9363 - mse: 170.6924 - mae: 8.4651 - val_loss: 10.3805 - val_acc: 0.9374 - val_mse: 168.3601 - val_mae: 8.3553\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5153 - acc: 0.9362 - mse: 170.3293 - mae: 8.4559 - val_loss: 10.3860 - val_acc: 0.9382 - val_mse: 167.8998 - val_mae: 8.3587\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5196 - acc: 0.9363 - mse: 170.4790 - mae: 8.4591 - val_loss: 10.3720 - val_acc: 0.9373 - val_mse: 167.8329 - val_mae: 8.3488\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5155 - acc: 0.9363 - mse: 170.3794 - mae: 8.4560 - val_loss: 10.3858 - val_acc: 0.9369 - val_mse: 167.8492 - val_mae: 8.3592\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5209 - acc: 0.9363 - mse: 170.4042 - mae: 8.4602 - val_loss: 10.3425 - val_acc: 0.9378 - val_mse: 166.7001 - val_mae: 8.3264\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5227 - acc: 0.9361 - mse: 170.4895 - mae: 8.4614 - val_loss: 10.3878 - val_acc: 0.9373 - val_mse: 167.1360 - val_mae: 8.3605\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.002711943117901683.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5166 - acc: 0.9363 - mse: 170.3334 - mae: 8.4569 - val_loss: 10.3464 - val_acc: 0.9373 - val_mse: 167.5019 - val_mae: 8.3299\n",
      "\n",
      "Epoch 00090: saving model to checkpoints/model_ckpt_epoch_90.hdf5\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0024407488061115147.\n",
      "1013/1013 [==============================] - 19s 19ms/step - loss: 10.5089 - acc: 0.9363 - mse: 170.2110 - mae: 8.4511 - val_loss: 10.3605 - val_acc: 0.9381 - val_mse: 167.2355 - val_mae: 8.3399\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5143 - acc: 0.9363 - mse: 170.2960 - mae: 8.4551 - val_loss: 10.4131 - val_acc: 0.9369 - val_mse: 169.2728 - val_mae: 8.3797\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5183 - acc: 0.9362 - mse: 170.4056 - mae: 8.4581 - val_loss: 10.3707 - val_acc: 0.9383 - val_mse: 167.6258 - val_mae: 8.3480\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5167 - acc: 0.9363 - mse: 170.2973 - mae: 8.4570 - val_loss: 10.3607 - val_acc: 0.9379 - val_mse: 167.5755 - val_mae: 8.3402\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5137 - acc: 0.9363 - mse: 170.3000 - mae: 8.4547 - val_loss: 10.3545 - val_acc: 0.9384 - val_mse: 166.8578 - val_mae: 8.3355\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5084 - acc: 0.9364 - mse: 170.2176 - mae: 8.4507 - val_loss: 10.3525 - val_acc: 0.9384 - val_mse: 166.9373 - val_mae: 8.3342\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5155 - acc: 0.9364 - mse: 170.3675 - mae: 8.4560 - val_loss: 10.3372 - val_acc: 0.9382 - val_mse: 166.6672 - val_mae: 8.3222\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5122 - acc: 0.9364 - mse: 170.2450 - mae: 8.4536 - val_loss: 10.3711 - val_acc: 0.9380 - val_mse: 167.4343 - val_mae: 8.3481\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5125 - acc: 0.9363 - mse: 170.2100 - mae: 8.4537 - val_loss: 10.3446 - val_acc: 0.9377 - val_mse: 166.9611 - val_mae: 8.3282\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.0024407487362623215.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5076 - acc: 0.9364 - mse: 170.1537 - mae: 8.4501 - val_loss: 10.3381 - val_acc: 0.9381 - val_mse: 166.2070 - val_mae: 8.3233\n",
      "\n",
      "Epoch 00100: saving model to checkpoints/model_ckpt_epoch_100.hdf5\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0021966738626360894.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.5035 - acc: 0.9364 - mse: 170.0273 - mae: 8.4470 - val_loss: 10.3532 - val_acc: 0.9376 - val_mse: 166.5311 - val_mae: 8.3344\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 10.4998 - acc: 0.9365 - mse: 169.9803 - mae: 8.4443 - val_loss: 10.3742 - val_acc: 0.9381 - val_mse: 167.0557 - val_mae: 8.3506\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5058 - acc: 0.9363 - mse: 170.1185 - mae: 8.4488 - val_loss: 10.3377 - val_acc: 0.9381 - val_mse: 166.8217 - val_mae: 8.3227\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5004 - acc: 0.9364 - mse: 170.0427 - mae: 8.4447 - val_loss: 10.3422 - val_acc: 0.9379 - val_mse: 166.5130 - val_mae: 8.3266\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5069 - acc: 0.9365 - mse: 170.0795 - mae: 8.4496 - val_loss: 10.3630 - val_acc: 0.9381 - val_mse: 167.2010 - val_mae: 8.3414\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.4995 - acc: 0.9364 - mse: 169.9478 - mae: 8.4440 - val_loss: 10.4094 - val_acc: 0.9379 - val_mse: 168.2355 - val_mae: 8.3767\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5009 - acc: 0.9365 - mse: 169.9731 - mae: 8.4450 - val_loss: 10.3494 - val_acc: 0.9384 - val_mse: 166.6740 - val_mae: 8.3315\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5050 - acc: 0.9363 - mse: 170.0667 - mae: 8.4482 - val_loss: 10.4392 - val_acc: 0.9373 - val_mse: 169.1405 - val_mae: 8.3986\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.5031 - acc: 0.9364 - mse: 169.9884 - mae: 8.4466 - val_loss: 10.3353 - val_acc: 0.9372 - val_mse: 166.4198 - val_mae: 8.3213\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.002196673769503832.\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 10.5003 - acc: 0.9365 - mse: 170.0104 - mae: 8.4447 - val_loss: 10.4188 - val_acc: 0.9367 - val_mse: 168.2758 - val_mae: 8.3835\n",
      "\n",
      "Epoch 00110: saving model to checkpoints/model_ckpt_epoch_110.hdf5\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.001977006392553449.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5024 - acc: 0.9364 - mse: 169.9850 - mae: 8.4462 - val_loss: 10.3447 - val_acc: 0.9383 - val_mse: 167.1711 - val_mae: 8.3281\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4945 - acc: 0.9366 - mse: 169.8196 - mae: 8.4402 - val_loss: 10.3483 - val_acc: 0.9375 - val_mse: 166.4565 - val_mae: 8.3316\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4968 - acc: 0.9364 - mse: 169.8620 - mae: 8.4420 - val_loss: 10.3326 - val_acc: 0.9384 - val_mse: 167.0723 - val_mae: 8.3193\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4971 - acc: 0.9364 - mse: 169.7953 - mae: 8.4422 - val_loss: 10.3677 - val_acc: 0.9375 - val_mse: 167.4040 - val_mae: 8.3460\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.5021 - acc: 0.9364 - mse: 169.9509 - mae: 8.4460 - val_loss: 10.3566 - val_acc: 0.9374 - val_mse: 166.5101 - val_mae: 8.3373\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4918 - acc: 0.9365 - mse: 169.7648 - mae: 8.4383 - val_loss: 10.3266 - val_acc: 0.9379 - val_mse: 166.3686 - val_mae: 8.3146\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4998 - acc: 0.9365 - mse: 169.8825 - mae: 8.4443 - val_loss: 10.3556 - val_acc: 0.9385 - val_mse: 167.3927 - val_mae: 8.3360\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4947 - acc: 0.9364 - mse: 169.8015 - mae: 8.4404 - val_loss: 10.3551 - val_acc: 0.9371 - val_mse: 166.8200 - val_mae: 8.3359\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4946 - acc: 0.9365 - mse: 169.8257 - mae: 8.4403 - val_loss: 10.3643 - val_acc: 0.9383 - val_mse: 167.2303 - val_mae: 8.3424\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0019770064391195774.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4956 - acc: 0.9365 - mse: 169.7668 - mae: 8.4411 - val_loss: 10.3374 - val_acc: 0.9372 - val_mse: 166.3708 - val_mae: 8.3228\n",
      "\n",
      "Epoch 00120: saving model to checkpoints/model_ckpt_epoch_120.hdf5\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0017793057952076197.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4952 - acc: 0.9366 - mse: 169.7942 - mae: 8.4409 - val_loss: 10.3223 - val_acc: 0.9380 - val_mse: 166.6696 - val_mae: 8.3116\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.4922 - acc: 0.9364 - mse: 169.7134 - mae: 8.4386 - val_loss: 10.3253 - val_acc: 0.9387 - val_mse: 166.5594 - val_mae: 8.3136\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 10.4924 - acc: 0.9364 - mse: 169.7474 - mae: 8.4387 - val_loss: 10.3298 - val_acc: 0.9379 - val_mse: 166.7286 - val_mae: 8.3171\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      "1013/1013 [==============================] - 15s 15ms/step - loss: 10.4962 - acc: 0.9365 - mse: 169.8241 - mae: 8.4415 - val_loss: 10.3485 - val_acc: 0.9380 - val_mse: 166.5804 - val_mae: 8.3311\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.001779305748641491.\n",
      " 591/1013 [================>.............] - ETA: 6s - loss: 10.5016 - acc: 0.9363 - mse: 169.9321 - mae: 8.4457"
     ]
    }
   ],
   "source": [
    "assert(keras.backend.backend() == 'tensorflow')\n",
    "\n",
    "normal_epochs = 300\n",
    "normal_batch_size = 2000\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "learning_rate = 0.0063\n",
    "gradient_clip_norm = 100.\n",
    "\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "model_training_checkpoint = ModelCheckpoint(monitor=\"val_loss\", \n",
    "                                           verbose = 1,\n",
    "                                           filepath = \"checkpoints/model_ckpt_epoch_{epoch:02d}.hdf5\",\n",
    "                                           period = 10)\n",
    "model = create_model(\n",
    "                    nvariables = NVARIABLES, \n",
    "                    lr = learning_rate, \n",
    "                    clipnorm = gradient_clip_norm, \n",
    "                    nodes1=10, \n",
    "                    nodes2=7, \n",
    "                    nodes3=5, \n",
    "                    outnodes=2,\n",
    "                    l1_reg = l1_reg, \n",
    "                    l2_reg = l2_reg)\n",
    "\n",
    "logger.info('Training model with l1_reg: {0} l2_reg: {1}'.format(l1_reg, l2_reg))\n",
    "\n",
    "model, history = train_model(model, \n",
    "                      x_train_displ, \n",
    "                      np.column_stack((y_train_displ, dxy_train_displ)),\n",
    "                      save_model=False, \n",
    "                      epochs=normal_epochs, \n",
    "                      batch_size=normal_batch_size,\n",
    "                      callbacks=[lr_decay,terminate_on_nan, model_training_checkpoint], \n",
    "                      validation_split=0.1, \n",
    "                      verbose=True)\n",
    "\n",
    "metrics = [len(history.history['loss']), history.history['loss'][-1], history.history['val_loss'][-1]]\n",
    "logger.info('Epoch {0}/{0} - loss: {1} - val_loss: {2}'.format(*metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d2f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
