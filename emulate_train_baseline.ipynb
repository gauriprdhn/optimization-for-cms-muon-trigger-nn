{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76497b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "1.3.4\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "# Script Imports\n",
    "from nn_globals import *\n",
    "from nn_plotting import __generate_delta_plots__\n",
    "from dataset import muon_data_split\n",
    "from nn_evaluate import huber_loss, k_fold_validation\n",
    "from nn_training import train_model, lr_schedule\n",
    "# Keras/TF import\n",
    "from keras.models import Model, load_model\n",
    "from keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, BatchNormalization, Dense, Activation\n",
    "from keras.callbacks import LearningRateScheduler, TerminateOnNaN, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be3d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading muon data from ./data/NN_input_params_FlatXYZ.npz ...\n",
      "[INFO    ] Loaded the variables with shape (19300000, 25)\n",
      "[INFO    ] Loaded the parameters with shape (19300000, 6)\n",
      "[INFO    ] Loaded the encoded variables with shape (3284620, 23)\n",
      "[INFO    ] Loaded the encoded parameters with shape (3284620,)\n",
      "[INFO    ] Loaded # of training and testing events: (2249964, 1034656)\n",
      "[WARNING ] The last batch for training could be too few! (2024967%128)=7. Please change test_size.\n",
      "[WARNING ] Try this formula: int(int(3284620*0.685)*0.9) % 128\n",
      "[WARNING ] The last batch for training after mixing could be too few! (4049935%128)=15. Please change test_size.\n",
      "[WARNING ] Try this formula: int(int(3284620*0.685)*2*0.9) % 128\n"
     ]
    }
   ],
   "source": [
    "# Import muon data\n",
    "# 'x' is the array of input variables, 'y' is the q/pT\n",
    "x_train_displ, x_test_displ, y_train_displ, y_test_displ, dxy_train_displ, dxy_test_displ= muon_data_split(filename=DATAFILEPATH, \n",
    "                                                                                                           reg_pt_scale=REG_PT_SCALE, \n",
    "                                                                                                           reg_dxy_scale=REG_DXY_SCALE, \n",
    "                                                                                                           test_size=TEST_SIZE,\n",
    "                                                                                                           nvariables = NVARIABLES,\n",
    "                                                                                                           nentries= NENTRIES,\n",
    "                                                                                                           batch_size = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69e3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nvariables, lr=0.001, clipnorm=10., initializer = \"glorot_uniform\",\n",
    "                nodes1=64, nodes2=32, nodes3=16, outnodes=2,\n",
    "                l1_reg = 0.0, l2_reg = 0.0):\n",
    "  \n",
    "    regularizer = L1L2(l1=l1_reg, l2=l2_reg)\n",
    "    bn_momentum = 0.9\n",
    "    eps = 1e-4\n",
    "\n",
    "    x = x_in = Input((nvariables,))\n",
    "    x = BatchNormalization(epsilon=eps, momentum=bn_momentum,name=\"bn-input\")(x)\n",
    "    \n",
    "    x = Dense(nodes1, \n",
    "               kernel_initializer=initializer,\n",
    "               use_bias = False,\n",
    "               kernel_regularizer = regularizer,\n",
    "               name=\"hidden-dense-1\")(x)\n",
    "    x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-1\")(x)\n",
    "    x = Activation(activation = \"tanh\",name=\"act_1\")(x)\n",
    "    \n",
    "    if nodes2:\n",
    "    \n",
    "        x = Dense(nodes2, \n",
    "                   kernel_initializer=initializer,\n",
    "                   use_bias = False,\n",
    "                   kernel_regularizer = regularizer,\n",
    "                   name=\"hidden-dense-2\")(x)\n",
    "        x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-2\")(x)\n",
    "        x = Activation(activation = \"tanh\",name=\"act_2\")(x)\n",
    "        if nodes3:\n",
    "\n",
    "            x = Dense(nodes3, \n",
    "                       kernel_initializer=initializer,\n",
    "                       kernel_regularizer = regularizer,\n",
    "                       use_bias = False,\n",
    "                       name=\"hidden-dense-3\")(x)\n",
    "            x = BatchNormalization(epsilon = eps, momentum  = bn_momentum, name = \"bn-3\")(x)\n",
    "            x = Activation(activation = \"tanh\", name=\"act_3\")(x)\n",
    "\n",
    "    x = Dense(outnodes,kernel_initializer = initializer,name=\"dense-output\")(x)\n",
    "    x = Activation(\"linear\")(x)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=x,name=\"baseline-model\")\n",
    "    \n",
    "    adam = Adam(lr=lr, clipnorm=clipnorm)\n",
    "    model.compile(optimizer=adam, \n",
    "                  loss=huber_loss, \n",
    "                  metrics=['acc','mse','mae'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c420cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Training model with l1_reg: 0.0 l2_reg: 0.0\n",
      "[INFO    ] Begin training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline-model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "bn-input (BatchNormalization (None, 23)                92        \n",
      "_________________________________________________________________\n",
      "hidden-dense-1 (Dense)       (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "bn-1 (BatchNormalization)    (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "act_1 (Activation)           (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "hidden-dense-2 (Dense)       (None, 7)                 70        \n",
      "_________________________________________________________________\n",
      "bn-2 (BatchNormalization)    (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "act_2 (Activation)           (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "hidden-dense-3 (Dense)       (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "bn-3 (BatchNormalization)    (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "act_3 (Activation)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense-output (Dense)         (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 527\n",
      "Trainable params: 437\n",
      "Non-trainable params: 90\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.05000000074505806.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 16:50:24.802376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - ETA: 0s - loss: 14.9906 - acc: 0.9247 - mse: 348.6965 - mae: 11.7935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 16:50:54.930642: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 31s 15ms/step - loss: 14.9906 - acc: 0.9247 - mse: 348.6965 - mae: 11.7935 - val_loss: 12.3924 - val_acc: 0.9334 - val_mse: 209.0125 - val_mae: 9.8593\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.7682 - acc: 0.9307 - mse: 195.4521 - mae: 9.3938 - val_loss: 11.6826 - val_acc: 0.9342 - val_mse: 194.5160 - val_mae: 9.3302\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.5659 - acc: 0.9321 - mse: 191.2361 - mae: 9.2424 - val_loss: 11.3635 - val_acc: 0.9347 - val_mse: 187.6433 - val_mae: 9.0913\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.5146 - acc: 0.9322 - mse: 190.3987 - mae: 9.2041 - val_loss: 11.5310 - val_acc: 0.9333 - val_mse: 190.7330 - val_mae: 9.2159\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.4797 - acc: 0.9323 - mse: 189.8249 - mae: 9.1780 - val_loss: 11.6899 - val_acc: 0.9348 - val_mse: 194.4746 - val_mae: 9.3348\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.4404 - acc: 0.9325 - mse: 189.1421 - mae: 9.1486 - val_loss: 11.4693 - val_acc: 0.9342 - val_mse: 188.5610 - val_mae: 9.1713\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.4244 - acc: 0.9326 - mse: 188.8359 - mae: 9.1366 - val_loss: 11.3957 - val_acc: 0.9308 - val_mse: 189.7179 - val_mae: 9.1151\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.4061 - acc: 0.9328 - mse: 188.6769 - mae: 9.1229 - val_loss: 11.1598 - val_acc: 0.9356 - val_mse: 183.3369 - val_mae: 8.9383\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.4020 - acc: 0.9326 - mse: 188.5373 - mae: 9.1199 - val_loss: 11.3605 - val_acc: 0.9358 - val_mse: 187.5794 - val_mae: 9.0890\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.05000000074505806.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3953 - acc: 0.9327 - mse: 188.4971 - mae: 9.1149 - val_loss: 12.7866 - val_acc: 0.9286 - val_mse: 226.3973 - val_mae: 10.1513\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/model_ckpt_epoch_10.hdf5\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.04500000067055226.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3705 - acc: 0.9328 - mse: 187.8328 - mae: 9.0963 - val_loss: 11.0981 - val_acc: 0.9357 - val_mse: 182.5783 - val_mae: 8.8925\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3518 - acc: 0.9328 - mse: 187.7071 - mae: 9.0823 - val_loss: 11.1854 - val_acc: 0.9328 - val_mse: 184.7010 - val_mae: 8.9575\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3373 - acc: 0.9330 - mse: 187.3669 - mae: 9.0715 - val_loss: 11.4185 - val_acc: 0.9342 - val_mse: 190.0515 - val_mae: 9.1319\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3449 - acc: 0.9329 - mse: 187.4494 - mae: 9.0771 - val_loss: 12.8552 - val_acc: 0.9154 - val_mse: 229.9379 - val_mae: 10.2027\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3129 - acc: 0.9332 - mse: 186.8553 - mae: 9.0532 - val_loss: 11.1102 - val_acc: 0.9345 - val_mse: 181.8342 - val_mae: 8.9016\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.3187 - acc: 0.9334 - mse: 186.7853 - mae: 9.0575 - val_loss: 11.6273 - val_acc: 0.9327 - val_mse: 198.2563 - val_mae: 9.2872\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3090 - acc: 0.9335 - mse: 186.8747 - mae: 9.0501 - val_loss: 10.9848 - val_acc: 0.9362 - val_mse: 180.1115 - val_mae: 8.8073\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2885 - acc: 0.9337 - mse: 186.1743 - mae: 9.0350 - val_loss: 12.1415 - val_acc: 0.9295 - val_mse: 210.6086 - val_mae: 9.6702\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.3053 - acc: 0.9335 - mse: 186.6063 - mae: 9.0473 - val_loss: 10.9350 - val_acc: 0.9361 - val_mse: 179.1934 - val_mae: 8.7706\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.04500000178813934.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2917 - acc: 0.9336 - mse: 186.3187 - mae: 9.0372 - val_loss: 11.0208 - val_acc: 0.9351 - val_mse: 180.1474 - val_mae: 8.8354\n",
      "\n",
      "Epoch 00020: saving model to checkpoints/model_ckpt_epoch_20.hdf5\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.04050000160932541.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2585 - acc: 0.9339 - mse: 185.6393 - mae: 9.0124 - val_loss: 10.9814 - val_acc: 0.9360 - val_mse: 180.1662 - val_mae: 8.8050\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2452 - acc: 0.9338 - mse: 185.3172 - mae: 9.0025 - val_loss: 11.4722 - val_acc: 0.9300 - val_mse: 191.9804 - val_mae: 9.1711\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2608 - acc: 0.9339 - mse: 185.7137 - mae: 9.0141 - val_loss: 10.9310 - val_acc: 0.9367 - val_mse: 178.1402 - val_mae: 8.7672\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2540 - acc: 0.9340 - mse: 185.5179 - mae: 9.0090 - val_loss: 11.0397 - val_acc: 0.9352 - val_mse: 181.1332 - val_mae: 8.8485\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.2452 - acc: 0.9340 - mse: 185.3311 - mae: 9.0025 - val_loss: 10.9209 - val_acc: 0.9361 - val_mse: 178.2841 - val_mae: 8.7602\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.2249 - acc: 0.9342 - mse: 184.9682 - mae: 8.9872 - val_loss: 11.2706 - val_acc: 0.9337 - val_mse: 185.0274 - val_mae: 9.0216\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2438 - acc: 0.9338 - mse: 185.3960 - mae: 9.0012 - val_loss: 11.0183 - val_acc: 0.9346 - val_mse: 182.7804 - val_mae: 8.8324\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2285 - acc: 0.9341 - mse: 185.0215 - mae: 8.9899 - val_loss: 11.6870 - val_acc: 0.9325 - val_mse: 197.8067 - val_mae: 9.3316\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.04050000011920929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2248 - acc: 0.9341 - mse: 184.9808 - mae: 8.9871 - val_loss: 11.1579 - val_acc: 0.9370 - val_mse: 183.6069 - val_mae: 8.9367\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.04050000011920929.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2281 - acc: 0.9339 - mse: 184.9450 - mae: 8.9895 - val_loss: 11.2776 - val_acc: 0.9362 - val_mse: 186.9651 - val_mae: 9.0261\n",
      "\n",
      "Epoch 00030: saving model to checkpoints/model_ckpt_epoch_30.hdf5\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.03645000010728836.\n",
      "2025/2025 [==============================] - 34s 17ms/step - loss: 11.2143 - acc: 0.9340 - mse: 184.8260 - mae: 8.9791 - val_loss: 10.9192 - val_acc: 0.9357 - val_mse: 178.7287 - val_mae: 8.7584\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 11.1946 - acc: 0.9342 - mse: 184.3702 - mae: 8.9645 - val_loss: 11.2029 - val_acc: 0.9361 - val_mse: 186.4521 - val_mae: 8.9704\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 11.2079 - acc: 0.9340 - mse: 184.5693 - mae: 8.9745 - val_loss: 11.2267 - val_acc: 0.9346 - val_mse: 184.6248 - val_mae: 8.9884\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2041 - acc: 0.9342 - mse: 184.6383 - mae: 8.9716 - val_loss: 11.1109 - val_acc: 0.9336 - val_mse: 183.3383 - val_mae: 8.9017\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.1911 - acc: 0.9343 - mse: 184.2596 - mae: 8.9619 - val_loss: 10.8951 - val_acc: 0.9350 - val_mse: 177.9459 - val_mae: 8.7403\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1900 - acc: 0.9341 - mse: 184.2014 - mae: 8.9612 - val_loss: 10.8632 - val_acc: 0.9358 - val_mse: 177.2597 - val_mae: 8.7169\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2012 - acc: 0.9341 - mse: 184.5936 - mae: 8.9694 - val_loss: 10.9490 - val_acc: 0.9359 - val_mse: 179.7956 - val_mae: 8.7805\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1965 - acc: 0.9340 - mse: 184.5198 - mae: 8.9659 - val_loss: 11.1237 - val_acc: 0.9327 - val_mse: 182.2843 - val_mae: 8.9113\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.1984 - acc: 0.9343 - mse: 184.4814 - mae: 8.9674 - val_loss: 10.9345 - val_acc: 0.9351 - val_mse: 178.4903 - val_mae: 8.7698\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.03644999861717224.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.2028 - acc: 0.9342 - mse: 184.4570 - mae: 8.9707 - val_loss: 11.0618 - val_acc: 0.9348 - val_mse: 180.7348 - val_mae: 8.8648\n",
      "\n",
      "Epoch 00040: saving model to checkpoints/model_ckpt_epoch_40.hdf5\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.03280499875545502.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1528 - acc: 0.9344 - mse: 183.3934 - mae: 8.9333 - val_loss: 10.9510 - val_acc: 0.9359 - val_mse: 178.1703 - val_mae: 8.7827\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.1597 - acc: 0.9344 - mse: 183.5814 - mae: 8.9385 - val_loss: 10.9572 - val_acc: 0.9360 - val_mse: 178.7469 - val_mae: 8.7873\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.1741 - acc: 0.9342 - mse: 183.8909 - mae: 8.9492 - val_loss: 11.0442 - val_acc: 0.9352 - val_mse: 184.0568 - val_mae: 8.8515\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1737 - acc: 0.9342 - mse: 183.9627 - mae: 8.9488 - val_loss: 10.9578 - val_acc: 0.9361 - val_mse: 179.4823 - val_mae: 8.7880\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1623 - acc: 0.9344 - mse: 183.7695 - mae: 8.9403 - val_loss: 11.0180 - val_acc: 0.9358 - val_mse: 179.7666 - val_mae: 8.8329\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1704 - acc: 0.9343 - mse: 183.7739 - mae: 8.9465 - val_loss: 10.9939 - val_acc: 0.9347 - val_mse: 181.0738 - val_mae: 8.8142\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1696 - acc: 0.9342 - mse: 183.9156 - mae: 8.9458 - val_loss: 10.9917 - val_acc: 0.9360 - val_mse: 180.3777 - val_mae: 8.8124\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1704 - acc: 0.9341 - mse: 183.6847 - mae: 8.9464 - val_loss: 11.1288 - val_acc: 0.9356 - val_mse: 183.8139 - val_mae: 8.9152\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1692 - acc: 0.9341 - mse: 183.8931 - mae: 8.9455 - val_loss: 10.8847 - val_acc: 0.9367 - val_mse: 177.5418 - val_mae: 8.7327\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.03280499950051308.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1828 - acc: 0.9340 - mse: 184.2008 - mae: 8.9557 - val_loss: 11.0356 - val_acc: 0.9357 - val_mse: 181.0222 - val_mae: 8.8459\n",
      "\n",
      "Epoch 00050: saving model to checkpoints/model_ckpt_epoch_50.hdf5\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1568 - acc: 0.9340 - mse: 183.5870 - mae: 8.9362 - val_loss: 11.1099 - val_acc: 0.9342 - val_mse: 182.2470 - val_mae: 8.9014\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1324 - acc: 0.9343 - mse: 183.0125 - mae: 8.9181 - val_loss: 10.8940 - val_acc: 0.9358 - val_mse: 178.3767 - val_mae: 8.7397\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1610 - acc: 0.9341 - mse: 183.7305 - mae: 8.9394 - val_loss: 10.9102 - val_acc: 0.9345 - val_mse: 180.2333 - val_mae: 8.7520\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.1454 - acc: 0.9341 - mse: 183.2937 - mae: 8.9278 - val_loss: 10.9684 - val_acc: 0.9356 - val_mse: 180.4723 - val_mae: 8.7955\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.1379 - acc: 0.9342 - mse: 183.0639 - mae: 8.9222 - val_loss: 10.9937 - val_acc: 0.9358 - val_mse: 181.7366 - val_mae: 8.8140\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.1682 - acc: 0.9337 - mse: 183.8850 - mae: 8.9447 - val_loss: 11.1729 - val_acc: 0.9351 - val_mse: 182.8304 - val_mae: 8.9491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 11.1312 - acc: 0.9342 - mse: 183.0808 - mae: 8.9171 - val_loss: 10.9373 - val_acc: 0.9357 - val_mse: 178.8336 - val_mae: 8.7717\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1375 - acc: 0.9340 - mse: 183.2132 - mae: 8.9218 - val_loss: 11.3128 - val_acc: 0.9327 - val_mse: 187.3358 - val_mae: 9.0522\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1463 - acc: 0.9341 - mse: 183.3740 - mae: 8.9285 - val_loss: 10.9573 - val_acc: 0.9329 - val_mse: 179.3577 - val_mae: 8.7872\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.02952449955046177.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1425 - acc: 0.9341 - mse: 183.2327 - mae: 8.9256 - val_loss: 10.8286 - val_acc: 0.9352 - val_mse: 177.3411 - val_mae: 8.6906\n",
      "\n",
      "Epoch 00060: saving model to checkpoints/model_ckpt_epoch_60.hdf5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.026572049595415592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1339 - acc: 0.9340 - mse: 183.0551 - mae: 8.9192 - val_loss: 10.9265 - val_acc: 0.9362 - val_mse: 180.8457 - val_mae: 8.7637\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1406 - acc: 0.9341 - mse: 183.3153 - mae: 8.9241 - val_loss: 11.4018 - val_acc: 0.9336 - val_mse: 190.7067 - val_mae: 9.1190\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1165 - acc: 0.9343 - mse: 182.7505 - mae: 8.9061 - val_loss: 11.0135 - val_acc: 0.9340 - val_mse: 180.5434 - val_mae: 8.8288\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1333 - acc: 0.9340 - mse: 183.0929 - mae: 8.9187 - val_loss: 11.0823 - val_acc: 0.9349 - val_mse: 181.1515 - val_mae: 8.8809\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1312 - acc: 0.9341 - mse: 182.9642 - mae: 8.9171 - val_loss: 11.0137 - val_acc: 0.9359 - val_mse: 180.8612 - val_mae: 8.8288\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1291 - acc: 0.9340 - mse: 182.9742 - mae: 8.9156 - val_loss: 10.9048 - val_acc: 0.9358 - val_mse: 179.3341 - val_mae: 8.7477\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1217 - acc: 0.9341 - mse: 182.9157 - mae: 8.9100 - val_loss: 10.9683 - val_acc: 0.9364 - val_mse: 180.4712 - val_mae: 8.7952\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.1162 - acc: 0.9341 - mse: 182.7227 - mae: 8.9060 - val_loss: 10.9062 - val_acc: 0.9355 - val_mse: 178.8508 - val_mae: 8.7484\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1262 - acc: 0.9342 - mse: 182.8960 - mae: 8.9135 - val_loss: 10.8461 - val_acc: 0.9363 - val_mse: 177.9727 - val_mae: 8.7038\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.026572048664093018.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1269 - acc: 0.9341 - mse: 182.9807 - mae: 8.9139 - val_loss: 11.0039 - val_acc: 0.9358 - val_mse: 180.5710 - val_mae: 8.8220\n",
      "\n",
      "Epoch 00070: saving model to checkpoints/model_ckpt_epoch_70.hdf5\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1136 - acc: 0.9341 - mse: 182.6272 - mae: 8.9039 - val_loss: 10.8069 - val_acc: 0.9362 - val_mse: 176.9447 - val_mae: 8.6743\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1034 - acc: 0.9342 - mse: 182.4520 - mae: 8.8964 - val_loss: 10.8791 - val_acc: 0.9352 - val_mse: 178.5042 - val_mae: 8.7284\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1020 - acc: 0.9341 - mse: 182.3439 - mae: 8.8953 - val_loss: 10.9075 - val_acc: 0.9347 - val_mse: 178.4045 - val_mae: 8.7493\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.1113 - acc: 0.9341 - mse: 182.6811 - mae: 8.9023 - val_loss: 11.0172 - val_acc: 0.9349 - val_mse: 181.9080 - val_mae: 8.8314\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1039 - acc: 0.9341 - mse: 182.4638 - mae: 8.8967 - val_loss: 11.0244 - val_acc: 0.9356 - val_mse: 181.5046 - val_mae: 8.8372\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.0938 - acc: 0.9342 - mse: 182.2594 - mae: 8.8892 - val_loss: 10.9588 - val_acc: 0.9346 - val_mse: 179.3192 - val_mae: 8.7879\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1035 - acc: 0.9340 - mse: 182.5770 - mae: 8.8965 - val_loss: 11.3272 - val_acc: 0.9330 - val_mse: 187.5797 - val_mae: 9.0632\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1038 - acc: 0.9342 - mse: 182.5968 - mae: 8.8966 - val_loss: 11.1190 - val_acc: 0.9334 - val_mse: 183.7407 - val_mae: 8.9076\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1066 - acc: 0.9341 - mse: 182.5996 - mae: 8.8988 - val_loss: 11.3703 - val_acc: 0.9318 - val_mse: 188.1348 - val_mae: 9.0952\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.023914843797683716.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1078 - acc: 0.9342 - mse: 182.5977 - mae: 8.8998 - val_loss: 11.1679 - val_acc: 0.9356 - val_mse: 186.0321 - val_mae: 8.9435\n",
      "\n",
      "Epoch 00080: saving model to checkpoints/model_ckpt_epoch_80.hdf5\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.021523359417915344.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.1010 - acc: 0.9342 - mse: 182.4804 - mae: 8.8946 - val_loss: 10.9207 - val_acc: 0.9354 - val_mse: 179.7070 - val_mae: 8.7592\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0796 - acc: 0.9343 - mse: 181.9352 - mae: 8.8786 - val_loss: 10.8695 - val_acc: 0.9352 - val_mse: 177.9339 - val_mae: 8.7211\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.0825 - acc: 0.9342 - mse: 182.0662 - mae: 8.8808 - val_loss: 11.0087 - val_acc: 0.9356 - val_mse: 182.0690 - val_mae: 8.8249\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0949 - acc: 0.9341 - mse: 182.5525 - mae: 8.8899 - val_loss: 11.2675 - val_acc: 0.9309 - val_mse: 187.1034 - val_mae: 9.0186\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 11.0870 - acc: 0.9342 - mse: 182.1594 - mae: 8.8841 - val_loss: 10.9132 - val_acc: 0.9360 - val_mse: 180.6830 - val_mae: 8.7536\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0882 - acc: 0.9342 - mse: 182.2334 - mae: 8.8851 - val_loss: 10.8318 - val_acc: 0.9354 - val_mse: 177.5811 - val_mae: 8.6931\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0970 - acc: 0.9340 - mse: 182.3686 - mae: 8.8915 - val_loss: 10.8739 - val_acc: 0.9363 - val_mse: 179.3995 - val_mae: 8.7244\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0826 - acc: 0.9342 - mse: 182.1098 - mae: 8.8808 - val_loss: 10.9095 - val_acc: 0.9361 - val_mse: 179.8682 - val_mae: 8.7511\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0858 - acc: 0.9341 - mse: 182.2517 - mae: 8.8832 - val_loss: 10.7767 - val_acc: 0.9361 - val_mse: 176.0276 - val_mae: 8.6517\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.021523360162973404.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0949 - acc: 0.9342 - mse: 182.3415 - mae: 8.8899 - val_loss: 10.7989 - val_acc: 0.9356 - val_mse: 176.1436 - val_mae: 8.6689\n",
      "\n",
      "Epoch 00090: saving model to checkpoints/model_ckpt_epoch_90.hdf5\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.019371024146676064.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 11.0729 - acc: 0.9342 - mse: 181.8842 - mae: 8.8736 - val_loss: 10.8511 - val_acc: 0.9352 - val_mse: 179.1021 - val_mae: 8.7076\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0718 - acc: 0.9341 - mse: 181.8419 - mae: 8.8726 - val_loss: 11.0766 - val_acc: 0.9350 - val_mse: 186.7901 - val_mae: 8.8754\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0642 - acc: 0.9342 - mse: 181.7039 - mae: 8.8670 - val_loss: 10.9353 - val_acc: 0.9335 - val_mse: 179.7360 - val_mae: 8.7707\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0642 - acc: 0.9343 - mse: 181.6839 - mae: 8.8671 - val_loss: 10.9618 - val_acc: 0.9356 - val_mse: 181.0612 - val_mae: 8.7902\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0716 - acc: 0.9342 - mse: 181.9991 - mae: 8.8726 - val_loss: 10.8462 - val_acc: 0.9351 - val_mse: 177.2401 - val_mae: 8.7041\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0727 - acc: 0.9344 - mse: 181.9412 - mae: 8.8733 - val_loss: 10.7951 - val_acc: 0.9363 - val_mse: 176.1520 - val_mae: 8.6657\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0654 - acc: 0.9342 - mse: 181.6593 - mae: 8.8679 - val_loss: 10.7976 - val_acc: 0.9363 - val_mse: 177.0224 - val_mae: 8.6674\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0746 - acc: 0.9342 - mse: 181.9659 - mae: 8.8747 - val_loss: 10.8192 - val_acc: 0.9368 - val_mse: 177.3571 - val_mae: 8.6839\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0792 - acc: 0.9342 - mse: 181.9874 - mae: 8.8782 - val_loss: 10.9470 - val_acc: 0.9340 - val_mse: 180.0748 - val_mae: 8.7793\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.019371023401618004.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.0600 - acc: 0.9343 - mse: 181.5806 - mae: 8.8639 - val_loss: 10.8898 - val_acc: 0.9365 - val_mse: 177.7370 - val_mae: 8.7364\n",
      "\n",
      "Epoch 00100: saving model to checkpoints/model_ckpt_epoch_100.hdf5\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.017433921061456203.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.0637 - acc: 0.9342 - mse: 181.7997 - mae: 8.8667 - val_loss: 10.7743 - val_acc: 0.9354 - val_mse: 175.3618 - val_mae: 8.6503\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0510 - acc: 0.9344 - mse: 181.4604 - mae: 8.8572 - val_loss: 10.8478 - val_acc: 0.9351 - val_mse: 178.7547 - val_mae: 8.7047\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0460 - acc: 0.9344 - mse: 181.2745 - mae: 8.8535 - val_loss: 10.9445 - val_acc: 0.9357 - val_mse: 180.6636 - val_mae: 8.7773\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.0484 - acc: 0.9344 - mse: 181.4001 - mae: 8.8552 - val_loss: 11.0220 - val_acc: 0.9346 - val_mse: 182.2208 - val_mae: 8.8351\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0585 - acc: 0.9343 - mse: 181.6461 - mae: 8.8627 - val_loss: 11.2305 - val_acc: 0.9331 - val_mse: 186.8202 - val_mae: 8.9907\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0554 - acc: 0.9342 - mse: 181.7599 - mae: 8.8604 - val_loss: 10.7997 - val_acc: 0.9352 - val_mse: 176.3591 - val_mae: 8.6692\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0564 - acc: 0.9345 - mse: 181.6223 - mae: 8.8613 - val_loss: 10.7851 - val_acc: 0.9362 - val_mse: 175.8078 - val_mae: 8.6582\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0452 - acc: 0.9343 - mse: 181.3428 - mae: 8.8529 - val_loss: 10.8446 - val_acc: 0.9357 - val_mse: 177.1466 - val_mae: 8.7022\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.0536 - acc: 0.9343 - mse: 181.6181 - mae: 8.8591 - val_loss: 10.8818 - val_acc: 0.9361 - val_mse: 179.9975 - val_mae: 8.7303\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.01743392087519169.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0572 - acc: 0.9343 - mse: 181.6860 - mae: 8.8618 - val_loss: 10.8750 - val_acc: 0.9347 - val_mse: 177.9731 - val_mae: 8.7256\n",
      "\n",
      "Epoch 00110: saving model to checkpoints/model_ckpt_epoch_110.hdf5\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.01569052878767252.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0435 - acc: 0.9342 - mse: 181.3039 - mae: 8.8516 - val_loss: 10.7548 - val_acc: 0.9358 - val_mse: 175.6594 - val_mae: 8.6357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 11.0521 - acc: 0.9342 - mse: 181.6015 - mae: 8.8579 - val_loss: 10.8328 - val_acc: 0.9363 - val_mse: 176.6313 - val_mae: 8.6940\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0459 - acc: 0.9343 - mse: 181.4330 - mae: 8.8534 - val_loss: 10.9519 - val_acc: 0.9354 - val_mse: 181.7891 - val_mae: 8.7825\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0410 - acc: 0.9343 - mse: 181.2193 - mae: 8.8497 - val_loss: 10.9053 - val_acc: 0.9359 - val_mse: 178.8686 - val_mae: 8.7481\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0458 - acc: 0.9343 - mse: 181.3868 - mae: 8.8532 - val_loss: 10.9604 - val_acc: 0.9335 - val_mse: 181.1726 - val_mae: 8.7892\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0556 - acc: 0.9342 - mse: 181.5841 - mae: 8.8606 - val_loss: 10.8090 - val_acc: 0.9349 - val_mse: 177.4901 - val_mae: 8.6762\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0450 - acc: 0.9344 - mse: 181.3895 - mae: 8.8527 - val_loss: 10.8378 - val_acc: 0.9365 - val_mse: 177.9694 - val_mae: 8.6976\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0383 - acc: 0.9344 - mse: 181.3726 - mae: 8.8477 - val_loss: 11.2003 - val_acc: 0.9343 - val_mse: 186.4954 - val_mae: 8.9681\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0367 - acc: 0.9344 - mse: 181.1776 - mae: 8.8465 - val_loss: 10.7775 - val_acc: 0.9352 - val_mse: 175.5634 - val_mae: 8.6526\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.015690527856349945.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0369 - acc: 0.9344 - mse: 181.2234 - mae: 8.8466 - val_loss: 10.8833 - val_acc: 0.9358 - val_mse: 177.8158 - val_mae: 8.7317\n",
      "\n",
      "Epoch 00120: saving model to checkpoints/model_ckpt_epoch_120.hdf5\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.014121475070714951.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0334 - acc: 0.9344 - mse: 181.1796 - mae: 8.8440 - val_loss: 11.1251 - val_acc: 0.9328 - val_mse: 182.9925 - val_mae: 8.9127\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0273 - acc: 0.9346 - mse: 181.0774 - mae: 8.8394 - val_loss: 10.7314 - val_acc: 0.9361 - val_mse: 175.3722 - val_mae: 8.6179\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0302 - acc: 0.9344 - mse: 181.1319 - mae: 8.8415 - val_loss: 10.7527 - val_acc: 0.9366 - val_mse: 175.9019 - val_mae: 8.6341\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0254 - acc: 0.9345 - mse: 181.0366 - mae: 8.8380 - val_loss: 11.0347 - val_acc: 0.9335 - val_mse: 181.0089 - val_mae: 8.8452\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0311 - acc: 0.9344 - mse: 181.1975 - mae: 8.8422 - val_loss: 10.8669 - val_acc: 0.9356 - val_mse: 179.1006 - val_mae: 8.7190\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0359 - acc: 0.9344 - mse: 181.2603 - mae: 8.8459 - val_loss: 10.8646 - val_acc: 0.9344 - val_mse: 178.3635 - val_mae: 8.7173\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0347 - acc: 0.9344 - mse: 181.2092 - mae: 8.8449 - val_loss: 10.7697 - val_acc: 0.9365 - val_mse: 176.3420 - val_mae: 8.6471\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0313 - acc: 0.9345 - mse: 181.2379 - mae: 8.8425 - val_loss: 10.7931 - val_acc: 0.9359 - val_mse: 176.5540 - val_mae: 8.6643\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 11.0205 - acc: 0.9347 - mse: 180.9008 - mae: 8.8343 - val_loss: 10.9907 - val_acc: 0.9339 - val_mse: 181.7923 - val_mae: 8.8117\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.01412147469818592.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0291 - acc: 0.9344 - mse: 181.1402 - mae: 8.8408 - val_loss: 11.3784 - val_acc: 0.9338 - val_mse: 191.0311 - val_mae: 9.1011\n",
      "\n",
      "Epoch 00130: saving model to checkpoints/model_ckpt_epoch_130.hdf5\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.01270932722836733.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0113 - acc: 0.9345 - mse: 180.7881 - mae: 8.8274 - val_loss: 10.7269 - val_acc: 0.9361 - val_mse: 175.4204 - val_mae: 8.6148\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0235 - acc: 0.9345 - mse: 181.0335 - mae: 8.8366 - val_loss: 10.8052 - val_acc: 0.9362 - val_mse: 177.5288 - val_mae: 8.6730\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0212 - acc: 0.9345 - mse: 181.0047 - mae: 8.8349 - val_loss: 10.7903 - val_acc: 0.9357 - val_mse: 176.4474 - val_mae: 8.6622\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0159 - acc: 0.9345 - mse: 180.9847 - mae: 8.8309 - val_loss: 10.7605 - val_acc: 0.9356 - val_mse: 175.9628 - val_mae: 8.6399\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0224 - acc: 0.9345 - mse: 181.0424 - mae: 8.8358 - val_loss: 10.7732 - val_acc: 0.9361 - val_mse: 175.9083 - val_mae: 8.6493\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0085 - acc: 0.9346 - mse: 180.6937 - mae: 8.8255 - val_loss: 10.8174 - val_acc: 0.9365 - val_mse: 178.0811 - val_mae: 8.6818\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 11.0254 - acc: 0.9345 - mse: 181.0903 - mae: 8.8380 - val_loss: 10.9468 - val_acc: 0.9337 - val_mse: 180.0209 - val_mae: 8.7792\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0183 - acc: 0.9345 - mse: 180.9472 - mae: 8.8327 - val_loss: 10.7963 - val_acc: 0.9359 - val_mse: 176.1507 - val_mae: 8.6662\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0096 - acc: 0.9346 - mse: 180.7704 - mae: 8.8261 - val_loss: 10.7822 - val_acc: 0.9367 - val_mse: 176.4775 - val_mae: 8.6560\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.012709327042102814.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0107 - acc: 0.9346 - mse: 180.7135 - mae: 8.8271 - val_loss: 10.7285 - val_acc: 0.9361 - val_mse: 175.2354 - val_mae: 8.6159\n",
      "\n",
      "Epoch 00140: saving model to checkpoints/model_ckpt_epoch_140.hdf5\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.011438394337892533.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0099 - acc: 0.9346 - mse: 180.7595 - mae: 8.8264 - val_loss: 10.7236 - val_acc: 0.9366 - val_mse: 175.3915 - val_mae: 8.6121\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.9991 - acc: 0.9347 - mse: 180.4970 - mae: 8.8184 - val_loss: 10.9625 - val_acc: 0.9327 - val_mse: 180.4495 - val_mae: 8.7907\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 11.0013 - acc: 0.9347 - mse: 180.5878 - mae: 8.8200 - val_loss: 10.8257 - val_acc: 0.9361 - val_mse: 177.2247 - val_mae: 8.6881\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 11.0072 - acc: 0.9346 - mse: 180.7950 - mae: 8.8244 - val_loss: 10.8061 - val_acc: 0.9352 - val_mse: 176.2219 - val_mae: 8.6745\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 34s 17ms/step - loss: 11.0055 - acc: 0.9347 - mse: 180.6369 - mae: 8.8231 - val_loss: 10.7476 - val_acc: 0.9367 - val_mse: 176.9127 - val_mae: 8.6299\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 11.0026 - acc: 0.9346 - mse: 180.5229 - mae: 8.8209 - val_loss: 10.8527 - val_acc: 0.9364 - val_mse: 178.4246 - val_mae: 8.7089\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 11.0012 - acc: 0.9346 - mse: 180.5146 - mae: 8.8199 - val_loss: 10.7286 - val_acc: 0.9361 - val_mse: 175.2658 - val_mae: 8.6161\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 33s 16ms/step - loss: 11.0113 - acc: 0.9345 - mse: 180.7622 - mae: 8.8275 - val_loss: 10.8984 - val_acc: 0.9351 - val_mse: 181.2806 - val_mae: 8.7425\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 10.9939 - acc: 0.9348 - mse: 180.4692 - mae: 8.8144 - val_loss: 10.8413 - val_acc: 0.9347 - val_mse: 177.6146 - val_mae: 8.7006\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.011438393965363503.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 11.0037 - acc: 0.9347 - mse: 180.6281 - mae: 8.8218 - val_loss: 10.7826 - val_acc: 0.9353 - val_mse: 175.8746 - val_mae: 8.6563\n",
      "\n",
      "Epoch 00150: saving model to checkpoints/model_ckpt_epoch_150.hdf5\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.010294554568827153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9860 - acc: 0.9347 - mse: 180.1666 - mae: 8.8086 - val_loss: 10.8678 - val_acc: 0.9363 - val_mse: 178.4050 - val_mae: 8.7196\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9973 - acc: 0.9348 - mse: 180.4715 - mae: 8.8170 - val_loss: 11.0588 - val_acc: 0.9351 - val_mse: 183.5563 - val_mae: 8.8624\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9921 - acc: 0.9347 - mse: 180.4392 - mae: 8.8130 - val_loss: 10.7976 - val_acc: 0.9342 - val_mse: 176.7296 - val_mae: 8.6676\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 10.9919 - acc: 0.9348 - mse: 180.3765 - mae: 8.8129 - val_loss: 10.8348 - val_acc: 0.9349 - val_mse: 177.6837 - val_mae: 8.6951\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9908 - acc: 0.9348 - mse: 180.3675 - mae: 8.8120 - val_loss: 10.7517 - val_acc: 0.9366 - val_mse: 176.6793 - val_mae: 8.6334\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9966 - acc: 0.9348 - mse: 180.5373 - mae: 8.8165 - val_loss: 10.7705 - val_acc: 0.9359 - val_mse: 176.2977 - val_mae: 8.6473\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 10.9847 - acc: 0.9349 - mse: 180.2538 - mae: 8.8076 - val_loss: 10.7513 - val_acc: 0.9350 - val_mse: 175.3651 - val_mae: 8.6331\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9931 - acc: 0.9346 - mse: 180.4359 - mae: 8.8138 - val_loss: 10.7641 - val_acc: 0.9366 - val_mse: 177.3057 - val_mae: 8.6425\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9877 - acc: 0.9347 - mse: 180.2905 - mae: 8.8098 - val_loss: 10.8485 - val_acc: 0.9340 - val_mse: 178.0188 - val_mae: 8.7058\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.010294554755091667.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9875 - acc: 0.9347 - mse: 180.3080 - mae: 8.8096 - val_loss: 10.8000 - val_acc: 0.9366 - val_mse: 176.1552 - val_mae: 8.6696\n",
      "\n",
      "Epoch 00160: saving model to checkpoints/model_ckpt_epoch_160.hdf5\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0092650992795825.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9756 - acc: 0.9346 - mse: 180.0163 - mae: 8.8008 - val_loss: 10.7497 - val_acc: 0.9366 - val_mse: 175.6606 - val_mae: 8.6321\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9833 - acc: 0.9347 - mse: 180.2327 - mae: 8.8065 - val_loss: 10.7172 - val_acc: 0.9361 - val_mse: 175.1347 - val_mae: 8.6074\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9743 - acc: 0.9350 - mse: 180.0484 - mae: 8.7999 - val_loss: 10.7273 - val_acc: 0.9365 - val_mse: 175.3572 - val_mae: 8.6150\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9770 - acc: 0.9349 - mse: 180.1721 - mae: 8.8018 - val_loss: 10.8072 - val_acc: 0.9365 - val_mse: 176.7277 - val_mae: 8.6743\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9834 - acc: 0.9348 - mse: 180.2957 - mae: 8.8066 - val_loss: 10.7629 - val_acc: 0.9366 - val_mse: 176.8973 - val_mae: 8.6412\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.00926509965211153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9802 - acc: 0.9348 - mse: 180.1281 - mae: 8.8042 - val_loss: 10.7762 - val_acc: 0.9366 - val_mse: 175.8415 - val_mae: 8.6515\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9776 - acc: 0.9347 - mse: 180.1762 - mae: 8.8022 - val_loss: 10.7396 - val_acc: 0.9355 - val_mse: 175.3739 - val_mae: 8.6241\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9712 - acc: 0.9347 - mse: 179.9956 - mae: 8.7974 - val_loss: 10.7711 - val_acc: 0.9369 - val_mse: 176.3301 - val_mae: 8.6479\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9738 - acc: 0.9347 - mse: 180.1201 - mae: 8.7993 - val_loss: 10.8368 - val_acc: 0.9359 - val_mse: 178.2702 - val_mae: 8.6966\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.00926509965211153.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9815 - acc: 0.9347 - mse: 180.2940 - mae: 8.8051 - val_loss: 10.8237 - val_acc: 0.9363 - val_mse: 179.3129 - val_mae: 8.6866\n",
      "\n",
      "Epoch 00170: saving model to checkpoints/model_ckpt_epoch_170.hdf5\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.008338589686900377.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.9772 - acc: 0.9348 - mse: 180.1352 - mae: 8.8019 - val_loss: 10.7044 - val_acc: 0.9367 - val_mse: 174.8511 - val_mae: 8.5977\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.9681 - acc: 0.9349 - mse: 179.9284 - mae: 8.7951 - val_loss: 10.7315 - val_acc: 0.9363 - val_mse: 174.8914 - val_mae: 8.6184\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9700 - acc: 0.9349 - mse: 180.0044 - mae: 8.7964 - val_loss: 10.8214 - val_acc: 0.9350 - val_mse: 177.4257 - val_mae: 8.6848\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9585 - acc: 0.9349 - mse: 179.8028 - mae: 8.7879 - val_loss: 10.7160 - val_acc: 0.9358 - val_mse: 175.1610 - val_mae: 8.6066\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9561 - acc: 0.9349 - mse: 179.7638 - mae: 8.7861 - val_loss: 10.7408 - val_acc: 0.9368 - val_mse: 175.3725 - val_mae: 8.6249\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9606 - acc: 0.9348 - mse: 179.8337 - mae: 8.7894 - val_loss: 10.7995 - val_acc: 0.9354 - val_mse: 177.9299 - val_mae: 8.6689\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9631 - acc: 0.9350 - mse: 179.8817 - mae: 8.7914 - val_loss: 10.7212 - val_acc: 0.9370 - val_mse: 175.6542 - val_mae: 8.6100\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9447 - acc: 0.9350 - mse: 179.5343 - mae: 8.7775 - val_loss: 10.7189 - val_acc: 0.9371 - val_mse: 175.1232 - val_mae: 8.6085\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9516 - acc: 0.9350 - mse: 179.6819 - mae: 8.7828 - val_loss: 10.7058 - val_acc: 0.9364 - val_mse: 174.3917 - val_mae: 8.5991\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.00833858922123909.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9448 - acc: 0.9350 - mse: 179.4847 - mae: 8.7776 - val_loss: 10.7028 - val_acc: 0.9359 - val_mse: 174.5782 - val_mae: 8.5966\n",
      "\n",
      "Epoch 00180: saving model to checkpoints/model_ckpt_epoch_180.hdf5\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.007504730299115181.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9418 - acc: 0.9351 - mse: 179.4994 - mae: 8.7753 - val_loss: 10.6721 - val_acc: 0.9370 - val_mse: 174.3981 - val_mae: 8.5734\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9458 - acc: 0.9350 - mse: 179.5685 - mae: 8.7783 - val_loss: 10.7054 - val_acc: 0.9361 - val_mse: 174.4676 - val_mae: 8.5987\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9492 - acc: 0.9351 - mse: 179.6733 - mae: 8.7809 - val_loss: 10.6934 - val_acc: 0.9366 - val_mse: 175.2540 - val_mae: 8.5895\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9337 - acc: 0.9351 - mse: 179.3190 - mae: 8.7692 - val_loss: 10.6870 - val_acc: 0.9371 - val_mse: 175.1349 - val_mae: 8.5845\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9331 - acc: 0.9351 - mse: 179.2342 - mae: 8.7687 - val_loss: 10.7494 - val_acc: 0.9369 - val_mse: 176.6230 - val_mae: 8.6314\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9290 - acc: 0.9352 - mse: 179.2243 - mae: 8.7657 - val_loss: 10.7204 - val_acc: 0.9365 - val_mse: 175.3607 - val_mae: 8.6095\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9198 - acc: 0.9353 - mse: 179.0042 - mae: 8.7589 - val_loss: 10.6817 - val_acc: 0.9364 - val_mse: 175.5295 - val_mae: 8.5806\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9194 - acc: 0.9353 - mse: 178.9844 - mae: 8.7585 - val_loss: 10.6950 - val_acc: 0.9361 - val_mse: 175.1945 - val_mae: 8.5903\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9142 - acc: 0.9353 - mse: 178.8629 - mae: 8.7546 - val_loss: 10.6588 - val_acc: 0.9365 - val_mse: 174.0612 - val_mae: 8.5635\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.007504730485379696.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9208 - acc: 0.9352 - mse: 179.0133 - mae: 8.7596 - val_loss: 10.6315 - val_acc: 0.9368 - val_mse: 173.1892 - val_mae: 8.5431\n",
      "\n",
      "Epoch 00190: saving model to checkpoints/model_ckpt_epoch_190.hdf5\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0067542574368417265.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9022 - acc: 0.9354 - mse: 178.6711 - mae: 8.7457 - val_loss: 10.6329 - val_acc: 0.9370 - val_mse: 173.5902 - val_mae: 8.5438\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9075 - acc: 0.9353 - mse: 178.7549 - mae: 8.7496 - val_loss: 10.6527 - val_acc: 0.9367 - val_mse: 173.9021 - val_mae: 8.5588\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.9113 - acc: 0.9354 - mse: 178.8977 - mae: 8.7523 - val_loss: 10.6342 - val_acc: 0.9372 - val_mse: 174.1300 - val_mae: 8.5448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.9085 - acc: 0.9354 - mse: 178.8552 - mae: 8.7503 - val_loss: 10.7302 - val_acc: 0.9369 - val_mse: 176.0297 - val_mae: 8.6167\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8880 - acc: 0.9354 - mse: 178.3969 - mae: 8.7350 - val_loss: 10.6296 - val_acc: 0.9368 - val_mse: 173.2574 - val_mae: 8.5416\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8910 - acc: 0.9355 - mse: 178.4097 - mae: 8.7373 - val_loss: 10.6497 - val_acc: 0.9373 - val_mse: 173.9884 - val_mae: 8.5562\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8949 - acc: 0.9355 - mse: 178.5525 - mae: 8.7400 - val_loss: 10.6318 - val_acc: 0.9374 - val_mse: 173.7504 - val_mae: 8.5427\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8824 - acc: 0.9355 - mse: 178.2466 - mae: 8.7308 - val_loss: 10.6492 - val_acc: 0.9368 - val_mse: 173.8870 - val_mae: 8.5561\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8814 - acc: 0.9355 - mse: 178.1853 - mae: 8.7300 - val_loss: 10.6918 - val_acc: 0.9373 - val_mse: 174.9912 - val_mae: 8.5877\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.006754257250577211.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8803 - acc: 0.9355 - mse: 178.2464 - mae: 8.7292 - val_loss: 10.6417 - val_acc: 0.9370 - val_mse: 174.9657 - val_mae: 8.5502\n",
      "\n",
      "Epoch 00200: saving model to checkpoints/model_ckpt_epoch_200.hdf5\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.006078831525519491.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8793 - acc: 0.9356 - mse: 178.2598 - mae: 8.7284 - val_loss: 10.6494 - val_acc: 0.9368 - val_mse: 173.7141 - val_mae: 8.5562\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8644 - acc: 0.9357 - mse: 177.7847 - mae: 8.7173 - val_loss: 10.6301 - val_acc: 0.9363 - val_mse: 172.9767 - val_mae: 8.5418\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8720 - acc: 0.9356 - mse: 177.9875 - mae: 8.7229 - val_loss: 10.6111 - val_acc: 0.9375 - val_mse: 173.1599 - val_mae: 8.5274\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8719 - acc: 0.9356 - mse: 178.0401 - mae: 8.7228 - val_loss: 10.6077 - val_acc: 0.9374 - val_mse: 172.6487 - val_mae: 8.5250\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8708 - acc: 0.9356 - mse: 178.0716 - mae: 8.7219 - val_loss: 10.9068 - val_acc: 0.9353 - val_mse: 179.7125 - val_mae: 8.7484\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8684 - acc: 0.9357 - mse: 177.8791 - mae: 8.7201 - val_loss: 10.5998 - val_acc: 0.9372 - val_mse: 173.7582 - val_mae: 8.5190\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8602 - acc: 0.9358 - mse: 177.8583 - mae: 8.7140 - val_loss: 10.6448 - val_acc: 0.9372 - val_mse: 174.5471 - val_mae: 8.5525\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8635 - acc: 0.9357 - mse: 177.8607 - mae: 8.7165 - val_loss: 10.5926 - val_acc: 0.9375 - val_mse: 172.8816 - val_mae: 8.5135\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8701 - acc: 0.9358 - mse: 178.0611 - mae: 8.7214 - val_loss: 10.5970 - val_acc: 0.9374 - val_mse: 172.3384 - val_mae: 8.5168\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.006078831385821104.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8621 - acc: 0.9358 - mse: 177.7798 - mae: 8.7154 - val_loss: 10.6938 - val_acc: 0.9364 - val_mse: 175.0513 - val_mae: 8.5891\n",
      "\n",
      "Epoch 00210: saving model to checkpoints/model_ckpt_epoch_210.hdf5\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.005470948247238994.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8529 - acc: 0.9359 - mse: 177.6077 - mae: 8.7085 - val_loss: 10.6274 - val_acc: 0.9373 - val_mse: 173.7775 - val_mae: 8.5395\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8491 - acc: 0.9357 - mse: 177.5546 - mae: 8.7057 - val_loss: 10.6022 - val_acc: 0.9378 - val_mse: 172.4101 - val_mae: 8.5208\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8379 - acc: 0.9359 - mse: 177.3794 - mae: 8.6973 - val_loss: 10.6001 - val_acc: 0.9367 - val_mse: 173.2331 - val_mae: 8.5191\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8503 - acc: 0.9359 - mse: 177.5386 - mae: 8.7066 - val_loss: 10.5711 - val_acc: 0.9376 - val_mse: 172.1864 - val_mae: 8.4974\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8369 - acc: 0.9361 - mse: 177.2632 - mae: 8.6965 - val_loss: 10.5896 - val_acc: 0.9374 - val_mse: 172.6392 - val_mae: 8.5113\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8406 - acc: 0.9360 - mse: 177.3539 - mae: 8.6992 - val_loss: 10.6541 - val_acc: 0.9367 - val_mse: 175.8448 - val_mae: 8.5593\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8253 - acc: 0.9362 - mse: 176.9719 - mae: 8.6879 - val_loss: 10.5685 - val_acc: 0.9380 - val_mse: 172.0792 - val_mae: 8.4951\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8300 - acc: 0.9361 - mse: 177.1012 - mae: 8.6913 - val_loss: 10.5609 - val_acc: 0.9381 - val_mse: 172.4096 - val_mae: 8.4896\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8348 - acc: 0.9361 - mse: 177.2987 - mae: 8.6949 - val_loss: 10.5878 - val_acc: 0.9377 - val_mse: 173.1939 - val_mae: 8.5096\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.005470948293805122.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8316 - acc: 0.9361 - mse: 177.1272 - mae: 8.6924 - val_loss: 10.5480 - val_acc: 0.9378 - val_mse: 171.5345 - val_mae: 8.4798\n",
      "\n",
      "Epoch 00220: saving model to checkpoints/model_ckpt_epoch_220.hdf5\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.0049238534644246105.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8280 - acc: 0.9360 - mse: 177.0350 - mae: 8.6898 - val_loss: 10.5398 - val_acc: 0.9380 - val_mse: 171.7274 - val_mae: 8.4736\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8221 - acc: 0.9363 - mse: 176.9905 - mae: 8.6852 - val_loss: 10.6571 - val_acc: 0.9371 - val_mse: 174.7676 - val_mae: 8.5615\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8142 - acc: 0.9362 - mse: 176.8605 - mae: 8.6795 - val_loss: 10.6338 - val_acc: 0.9373 - val_mse: 174.1949 - val_mae: 8.5444\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8139 - acc: 0.9361 - mse: 176.7101 - mae: 8.6792 - val_loss: 10.5364 - val_acc: 0.9375 - val_mse: 171.4832 - val_mae: 8.4716\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8194 - acc: 0.9362 - mse: 176.8584 - mae: 8.6832 - val_loss: 10.6496 - val_acc: 0.9374 - val_mse: 174.5741 - val_mae: 8.5556\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8137 - acc: 0.9361 - mse: 176.7017 - mae: 8.6790 - val_loss: 10.5660 - val_acc: 0.9379 - val_mse: 171.5004 - val_mae: 8.4937\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8108 - acc: 0.9361 - mse: 176.6422 - mae: 8.6769 - val_loss: 10.5615 - val_acc: 0.9370 - val_mse: 171.9588 - val_mae: 8.4903\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8146 - acc: 0.9363 - mse: 176.6736 - mae: 8.6797 - val_loss: 10.5764 - val_acc: 0.9377 - val_mse: 173.1523 - val_mae: 8.5011\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8109 - acc: 0.9362 - mse: 176.6884 - mae: 8.6769 - val_loss: 10.5507 - val_acc: 0.9372 - val_mse: 172.4609 - val_mae: 8.4818\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.004923853557556868.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.8097 - acc: 0.9363 - mse: 176.6419 - mae: 8.6759 - val_loss: 10.5933 - val_acc: 0.9376 - val_mse: 172.8320 - val_mae: 8.5141\n",
      "\n",
      "Epoch 00230: saving model to checkpoints/model_ckpt_epoch_230.hdf5\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.004431468201801181.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8008 - acc: 0.9364 - mse: 176.3827 - mae: 8.6693 - val_loss: 10.5742 - val_acc: 0.9375 - val_mse: 171.8701 - val_mae: 8.5000\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.8059 - acc: 0.9362 - mse: 176.5906 - mae: 8.6732 - val_loss: 10.5320 - val_acc: 0.9379 - val_mse: 171.6722 - val_mae: 8.4678\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.7955 - acc: 0.9363 - mse: 176.3549 - mae: 8.6654 - val_loss: 10.5228 - val_acc: 0.9382 - val_mse: 171.4867 - val_mae: 8.4612\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.8043 - acc: 0.9363 - mse: 176.4886 - mae: 8.6720 - val_loss: 10.5229 - val_acc: 0.9379 - val_mse: 170.9096 - val_mae: 8.4613\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.8003 - acc: 0.9362 - mse: 176.4124 - mae: 8.6689 - val_loss: 10.5332 - val_acc: 0.9381 - val_mse: 171.4393 - val_mae: 8.4686\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.8012 - acc: 0.9362 - mse: 176.3831 - mae: 8.6695 - val_loss: 10.6433 - val_acc: 0.9364 - val_mse: 174.8035 - val_mae: 8.5518\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.7941 - acc: 0.9362 - mse: 176.2708 - mae: 8.6643 - val_loss: 10.5481 - val_acc: 0.9378 - val_mse: 171.6478 - val_mae: 8.4801\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.7868 - acc: 0.9363 - mse: 176.0268 - mae: 8.6589 - val_loss: 10.5452 - val_acc: 0.9378 - val_mse: 172.8389 - val_mae: 8.4775\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.8028 - acc: 0.9362 - mse: 176.4877 - mae: 8.6709 - val_loss: 10.5518 - val_acc: 0.9378 - val_mse: 172.3285 - val_mae: 8.4824\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.0044314684346318245.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 10.7971 - acc: 0.9363 - mse: 176.4178 - mae: 8.6665 - val_loss: 10.5310 - val_acc: 0.9381 - val_mse: 171.0504 - val_mae: 8.4671\n",
      "\n",
      "Epoch 00240: saving model to checkpoints/model_ckpt_epoch_240.hdf5\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.003988321591168642.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.7882 - acc: 0.9361 - mse: 176.0722 - mae: 8.6598 - val_loss: 10.5075 - val_acc: 0.9379 - val_mse: 171.4096 - val_mae: 8.4495\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 15ms/step - loss: 10.7874 - acc: 0.9363 - mse: 176.1866 - mae: 8.6592 - val_loss: 10.5094 - val_acc: 0.9377 - val_mse: 170.9475 - val_mae: 8.4509\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7892 - acc: 0.9364 - mse: 176.1584 - mae: 8.6606 - val_loss: 10.5241 - val_acc: 0.9379 - val_mse: 170.8039 - val_mae: 8.4618\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7838 - acc: 0.9365 - mse: 176.0175 - mae: 8.6565 - val_loss: 10.5676 - val_acc: 0.9371 - val_mse: 172.5842 - val_mae: 8.4945\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7867 - acc: 0.9362 - mse: 176.1254 - mae: 8.6587 - val_loss: 10.5231 - val_acc: 0.9375 - val_mse: 171.1035 - val_mae: 8.4612\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7838 - acc: 0.9363 - mse: 176.0961 - mae: 8.6564 - val_loss: 10.5111 - val_acc: 0.9375 - val_mse: 171.2126 - val_mae: 8.4520\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7793 - acc: 0.9364 - mse: 175.9526 - mae: 8.6531 - val_loss: 10.5079 - val_acc: 0.9381 - val_mse: 170.7964 - val_mae: 8.4499\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7844 - acc: 0.9363 - mse: 176.0717 - mae: 8.6570 - val_loss: 10.5617 - val_acc: 0.9379 - val_mse: 171.6767 - val_mae: 8.4900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7790 - acc: 0.9364 - mse: 175.9784 - mae: 8.6530 - val_loss: 10.5004 - val_acc: 0.9380 - val_mse: 170.7337 - val_mae: 8.4442\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.003988321404904127.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7919 - acc: 0.9363 - mse: 176.1705 - mae: 8.6626 - val_loss: 10.5486 - val_acc: 0.9376 - val_mse: 171.8609 - val_mae: 8.4805\n",
      "\n",
      "Epoch 00250: saving model to checkpoints/model_ckpt_epoch_250.hdf5\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.7799 - acc: 0.9365 - mse: 176.0022 - mae: 8.6536 - val_loss: 10.5125 - val_acc: 0.9382 - val_mse: 171.6022 - val_mae: 8.4532\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.7772 - acc: 0.9364 - mse: 175.9647 - mae: 8.6515 - val_loss: 10.5550 - val_acc: 0.9380 - val_mse: 171.6298 - val_mae: 8.4848\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7774 - acc: 0.9364 - mse: 176.0090 - mae: 8.6517 - val_loss: 10.5017 - val_acc: 0.9379 - val_mse: 171.0717 - val_mae: 8.4454\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7759 - acc: 0.9363 - mse: 175.9222 - mae: 8.6505 - val_loss: 10.4922 - val_acc: 0.9379 - val_mse: 170.5433 - val_mae: 8.4383\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7840 - acc: 0.9364 - mse: 176.0712 - mae: 8.6566 - val_loss: 10.5490 - val_acc: 0.9383 - val_mse: 172.0979 - val_mae: 8.4804\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7647 - acc: 0.9364 - mse: 175.6567 - mae: 8.6422 - val_loss: 10.6136 - val_acc: 0.9374 - val_mse: 174.6637 - val_mae: 8.5288\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7683 - acc: 0.9365 - mse: 175.7287 - mae: 8.6449 - val_loss: 10.4979 - val_acc: 0.9380 - val_mse: 170.4733 - val_mae: 8.4420\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7715 - acc: 0.9364 - mse: 175.7546 - mae: 8.6473 - val_loss: 10.5557 - val_acc: 0.9379 - val_mse: 172.2328 - val_mae: 8.4855\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7786 - acc: 0.9364 - mse: 175.9804 - mae: 8.6526 - val_loss: 10.5892 - val_acc: 0.9379 - val_mse: 172.9140 - val_mae: 8.5104\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.0035894892644137144.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7697 - acc: 0.9363 - mse: 175.7975 - mae: 8.6459 - val_loss: 10.4925 - val_acc: 0.9381 - val_mse: 170.4042 - val_mae: 8.4383\n",
      "\n",
      "Epoch 00260: saving model to checkpoints/model_ckpt_epoch_260.hdf5\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.003230540337972343.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7672 - acc: 0.9364 - mse: 175.7161 - mae: 8.6441 - val_loss: 10.4905 - val_acc: 0.9382 - val_mse: 170.6164 - val_mae: 8.4368\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7630 - acc: 0.9364 - mse: 175.6759 - mae: 8.6409 - val_loss: 10.4891 - val_acc: 0.9382 - val_mse: 170.7851 - val_mae: 8.4355\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7639 - acc: 0.9365 - mse: 175.6428 - mae: 8.6416 - val_loss: 10.4758 - val_acc: 0.9377 - val_mse: 170.1694 - val_mae: 8.4257\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7660 - acc: 0.9364 - mse: 175.8008 - mae: 8.6431 - val_loss: 10.5118 - val_acc: 0.9377 - val_mse: 170.6651 - val_mae: 8.4523\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7748 - acc: 0.9364 - mse: 175.8530 - mae: 8.6498 - val_loss: 10.5095 - val_acc: 0.9384 - val_mse: 171.3660 - val_mae: 8.4508\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7597 - acc: 0.9365 - mse: 175.5456 - mae: 8.6384 - val_loss: 10.5130 - val_acc: 0.9383 - val_mse: 170.5690 - val_mae: 8.4538\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7673 - acc: 0.9363 - mse: 175.7338 - mae: 8.6442 - val_loss: 10.4976 - val_acc: 0.9382 - val_mse: 170.6076 - val_mae: 8.4423\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7616 - acc: 0.9363 - mse: 175.6317 - mae: 8.6398 - val_loss: 10.5154 - val_acc: 0.9380 - val_mse: 171.3782 - val_mae: 8.4552\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7707 - acc: 0.9364 - mse: 175.8316 - mae: 8.6467 - val_loss: 10.5053 - val_acc: 0.9379 - val_mse: 170.9818 - val_mae: 8.4478\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.0032305403146892786.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7642 - acc: 0.9365 - mse: 175.5998 - mae: 8.6418 - val_loss: 10.5371 - val_acc: 0.9382 - val_mse: 171.3000 - val_mae: 8.4716\n",
      "\n",
      "Epoch 00270: saving model to checkpoints/model_ckpt_epoch_270.hdf5\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.0029074862832203507.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7574 - acc: 0.9364 - mse: 175.5671 - mae: 8.6368 - val_loss: 10.5528 - val_acc: 0.9375 - val_mse: 171.4726 - val_mae: 8.4831\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7607 - acc: 0.9364 - mse: 175.6503 - mae: 8.6391 - val_loss: 10.5713 - val_acc: 0.9376 - val_mse: 172.2223 - val_mae: 8.4971\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7591 - acc: 0.9364 - mse: 175.5353 - mae: 8.6379 - val_loss: 10.5512 - val_acc: 0.9367 - val_mse: 171.1437 - val_mae: 8.4823\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7614 - acc: 0.9365 - mse: 175.5880 - mae: 8.6398 - val_loss: 10.4831 - val_acc: 0.9377 - val_mse: 170.4321 - val_mae: 8.4312\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7552 - acc: 0.9366 - mse: 175.4812 - mae: 8.6350 - val_loss: 10.5228 - val_acc: 0.9382 - val_mse: 170.4848 - val_mae: 8.4612\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.002907486166805029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.7622 - acc: 0.9365 - mse: 175.5785 - mae: 8.6403 - val_loss: 10.4880 - val_acc: 0.9379 - val_mse: 171.0744 - val_mae: 8.4350\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.7533 - acc: 0.9365 - mse: 175.4269 - mae: 8.6337 - val_loss: 10.4830 - val_acc: 0.9381 - val_mse: 170.0256 - val_mae: 8.4313\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.7496 - acc: 0.9365 - mse: 175.3592 - mae: 8.6309 - val_loss: 10.4946 - val_acc: 0.9379 - val_mse: 171.2708 - val_mae: 8.4399\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.7503 - acc: 0.9366 - mse: 175.3131 - mae: 8.6314 - val_loss: 10.4755 - val_acc: 0.9380 - val_mse: 170.5154 - val_mae: 8.4255\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.002907486166805029.\n",
      "2025/2025 [==============================] - 28s 14ms/step - loss: 10.7488 - acc: 0.9366 - mse: 175.4799 - mae: 8.6303 - val_loss: 10.4683 - val_acc: 0.9381 - val_mse: 170.4907 - val_mae: 8.4200\n",
      "\n",
      "Epoch 00280: saving model to checkpoints/model_ckpt_epoch_280.hdf5\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.0026167375501245263.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7514 - acc: 0.9366 - mse: 175.3979 - mae: 8.6323 - val_loss: 10.4846 - val_acc: 0.9376 - val_mse: 170.6089 - val_mae: 8.4325\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7489 - acc: 0.9366 - mse: 175.2997 - mae: 8.6304 - val_loss: 10.4824 - val_acc: 0.9381 - val_mse: 170.8083 - val_mae: 8.4308\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7478 - acc: 0.9365 - mse: 175.3806 - mae: 8.6295 - val_loss: 10.4959 - val_acc: 0.9382 - val_mse: 170.7550 - val_mae: 8.4406\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7546 - acc: 0.9365 - mse: 175.4656 - mae: 8.6346 - val_loss: 10.4761 - val_acc: 0.9384 - val_mse: 170.3394 - val_mae: 8.4260\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 29s 14ms/step - loss: 10.7474 - acc: 0.9364 - mse: 175.2701 - mae: 8.6293 - val_loss: 10.4686 - val_acc: 0.9383 - val_mse: 170.2216 - val_mae: 8.4205\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 10.7509 - acc: 0.9364 - mse: 175.4579 - mae: 8.6318 - val_loss: 10.4810 - val_acc: 0.9381 - val_mse: 170.2756 - val_mae: 8.4298\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.7469 - acc: 0.9364 - mse: 175.2985 - mae: 8.6289 - val_loss: 10.4879 - val_acc: 0.9380 - val_mse: 170.0772 - val_mae: 8.4347\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 10.7487 - acc: 0.9364 - mse: 175.3579 - mae: 8.6302 - val_loss: 10.5035 - val_acc: 0.9381 - val_mse: 171.0812 - val_mae: 8.4464\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 10.7424 - acc: 0.9364 - mse: 175.2388 - mae: 8.6255 - val_loss: 10.4641 - val_acc: 0.9381 - val_mse: 170.3096 - val_mae: 8.4169\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.0026167375035583973.\n",
      "2025/2025 [==============================] - 30s 15ms/step - loss: 10.7436 - acc: 0.9366 - mse: 175.2328 - mae: 8.6263 - val_loss: 10.4769 - val_acc: 0.9379 - val_mse: 170.4149 - val_mae: 8.4266\n",
      "\n",
      "Epoch 00290: saving model to checkpoints/model_ckpt_epoch_290.hdf5\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.0023550637532025577.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 10.7481 - acc: 0.9364 - mse: 175.3752 - mae: 8.6297 - val_loss: 10.4798 - val_acc: 0.9381 - val_mse: 170.8515 - val_mae: 8.4287\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 34s 17ms/step - loss: 10.7402 - acc: 0.9364 - mse: 175.2367 - mae: 8.6237 - val_loss: 10.5138 - val_acc: 0.9372 - val_mse: 171.1541 - val_mae: 8.4543\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 33s 16ms/step - loss: 10.7460 - acc: 0.9365 - mse: 175.3497 - mae: 8.6282 - val_loss: 10.4678 - val_acc: 0.9385 - val_mse: 170.0158 - val_mae: 8.4198\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 10.7441 - acc: 0.9365 - mse: 175.2554 - mae: 8.6269 - val_loss: 10.4944 - val_acc: 0.9378 - val_mse: 170.1773 - val_mae: 8.4397\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 33s 16ms/step - loss: 10.7373 - acc: 0.9366 - mse: 175.0969 - mae: 8.6216 - val_loss: 10.4555 - val_acc: 0.9381 - val_mse: 169.6445 - val_mae: 8.4106\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 34s 17ms/step - loss: 10.7423 - acc: 0.9365 - mse: 175.2190 - mae: 8.6254 - val_loss: 10.4633 - val_acc: 0.9384 - val_mse: 169.6480 - val_mae: 8.4164\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 36s 18ms/step - loss: 10.7474 - acc: 0.9364 - mse: 175.3394 - mae: 8.6291 - val_loss: 10.4849 - val_acc: 0.9383 - val_mse: 170.6572 - val_mae: 8.4323\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 34s 17ms/step - loss: 10.7444 - acc: 0.9364 - mse: 175.2430 - mae: 8.6270 - val_loss: 10.4729 - val_acc: 0.9384 - val_mse: 170.3901 - val_mae: 8.4235\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 32s 16ms/step - loss: 10.7325 - acc: 0.9365 - mse: 174.9473 - mae: 8.6180 - val_loss: 10.4669 - val_acc: 0.9381 - val_mse: 170.1843 - val_mae: 8.4189\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.0023550637997686863.\n",
      "2025/2025 [==============================] - 31s 15ms/step - loss: 10.7406 - acc: 0.9364 - mse: 175.1793 - mae: 8.6241 - val_loss: 10.4613 - val_acc: 0.9379 - val_mse: 170.3283 - val_mae: 8.4149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Done training. Time elapsed: 2:28:13.749738 sec\n",
      "[INFO    ] Epoch 300/300 - loss: 10.740618705749512 - val_loss: 10.46129322052002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00300: saving model to checkpoints/model_ckpt_epoch_300.hdf5\n"
     ]
    }
   ],
   "source": [
    "assert(keras.backend.backend() == 'tensorflow')\n",
    "\n",
    "normal_epochs = 300\n",
    "normal_batch_size = 1000\n",
    "l1_reg = 0.0\n",
    "l2_reg = 0.0\n",
    "learning_rate = 0.05\n",
    "gradient_clip_norm = 100.\n",
    "\n",
    "lr_decay = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "model_training_checkpoint = ModelCheckpoint(monitor=\"val_loss\", \n",
    "                                           verbose = 1,\n",
    "                                           filepath = \"checkpoints/model_ckpt_epoch_{epoch:02d}.hdf5\",\n",
    "                                           period = 10)\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", \n",
    "                                               min_delta= 1e-5, \n",
    "                                               mode = \"auto\", \n",
    "                                               patience = 10)\n",
    "\n",
    "model = create_model(\n",
    "                    nvariables = NVARIABLES, \n",
    "                    lr = learning_rate, \n",
    "                    clipnorm = gradient_clip_norm, \n",
    "                    nodes1=10, \n",
    "                    nodes2=7, \n",
    "                    nodes3=5, \n",
    "                    outnodes=2,\n",
    "                    l1_reg = l1_reg, \n",
    "                    l2_reg = l2_reg)\n",
    "\n",
    "logger.info('Training model with l1_reg: {0} l2_reg: {1}'.format(l1_reg, l2_reg))\n",
    "\n",
    "model, history = train_model(model, \n",
    "                      x_train_displ, \n",
    "                      np.column_stack((y_train_displ, dxy_train_displ)),\n",
    "                      save_model=False, \n",
    "                      epochs=normal_epochs, \n",
    "                      batch_size=normal_batch_size,\n",
    "                      callbacks=[lr_decay,terminate_on_nan, model_training_checkpoint], \n",
    "                      validation_split=0.1, \n",
    "                      verbose=True)\n",
    "\n",
    "metrics = [len(history.history['loss']), history.history['loss'][-1], history.history['val_loss'][-1]]\n",
    "logger.info('Epoch {0}/{0} - loss: {1} - val_loss: {2}'.format(*metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ace39d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 19:18:38.753058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for 1-Fold cv for momentum = 52.12346508293483\n",
      "Mean RMSE for 1-Fold cv for displacement = 17.094939236643718\n",
      "Mean MAE for 1-Fold cv for momentum = 11.225666081859531\n",
      "Mean MAE for 1-Fold cv for displacement = 12.051035439779488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] # of entries: 1034656, mean: 0.04872230097123355, std: 0.18677842831551852\n",
      "[INFO    ] gaus fit (a, mu, sig): [ 5.22447713e+04 -1.05662438e-02  2.61796697e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 375x375 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] # of entries: 149864, mean: -0.2786651528813812, std: 10.9846716990604\n",
      "[INFO    ] gaus fit (a, mu, sig): [ 8.43505192e+03 -3.84070478e-01  6.39581352e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 375x375 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_fold_validation(model = model,\n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds = 1,\n",
    "                  metric_type = \"RMSE\")\n",
    "k_fold_validation(model = model,\n",
    "                  x = x_test_displ,\n",
    "                  y = y_test_displ,\n",
    "                  dxy = dxy_test_displ,\n",
    "                  folds = 1,\n",
    "                  metric_type = \"MAE\")\n",
    "__generate_delta_plots__(model,\n",
    "                         x = x_test_displ,\n",
    "                         y = y_test_displ,\n",
    "                         dxy = dxy_test_displ,\n",
    "                         color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1aa2213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# from nn_pruning_module_support import saving_model\n",
    "# saving_model(model = model,\n",
    "#             filepath = \"./models\",\n",
    "#             model_filename = \"baseline_reduced_dim_0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b31c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
